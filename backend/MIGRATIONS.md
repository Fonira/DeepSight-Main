# DeepSight Database Migrations & Backup Guide

## Overview

DeepSight uses **Alembic** for database schema migrations and **pg_dump** for backups.

| Component | Tool | Location |
|-----------|------|----------|
| Migrations | Alembic | `backend/alembic/` |
| Backup | pg_dump + gzip | `backend/scripts/backup_db.py` |
| Restore | psql | `backend/scripts/restore_db.py` |
| Cron backup | GitHub Actions | `.github/workflows/db-backup.yml` |
| In-process backup | APScheduler | `backend/src/main.py` (lifespan) |

---

## Migrations (Alembic)

### Setup

Alembic is configured in `backend/alembic.ini` and `backend/alembic/env.py`.
It reads models from `src/db/database.py` and connects using `DATABASE_URL`.

### Creating a new migration

```bash
cd backend

# Auto-generate from model changes
alembic revision --autogenerate -m "add_new_column_to_users"

# Or create an empty migration for manual SQL
alembic revision -m "custom_data_migration"
```

### Running migrations

```bash
cd backend

# Apply all pending migrations
alembic upgrade head

# Upgrade to a specific revision
alembic upgrade 001

# Downgrade one step
alembic downgrade -1

# Downgrade to base (empty DB)
alembic downgrade base

# Show current revision
alembic current

# Show migration history
alembic history --verbose
```

### Migration on Railway (production)

Migrations run automatically via APScheduler backup integration. For manual migration:

```bash
# Set DATABASE_URL to your Railway PostgreSQL URL
export DATABASE_URL="postgresql://user:pass@host:port/dbname"
cd backend
alembic upgrade head
```

### Best practices

1. **Always review autogenerated migrations** — Alembic may miss renames or data migrations
2. **Test migrations locally** before deploying
3. **Never modify a migration after it has been applied** to production
4. **Include both upgrade and downgrade** functions
5. **Use `if_not_exists=True`** for create_table in baseline migrations

---

## Backup

### Local backup (CLI)

```bash
cd backend

# Local backup only
python -m scripts.backup_db

# Backup + upload to S3
python -m scripts.backup_db --upload
```

Output: `/tmp/deepsight-backups/deepsight_YYYYMMDD_HHMMSS.sql.gz`

### Automatic backups

Two mechanisms run backups:

1. **APScheduler** (in-process): Configured in `main.py` lifespan, runs daily at the hour set in `BACKUP_CRON_HOUR` (default 03:00 UTC). Uploads to S3 if credentials are set.

2. **GitHub Actions**: `.github/workflows/db-backup.yml` runs daily at 03:00 UTC. Also stores a 7-day artifact in GitHub.

### S3 Configuration

Set these environment variables (or Railway secrets):

| Variable | Description | Default |
|----------|-------------|---------|
| `AWS_ACCESS_KEY_ID` | S3 access key | — |
| `AWS_SECRET_ACCESS_KEY` | S3 secret key | — |
| `AWS_REGION` | S3 region | `eu-west-3` |
| `BACKUP_S3_BUCKET` | Bucket name | `deepsight-backups` |
| `BACKUP_S3_PREFIX` | Key prefix | `db-backups/` |
| `BACKUP_RETENTION_DAYS` | Auto-cleanup age | `30` |

### Retention

- **Local**: Old `.sql.gz` files are deleted after `BACKUP_RETENTION_DAYS` days
- **S3**: Old objects are deleted after `BACKUP_RETENTION_DAYS` days
- **GitHub Artifacts**: Kept for 7 days

---

## Restore

### From local file

```bash
cd backend
python -m scripts.restore_db path/to/backup.sql.gz
```

### From S3

```bash
# Specific file
python -m scripts.restore_db --from-s3 deepsight_20260212_030000.sql.gz

# Most recent backup
python -m scripts.restore_db --latest
```

### Production restore

For production databases, the `--confirm` flag is required:

```bash
python -m scripts.restore_db --latest --confirm
```

### Safety features

- **Pre-restore backup**: By default, creates a backup before restoring. Skip with `--force`.
- **Production guard**: Detects Railway hosts and requires `--confirm`.
- **Size display**: Shows backup file size and target database info before proceeding.

---

## Health Endpoint

`GET /api/health/db` returns:

```json
{
  "database": {
    "status": "healthy",
    "latency_ms": 2.5,
    "version": "PostgreSQL 16.1",
    "size_mb": 42.5,
    "active_connections": 8,
    "max_connections": 100
  },
  "migrations": {
    "current_revision": "001",
    "head_revision": "001",
    "pending": 0,
    "is_up_to_date": true
  }
}
```

---

## Troubleshooting

### "pg_dump not found"

Install PostgreSQL client tools:
```bash
# Ubuntu/Debian
sudo apt-get install postgresql-client

# macOS
brew install libpq && brew link --force libpq
```

### "SSL connection required"

Railway's public proxy requires SSL. The scripts handle this automatically for `*.proxy.rlwy.net` hosts.

### Migration conflicts

If two developers create migrations at the same time:
```bash
# Show branches
alembic branches

# Merge branches
alembic merge -m "merge_branches" rev1 rev2
```

### Restore fails with "relation already exists"

The backup uses `--no-owner --no-acl` and plain format. If tables exist, psql will show warnings but continue. For a clean restore, drop and recreate the database first.
