"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“š PLAYLIST ROUTER v4.1 â€” DEEP SIGHT OPTIMIZED EDITION                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ğŸ§® Scoring sÃ©mantique dynamique pour sÃ©lection contextuelle                       â•‘
â•‘  ğŸ’¾ Cache intelligent LRU avec TTL                                                 â•‘
â•‘  ğŸ”€ Fusion multi-sources Mistral + Perplexity                                      â•‘
â•‘  ğŸ¯ Allocation dynamique de tokens selon pertinence                                â•‘
â•‘  â±ï¸ Extraction et validation automatique des timecodes                             â•‘
â•‘  ğŸ§  Raisonnement bayÃ©sien adaptatif par mode                                       â•‘
â•‘  ğŸ“Š MÃ©triques de confiance et sourÃ§age enrichi                                     â•‘
â•‘  ğŸ“¹ FIX v4.1: Endpoint video individuel ajoutÃ©                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import json
import httpx
import re
import hashlib
from uuid import uuid4
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List, Tuple
from collections import Counter, OrderedDict
from functools import lru_cache
from dataclasses import dataclass, field
from enum import Enum
from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks, Query
from pydantic import BaseModel, Field
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, delete, func

from db.database import (
    get_session, User, Summary, PlaylistAnalysis, PlaylistChatMessage
)
from auth.dependencies import get_current_user
from core.config import PLAN_LIMITS, get_mistral_key, get_perplexity_key
from videos.analysis import generate_summary, detect_category
from transcripts import (
    extract_video_id, extract_playlist_id,
    get_video_info, get_transcript_with_timestamps,
    get_playlist_videos, get_playlist_info
)

router = APIRouter()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“¦ SCHEMAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AnalyzePlaylistRequest(BaseModel):
    url: str
    max_videos: int = Field(default=10, ge=1, le=100)
    mode: str = Field(default="standard", description="accessible | standard | expert")
    lang: str = "fr"
    model: Optional[str] = None

class AnalyzeCorpusRequest(BaseModel):
    urls: List[str] = Field(..., min_length=1, max_length=100)
    name: str = Field(default="Mon Corpus")
    mode: str = Field(default="standard", description="accessible | standard | expert")
    lang: str = "fr"
    model: Optional[str] = None

class PlaylistTaskStatus(BaseModel):
    task_id: str
    status: str
    progress: int = 0
    message: str = ""
    current_video: int = 0
    total_videos: int = 0
    result: Optional[Dict[str, Any]] = None

class ChatCorpusRequest(BaseModel):
    message: str
    web_search: bool = False
    mode: str = Field(default="standard", description="accessible | standard | expert")
    lang: str = Field(default="fr", description="Response language: fr | en")

class ChatCorpusResponse(BaseModel):
    response: str
    sources: Optional[List[Dict[str, str]]] = None
    citations: Optional[List[str]] = None
    model_used: str = ""
    tokens_used: int = 0
    relevance_scores: Optional[Dict[str, float]] = None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ—„ï¸ CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_playlist_task_store: Dict[str, Dict[str, Any]] = {}

PLAN_VIDEO_LIMITS = {
    "free": 10,
    "starter": 20,
    "pro": 50,
    "expert": 100,
    "unlimited": 100
}

PLAN_MODELS = {
    "free": "mistral-small-latest",
    "starter": "mistral-small-latest",
    "pro": "mistral-medium-latest",
    "expert": "mistral-large-latest",
    "unlimited": "mistral-large-latest"
}

CHAT_CONFIG = {
    "free": {
        "model": "mistral-small-latest",
        "max_corpus": 40000,
        "max_videos": 10,
        "daily_limit": 10,
        "web_search": False
    },
    "starter": {
        "model": "mistral-small-latest",
        "max_corpus": 60000,
        "max_videos": 15,
        "daily_limit": 40,
        "web_search": False
    },
    "pro": {
        "model": "mistral-large-latest",
        "max_corpus": 200000,
        "max_videos": 40,
        "daily_limit": 100,
        "web_search": True
    },
    "expert": {
        "model": "mistral-large-latest",
        "max_corpus": 300000,
        "max_videos": 50,
        "daily_limit": -1,
        "web_search": True
    },
    "unlimited": {
        "model": "mistral-large-latest",
        "max_corpus": 300000,
        "max_videos": 50,
        "daily_limit": -1,
        "web_search": True
    }
}

MODE_CONFIG = {
    "accessible": {
        "max_tokens": 2000,
        "num_segments": 3,
        "timecode_min": 2,
        "style_fr": "Professeur passionnÃ©: concis (2-4 phrases), accessible, curieux mais critique",
        "style_en": "Passionate professor: concise (2-4 sentences), accessible, curious but critical"
    },
    "standard": {
        "max_tokens": 4000,
        "num_segments": 4,
        "timecode_min": 4,
        "style_fr": "Analyste Ã©quilibrÃ©: complet (5-8 phrases), Ã©value la crÃ©dibilitÃ©, distingue fait/opinion",
        "style_en": "Balanced analyst: complete (5-8 sentences), evaluates credibility, distinguishes fact/opinion"
    },
    "expert": {
        "max_tokens": 8000,
        "num_segments": 5,
        "timecode_min": 6,
        "style_fr": "Analyste bayÃ©sien exhaustif: analyse dÃ©taillÃ©e, identifie sophismes et biais, impitoyablement rigoureux",
        "style_en": "Exhaustive Bayesian analyst: detailed analysis, identifies fallacies and biases, ruthlessly rigorous"
    }
}

VOLATILE_TOPICS = {
    "sport": {
        "keywords": ["joueur", "effectif", "transfert", "Ã©quipe", "club", "entraÃ®neur", "coach",
                    "mercato", "classement", "buteur", "titulaire", "blessÃ©", "PSG", "OM", "OL",
                    "player", "roster", "transfer", "team", "manager", "standings", "injured"],
        "disclaimer_fr": "âš ï¸ **Attention** : Les effectifs sportifs changent frÃ©quemment. Ces informations datent de la vidÃ©o.",
        "disclaimer_en": "âš ï¸ **Warning**: Sports rosters change frequently. This information is from the video's date."
    },
    "business": {
        "keywords": ["PDG", "CEO", "directeur", "prÃ©sident", "dÃ©mission", "nomination", "rachat",
                    "fusion", "acquisition", "valorisation", "licenciement",
                    "director", "president", "resignation", "appointment", "buyout", "merger"],
        "disclaimer_fr": "âš ï¸ **Attention** : Les positions de direction Ã©voluent. VÃ©rifiez les informations actuelles.",
        "disclaimer_en": "âš ï¸ **Warning**: Leadership positions change. Verify current information."
    },
    "tech": {
        "keywords": ["version", "mise Ã  jour", "beta", "alpha", "sortie", "lancement", "prix",
                    "disponible", "annonce", "roadmap", "update", "release", "launch", "available"],
        "disclaimer_fr": "âš ï¸ **Attention** : Les informations technologiques Ã©voluent rapidement.",
        "disclaimer_en": "âš ï¸ **Warning**: Technology information evolves rapidly."
    },
    "politique": {
        "keywords": ["ministre", "prÃ©sident", "gouvernement", "Ã©lection", "loi", "dÃ©cret",
                    "rÃ©forme", "vote", "sondage", "candidat",
                    "minister", "government", "election", "law", "reform", "poll", "candidate"],
        "disclaimer_fr": "âš ï¸ **Attention** : La situation politique peut avoir Ã©voluÃ© depuis cette vidÃ©o.",
        "disclaimer_en": "âš ï¸ **Warning**: The political situation may have evolved since this video."
    }
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§® SEMANTIC SCORING ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SemanticScorer:
    """Moteur de scoring sÃ©mantique sans embeddings externes."""
    
    STOPWORDS = frozenset([
        "le", "la", "les", "de", "du", "des", "un", "une", "et", "ou", "mais",
        "donc", "car", "ni", "que", "qui", "quoi", "dont", "oÃ¹", "ce", "cette",
        "ces", "son", "sa", "ses", "leur", "leurs", "mon", "ma", "mes", "ton",
        "ta", "tes", "notre", "nos", "votre", "vos", "je", "tu", "il", "elle",
        "nous", "vous", "ils", "elles", "on", "se", "ne", "pas", "plus", "trÃ¨s",
        "bien", "tout", "tous", "toute", "toutes", "mÃªme", "aussi", "avec",
        "pour", "par", "dans", "sur", "sous", "vers", "chez", "entre", "sans",
        "est", "sont", "Ã©tÃ©", "Ãªtre", "avoir", "fait", "faire", "peut", "dit",
        "comme", "quand", "alors", "encore", "dÃ©jÃ ", "toujours", "jamais",
        "the", "a", "an", "and", "or", "but", "is", "are", "was", "were", "be",
        "been", "being", "have", "has", "had", "do", "does", "did", "will",
        "would", "could", "should", "may", "might", "must", "shall", "can",
        "to", "of", "in", "for", "on", "with", "at", "by", "from", "as", "into",
        "about", "like", "through", "after", "over", "between", "out", "against",
        "during", "before", "under", "around", "among", "this", "that", "these",
        "those", "it", "its", "they", "them", "their", "what", "which", "who",
        "how", "when", "where", "why", "all", "each", "every", "both", "few",
        "more", "most", "other", "some", "such", "no", "not", "only", "own",
        "same", "so", "than", "too", "very", "just", "also", "now"
    ])
    
    CATEGORY_KEYWORDS = {
        "science": ["recherche", "Ã©tude", "dÃ©couverte", "thÃ©orie", "expÃ©rience", "donnÃ©es", 
                   "analyse", "scientifique", "chercheur", "laboratoire", "hypothÃ¨se"],
        "technology": ["algorithme", "code", "systÃ¨me", "logiciel", "ia", "intelligence", 
                      "artificielle", "dÃ©veloppement", "application", "programme", "tech"],
        "history": ["histoire", "Ã©poque", "siÃ¨cle", "Ã©vÃ©nement", "guerre", "civilisation", 
                   "passÃ©", "historique", "roi", "empire", "rÃ©volution"],
        "philosophy": ["philosophie", "pensÃ©e", "concept", "Ã©thique", "morale", "existence", 
                      "sens", "conscience", "libertÃ©", "vÃ©ritÃ©"],
        "economy": ["Ã©conomie", "marchÃ©", "finance", "investissement", "croissance", 
                   "entreprise", "commerce", "banque", "argent", "capital"],
        "health": ["santÃ©", "mÃ©decine", "maladie", "traitement", "corps", "cerveau", 
                  "mental", "nutrition", "sport", "bien-Ãªtre"],
        "society": ["sociÃ©tÃ©", "politique", "social", "culture", "population", 
                   "gouvernement", "citoyen", "communautÃ©", "droit"]
    }
    
    @classmethod
    def tokenize(cls, text: str) -> List[str]:
        if not text:
            return []
        text = text.lower()
        text = re.sub(r'[Ã Ã¢Ã¤]', 'a', text)
        text = re.sub(r'[Ã©Ã¨ÃªÃ«]', 'e', text)
        text = re.sub(r'[Ã®Ã¯]', 'i', text)
        text = re.sub(r'[Ã´Ã¶]', 'o', text)
        text = re.sub(r'[Ã¹Ã»Ã¼]', 'u', text)
        text = re.sub(r'[Ã§]', 'c', text)
        text = re.sub(r'[^\w\s]', ' ', text)
        tokens = text.split()
        return [t for t in tokens if t not in cls.STOPWORDS and len(t) > 2]
    
    @classmethod
    def compute_tf(cls, tokens: List[str]) -> Dict[str, float]:
        if not tokens:
            return {}
        freq = Counter(tokens)
        max_freq = max(freq.values())
        return {t: f / max_freq for t, f in freq.items()}
    
    @classmethod
    def jaccard_similarity(cls, set1: set, set2: set) -> float:
        if not set1 or not set2:
            return 0.0
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        return intersection / union if union > 0 else 0.0
    
    @classmethod
    def get_category_boost(cls, query_tokens: set, category: str) -> float:
        if not category:
            return 1.0
        category_kw = cls.CATEGORY_KEYWORDS.get(category.lower(), [])
        if not category_kw:
            return 1.0
        matches = len(query_tokens & set(category_kw))
        return 1.0 + (matches * 0.12)
    
    @classmethod
    def extract_key_concepts(cls, text: str, top_n: int = 10) -> List[str]:
        tokens = cls.tokenize(text)
        if not tokens:
            return []
        freq = Counter(tokens)
        total = len(tokens)
        concepts = [
            word for word, count in freq.most_common(top_n * 2)
            if count / total < 0.5 and len(word) > 3
        ]
        return concepts[:top_n]
    
    @classmethod
    def score_video(cls, query: str, video: Dict) -> Tuple[float, List[str]]:
        query_tokens = set(cls.tokenize(query))
        if not query_tokens:
            return 0.0, []
        
        title = video.get("video_title", "") or video.get("title", "")
        summary = video.get("summary_content", "") or ""
        transcript = video.get("transcript_context", "") or ""
        category = video.get("category", "")
        
        title_tokens = set(cls.tokenize(title))
        summary_tokens = set(cls.tokenize(summary[:3000]))
        transcript_tokens = set(cls.tokenize(transcript[:2000]))
        
        title_score = cls.jaccard_similarity(query_tokens, title_tokens) * 2.5
        summary_score = cls.jaccard_similarity(query_tokens, summary_tokens) * 1.2
        transcript_score = cls.jaccard_similarity(query_tokens, transcript_tokens)
        
        all_video_tokens = list(title_tokens) + list(summary_tokens)
        video_tf = cls.compute_tf(all_video_tokens)
        query_tf = cls.compute_tf(list(query_tokens))
        tf_overlap = sum(query_tf.get(t, 0) * video_tf.get(t, 0) for t in query_tokens)
        
        cat_boost = cls.get_category_boost(query_tokens, category)
        
        raw_score = (
            title_score * 0.30 +
            summary_score * 0.35 +
            transcript_score * 0.15 +
            tf_overlap * 0.20
        )
        
        final_score = min(raw_score * cat_boost, 1.0)
        all_video_terms = title_tokens | summary_tokens
        matched = list(query_tokens & all_video_terms)
        
        return final_score, matched


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ’¾ CACHE INTELLIGENT â€” LRU avec TTL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TTLCache:
    """Cache LRU avec expiration temporelle."""
    
    def __init__(self, max_size: int = 100, ttl_seconds: int = 3600):
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
        self._cache: OrderedDict[str, Tuple[Any, datetime]] = OrderedDict()
    
    def _make_key(self, *args, **kwargs) -> str:
        key_data = json.dumps({"args": args, "kwargs": kwargs}, sort_keys=True, default=str)
        return hashlib.md5(key_data.encode()).hexdigest()[:16]
    
    def get(self, key: str) -> Optional[Any]:
        if key not in self._cache:
            return None
        value, timestamp = self._cache[key]
        if datetime.now() - timestamp > timedelta(seconds=self.ttl_seconds):
            del self._cache[key]
            return None
        self._cache.move_to_end(key)
        return value
    
    def set(self, key: str, value: Any):
        if key in self._cache:
            del self._cache[key]
        elif len(self._cache) >= self.max_size:
            self._cache.popitem(last=False)
        self._cache[key] = (value, datetime.now())
    
    def clear(self):
        self._cache.clear()


_chat_cache = TTLCache(max_size=200, ttl_seconds=1800)
_perplexity_cache = TTLCache(max_size=50, ttl_seconds=3600)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â±ï¸ TIMECODE EXTRACTOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TimecodeExtractor:
    """Extrait et valide les timecodes des transcriptions."""
    
    PATTERN = re.compile(r'[\[\(]?(\d{1,2}):(\d{2})(?::(\d{2}))?[\]\)]?')
    
    @classmethod
    def extract_all(cls, text: str) -> List[Dict[str, Any]]:
        if not text:
            return []
        
        timecodes = []
        for match in cls.PATTERN.finditer(text):
            h, m, s = 0, int(match.group(1)), int(match.group(2))
            if match.group(3):
                h, m, s = int(match.group(1)), int(match.group(2)), int(match.group(3))
            
            total_seconds = h * 3600 + m * 60 + s
            start = max(0, match.start() - 50)
            end = min(len(text), match.end() + 50)
            context = text[start:end].strip()
            
            if h > 0:
                tc_str = f"{h}:{m:02d}:{s:02d}"
            else:
                tc_str = f"{m}:{s:02d}"
            
            timecodes.append({
                "timecode": tc_str,
                "seconds": total_seconds,
                "context": context,
                "position": match.start()
            })
        
        return timecodes
    
    @classmethod
    def find_relevant_timecodes(cls, transcript: str, query: str, max_timecodes: int = 5) -> List[Dict[str, Any]]:
        all_timecodes = cls.extract_all(transcript)
        if not all_timecodes:
            return []
        
        query_tokens = set(SemanticScorer.tokenize(query))
        if not query_tokens:
            return all_timecodes[:max_timecodes]
        
        scored = []
        for tc in all_timecodes:
            context_tokens = set(SemanticScorer.tokenize(tc["context"]))
            score = SemanticScorer.jaccard_similarity(query_tokens, context_tokens)
            scored.append((score, tc))
        
        scored.sort(key=lambda x: x[0], reverse=True)
        return [tc for score, tc in scored[:max_timecodes] if score > 0.05]
    
    @classmethod
    def format_for_response(cls, timecodes: List[Dict], video_id: str = "") -> str:
        if not timecodes:
            return ""
        
        lines = ["**â±ï¸ Passages pertinents:**"]
        for tc in timecodes[:5]:
            if video_id:
                url = f"https://youtube.com/watch?v={video_id}&t={tc['seconds']}"
                lines.append(f"- [{tc['timecode']}]({url})")
            else:
                lines.append(f"- {tc['timecode']}")
        
        return "\n".join(lines)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ ENDPOINTS â€” Analyse playlist et corpus
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.post("/analyze", response_model=PlaylistTaskStatus)
async def analyze_playlist(
    request: AnalyzePlaylistRequest,
    background_tasks: BackgroundTasks,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """Lance l'analyse d'une playlist YouTube."""
    print(f"\n{'='*60}", flush=True)
    print(f"ğŸ“š PLAYLIST ANALYSIS REQUEST", flush=True)
    print(f"   URL: {request.url}", flush=True)
    print(f"   Mode: {request.mode}", flush=True)
    print(f"   User: {current_user.email}", flush=True)
    
    playlist_id = extract_playlist_id(request.url)
    if not playlist_id:
        raise HTTPException(status_code=400, detail="URL de playlist invalide")
    
    plan = current_user.plan or "free"
    max_allowed = PLAN_VIDEO_LIMITS.get(plan, 10)
    max_videos = min(request.max_videos, max_allowed)
    
    if current_user.credits < max_videos:
        raise HTTPException(
            status_code=403,
            detail=f"CrÃ©dits insuffisants ({current_user.credits} disponibles, {max_videos} requis)"
        )
    
    task_id = str(uuid4())
    model = request.model or PLAN_MODELS.get(plan, "mistral-small-latest")
    
    _playlist_task_store[task_id] = {
        "status": "pending",
        "progress": 0,
        "message": "Initialisation...",
        "current_video": 0,
        "total_videos": 0,
        "result": None
    }
    
    background_tasks.add_task(
        _analyze_playlist_background,
        task_id=task_id,
        playlist_id=playlist_id,
        url=request.url,
        max_videos=max_videos,
        mode=request.mode,
        lang=request.lang,
        model=model,
        user_id=current_user.id,
        user_plan=plan
    )
    
    return PlaylistTaskStatus(
        task_id=task_id,
        status="pending",
        message="Analyse lancÃ©e"
    )


@router.get("/task/{task_id}", response_model=PlaylistTaskStatus)
async def get_task_status(task_id: str):
    """RÃ©cupÃ¨re le statut d'une tÃ¢che d'analyse."""
    task = _playlist_task_store.get(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="TÃ¢che non trouvÃ©e")
    
    return PlaylistTaskStatus(
        task_id=task_id,
        status=task["status"],
        progress=task.get("progress", 0),
        message=task.get("message", ""),
        current_video=task.get("current_video", 0),
        total_videos=task.get("total_videos", 0),
        result=task.get("result")
    )


@router.post("/corpus/analyze", response_model=PlaylistTaskStatus)
@router.post("/analyze-corpus", response_model=PlaylistTaskStatus, include_in_schema=False)
async def analyze_corpus(
    request: AnalyzeCorpusRequest,
    background_tasks: BackgroundTasks,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """
    Analyse un corpus personnalisÃ© de vidÃ©os.

    Note: `/analyze-corpus` is an alias for mobile compatibility.
    Preferred path is `/corpus/analyze`.
    """
    print(f"\n{'='*60}", flush=True)
    print(f"ğŸ“¦ CORPUS ANALYSIS REQUEST", flush=True)
    print(f"   Name: {request.name}", flush=True)
    print(f"   Videos: {len(request.urls)}", flush=True)
    
    plan = current_user.plan or "free"
    max_allowed = PLAN_VIDEO_LIMITS.get(plan, 10)
    
    if len(request.urls) > max_allowed:
        raise HTTPException(
            status_code=403,
            detail=f"Maximum {max_allowed} vidÃ©os pour le plan {plan}"
        )
    
    if current_user.credits < len(request.urls):
        raise HTTPException(
            status_code=403,
            detail=f"CrÃ©dits insuffisants ({current_user.credits} disponibles)"
        )
    
    task_id = str(uuid4())
    model = request.model or PLAN_MODELS.get(plan, "mistral-small-latest")
    
    _playlist_task_store[task_id] = {
        "status": "pending",
        "progress": 0,
        "message": "Initialisation du corpus...",
        "current_video": 0,
        "total_videos": len(request.urls),
        "result": None
    }
    
    background_tasks.add_task(
        _analyze_corpus_background,
        task_id=task_id,
        urls=request.urls,
        corpus_name=request.name,
        mode=request.mode,
        lang=request.lang,
        model=model,
        user_id=current_user.id,
        user_plan=plan
    )
    
    return PlaylistTaskStatus(
        task_id=task_id,
        status="pending",
        message="Analyse du corpus lancÃ©e"
    )


@router.get("", response_model=List[Dict])
async def list_playlists(
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """Liste les playlists de l'utilisateur."""
    result = await session.execute(
        select(PlaylistAnalysis)
        .where(PlaylistAnalysis.user_id == current_user.id)
        .order_by(PlaylistAnalysis.created_at.desc())
    )
    playlists = result.scalars().all()
    
    return [
        {
            "id": p.id,
            "playlist_id": p.playlist_id,
            "playlist_title": p.playlist_title,
            "playlist_url": p.playlist_url,
            "num_videos": p.num_videos,
            "num_processed": p.num_processed,
            "total_duration": p.total_duration,
            "total_words": p.total_words,
            "status": p.status,
            "created_at": p.created_at.isoformat() if p.created_at else None,
            "completed_at": p.completed_at.isoformat() if p.completed_at else None
        }
        for p in playlists
    ]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• CRUD PLAYLISTS â€” CrÃ©er et modifier des playlists manuellement
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class CreatePlaylistRequest(BaseModel):
    """RequÃªte pour crÃ©er une playlist manuellement"""
    name: str = Field(..., min_length=1, max_length=200)
    description: Optional[str] = None
    video_ids: Optional[List[int]] = None  # IDs de summaries existants Ã  ajouter


class UpdatePlaylistRequest(BaseModel):
    """RequÃªte pour mettre Ã  jour une playlist"""
    name: Optional[str] = Field(None, min_length=1, max_length=200)
    description: Optional[str] = None
    add_video_ids: Optional[List[int]] = None
    remove_video_ids: Optional[List[int]] = None


@router.post("", response_model=Dict)
async def create_playlist(
    request: CreatePlaylistRequest,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """
    ğŸ†• CrÃ©e une nouvelle playlist/corpus manuellement.

    Permet de regrouper des vidÃ©os dÃ©jÃ  analysÃ©es dans une collection personnalisÃ©e.
    """
    # VÃ©rifier les permissions du plan
    plan = current_user.plan or "free"
    plan_limits = PLAN_LIMITS.get(plan, PLAN_LIMITS["free"])

    if not plan_limits.get("can_use_playlists", False):
        raise HTTPException(
            status_code=403,
            detail={
                "code": "plan_required",
                "message": "Les playlists nÃ©cessitent un plan Starter ou supÃ©rieur",
                "upgrade_url": "/upgrade"
            }
        )

    # GÃ©nÃ©rer un ID unique pour la playlist
    playlist_id = f"custom_{uuid4().hex[:12]}"

    # CrÃ©er la playlist
    playlist = PlaylistAnalysis(
        user_id=current_user.id,
        playlist_id=playlist_id,
        playlist_title=request.name,
        playlist_url=None,  # Playlist manuelle, pas d'URL YouTube
        num_videos=0,
        status="created",
        started_at=datetime.utcnow(),
        completed_at=datetime.utcnow()
    )
    session.add(playlist)
    await session.flush()  # Pour obtenir l'ID

    # Ajouter des vidÃ©os existantes si spÃ©cifiÃ©es
    videos_added = 0
    if request.video_ids:
        for position, summary_id in enumerate(request.video_ids, 1):
            # VÃ©rifier que le summary appartient Ã  l'utilisateur
            summary_result = await session.execute(
                select(Summary)
                .where(Summary.id == summary_id)
                .where(Summary.user_id == current_user.id)
            )
            summary = summary_result.scalar_one_or_none()

            if summary:
                # Mettre Ã  jour le summary pour l'associer Ã  cette playlist
                summary.playlist_id = playlist_id
                summary.playlist_position = position
                videos_added += 1

        playlist.num_videos = videos_added
        playlist.num_processed = videos_added

    await session.commit()

    print(f"ğŸ“š Created playlist '{request.name}' with {videos_added} videos for user {current_user.id}", flush=True)

    return {
        "id": playlist.id,
        "playlist_id": playlist_id,
        "playlist_title": request.name,
        "num_videos": videos_added,
        "status": "created",
        "created_at": playlist.started_at.isoformat()
    }


@router.put("/{playlist_id}")
async def update_playlist(
    playlist_id: str,
    request: UpdatePlaylistRequest,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """
    ğŸ†• Met Ã  jour une playlist existante.

    Permet de:
    - Renommer la playlist
    - Ajouter des vidÃ©os
    - Retirer des vidÃ©os
    """
    # RÃ©cupÃ©rer la playlist
    result = await session.execute(
        select(PlaylistAnalysis)
        .where(PlaylistAnalysis.playlist_id == playlist_id)
        .where(PlaylistAnalysis.user_id == current_user.id)
        .order_by(PlaylistAnalysis.created_at.desc())
        .limit(1)
    )
    playlist = result.scalar_one_or_none()

    if not playlist:
        raise HTTPException(status_code=404, detail="Playlist non trouvÃ©e")

    # Mettre Ã  jour le nom si fourni
    if request.name is not None:
        playlist.playlist_title = request.name

    # Ajouter des vidÃ©os
    if request.add_video_ids:
        # RÃ©cupÃ©rer la position max actuelle
        max_pos_result = await session.execute(
            select(func.max(Summary.playlist_position))
            .where(Summary.playlist_id == playlist_id)
        )
        max_pos = max_pos_result.scalar() or 0

        for summary_id in request.add_video_ids:
            summary_result = await session.execute(
                select(Summary)
                .where(Summary.id == summary_id)
                .where(Summary.user_id == current_user.id)
            )
            summary = summary_result.scalar_one_or_none()

            if summary and summary.playlist_id != playlist_id:
                max_pos += 1
                summary.playlist_id = playlist_id
                summary.playlist_position = max_pos

    # Retirer des vidÃ©os
    if request.remove_video_ids:
        for summary_id in request.remove_video_ids:
            summary_result = await session.execute(
                select(Summary)
                .where(Summary.id == summary_id)
                .where(Summary.playlist_id == playlist_id)
            )
            summary = summary_result.scalar_one_or_none()

            if summary:
                summary.playlist_id = None
                summary.playlist_position = None

    # Recalculer le nombre de vidÃ©os
    count_result = await session.execute(
        select(func.count(Summary.id))
        .where(Summary.playlist_id == playlist_id)
    )
    playlist.num_videos = count_result.scalar() or 0
    playlist.num_processed = playlist.num_videos

    await session.commit()

    print(f"ğŸ“š Updated playlist '{playlist.playlist_title}' (now {playlist.num_videos} videos)", flush=True)

    return {
        "id": playlist.id,
        "playlist_id": playlist_id,
        "playlist_title": playlist.playlist_title,
        "num_videos": playlist.num_videos,
        "status": playlist.status,
        "updated": True
    }


@router.get("/{playlist_id}")
async def get_playlist(
    playlist_id: str,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """RÃ©cupÃ¨re une playlist avec ses vidÃ©os."""
    # FIX v4.1: Prendre la plus rÃ©cente si plusieurs analyses existent
    result = await session.execute(
        select(PlaylistAnalysis)
        .where(PlaylistAnalysis.playlist_id == playlist_id)
        .where(PlaylistAnalysis.user_id == current_user.id)
        .order_by(PlaylistAnalysis.created_at.desc())
        .limit(1)
    )
    playlist = result.scalar_one_or_none()
    
    if not playlist:
        raise HTTPException(status_code=404, detail="Playlist non trouvÃ©e")
    
    # RÃ©cupÃ©rer les vidÃ©os
    videos_result = await session.execute(
        select(Summary)
        .where(Summary.playlist_id == playlist_id)
        .where(Summary.user_id == current_user.id)
        .order_by(Summary.playlist_position)
    )
    videos = videos_result.scalars().all()
    
    return {
        "id": playlist.id,
        "playlist_id": playlist.playlist_id,
        "playlist_title": playlist.playlist_title,
        "playlist_url": playlist.playlist_url,
        "num_videos": playlist.num_videos,
        "num_processed": playlist.num_processed,
        "total_duration": playlist.total_duration,
        "total_words": playlist.total_words,
        "meta_analysis": playlist.meta_analysis,
        "status": playlist.status,
        "created_at": playlist.created_at.isoformat() if playlist.created_at else None,
        "videos": [
            {
                "id": v.id,
                "video_id": v.video_id,
                "video_title": v.video_title,
                "video_channel": v.video_channel,
                "video_duration": v.video_duration,
                "video_url": v.video_url,
                "thumbnail_url": v.thumbnail_url,
                "category": v.category,
                "summary_content": v.summary_content,
                "transcript_context": v.transcript_context,
                "word_count": v.word_count,
                "position": v.playlist_position
            }
            for v in videos
        ]
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š PLAYLIST DETAILS â€” Statistiques dÃ©taillÃ©es (P1 mobile compatibility)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.get("/{playlist_id}/details")
async def get_playlist_details(
    playlist_id: str,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """
    RÃ©cupÃ¨re les dÃ©tails et statistiques d'une playlist.

    Mobile-compatible endpoint providing detailed analytics.
    """
    # RÃ©cupÃ©rer la playlist
    result = await session.execute(
        select(PlaylistAnalysis)
        .where(PlaylistAnalysis.playlist_id == playlist_id)
        .where(PlaylistAnalysis.user_id == current_user.id)
        .order_by(PlaylistAnalysis.created_at.desc())
        .limit(1)
    )
    playlist = result.scalar_one_or_none()

    if not playlist:
        raise HTTPException(status_code=404, detail="Playlist non trouvÃ©e")

    # RÃ©cupÃ©rer les vidÃ©os pour les statistiques
    videos_result = await session.execute(
        select(Summary)
        .where(Summary.playlist_id == playlist_id)
        .where(Summary.user_id == current_user.id)
        .order_by(Summary.playlist_position)
    )
    videos = videos_result.scalars().all()

    # Calculer les statistiques
    categories = {}
    channels = {}
    total_duration = 0
    total_words = 0

    for v in videos:
        # CatÃ©gories
        cat = v.category or "Autre"
        categories[cat] = categories.get(cat, 0) + 1

        # ChaÃ®nes
        ch = v.video_channel or "Inconnu"
        channels[ch] = channels.get(ch, 0) + 1

        # Totaux
        total_duration += v.video_duration or 0
        total_words += v.word_count or 0

    # Formater la durÃ©e
    hours = total_duration // 3600
    minutes = (total_duration % 3600) // 60
    duration_str = f"{hours}h {minutes}min" if hours > 0 else f"{minutes} min"

    return {
        "id": playlist.id,
        "playlist_id": playlist_id,
        "playlist_title": playlist.playlist_title,
        "playlist_url": playlist.playlist_url,
        "status": playlist.status,
        "created_at": playlist.created_at.isoformat() if playlist.created_at else None,
        "completed_at": playlist.completed_at.isoformat() if playlist.completed_at else None,
        "statistics": {
            "num_videos": len(videos),
            "num_processed": playlist.num_processed or len(videos),
            "total_duration": total_duration,
            "total_duration_formatted": duration_str,
            "total_words": total_words,
            "average_duration": total_duration // len(videos) if videos else 0,
            "average_words": total_words // len(videos) if videos else 0
        },
        "categories": categories,
        "channels": channels,
        "has_meta_analysis": bool(playlist.meta_analysis),
        "videos_summary": [
            {
                "id": v.id,
                "title": v.video_title,
                "channel": v.video_channel,
                "duration": v.video_duration,
                "category": v.category,
                "position": v.playlist_position
            }
            for v in videos
        ]
    }


@router.post("/{playlist_id}/corpus-summary")
async def generate_corpus_summary(
    playlist_id: str,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """
    GÃ©nÃ¨re ou rÃ©gÃ©nÃ¨re la mÃ©ta-analyse (corpus summary) d'une playlist.

    Utile si la mÃ©ta-analyse initiale a Ã©chouÃ© ou pour la mettre Ã  jour.
    """
    # RÃ©cupÃ©rer la playlist
    result = await session.execute(
        select(PlaylistAnalysis)
        .where(PlaylistAnalysis.playlist_id == playlist_id)
        .where(PlaylistAnalysis.user_id == current_user.id)
        .order_by(PlaylistAnalysis.created_at.desc())
        .limit(1)
    )
    playlist = result.scalar_one_or_none()

    if not playlist:
        raise HTTPException(status_code=404, detail="Playlist non trouvÃ©e")

    # VÃ©rifier les crÃ©dits (1 crÃ©dit pour rÃ©gÃ©nÃ©rer)
    if current_user.credits < 1:
        raise HTTPException(status_code=402, detail="CrÃ©dits insuffisants")

    # RÃ©cupÃ©rer les vidÃ©os
    videos_result = await session.execute(
        select(Summary)
        .where(Summary.playlist_id == playlist_id)
        .where(Summary.user_id == current_user.id)
        .order_by(Summary.playlist_position)
    )
    videos = videos_result.scalars().all()

    if not videos:
        raise HTTPException(status_code=400, detail="Aucune vidÃ©o dans cette playlist")

    # PrÃ©parer les donnÃ©es pour la mÃ©ta-analyse
    summaries = []
    for v in videos:
        summaries.append({
            "position": v.playlist_position or 0,
            "title": v.video_title or "Sans titre",
            "channel": v.video_channel or "Inconnu",
            "summary": (v.summary_content or "")[:2000],
            "category": v.category or "Autre",
            "duration": v.video_duration or 0,
            "word_count": v.word_count or 0
        })

    # GÃ©nÃ©rer la mÃ©ta-analyse
    plan = current_user.plan or "free"
    model = PLAN_MODELS.get(plan, "mistral-small-latest")
    lang = videos[0].lang if videos else "fr"

    meta_analysis = await _generate_meta_analysis_v4(
        summaries=summaries,
        playlist_title=playlist.playlist_title or "Corpus",
        lang=lang,
        model=model
    )

    # Mettre Ã  jour la playlist
    playlist.meta_analysis = meta_analysis

    # DÃ©duire 1 crÃ©dit
    current_user.credits -= 1

    await session.commit()

    return {
        "success": True,
        "playlist_id": playlist_id,
        "meta_analysis": meta_analysis,
        "credits_remaining": current_user.credits
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“¹ GET VIDEO SUMMARY â€” RÃ©cupÃ¨re le rÃ©sumÃ© d'une vidÃ©o du corpus (FIX v4.1)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.get("/{playlist_id}/video/{summary_id}")
async def get_video_summary(
    playlist_id: str,
    summary_id: int,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """
    RÃ©cupÃ¨re le rÃ©sumÃ© complet d'une vidÃ©o spÃ©cifique dans une playlist.
    
    FIX v4.1: Cet endpoint Ã©tait manquant et causait des erreurs 404
    quand l'utilisateur cliquait sur "RÃ©sumÃ© VidÃ©o".
    """
    print(f"ğŸ“¹ GET VIDEO SUMMARY: playlist={playlist_id}, summary={summary_id}", flush=True)
    
    # VÃ©rifier que la playlist appartient Ã  l'utilisateur
    playlist_result = await session.execute(
        select(PlaylistAnalysis)
        .where(PlaylistAnalysis.playlist_id == playlist_id)
        .where(PlaylistAnalysis.user_id == current_user.id)
        .order_by(PlaylistAnalysis.created_at.desc())
        .limit(1)
    )
    playlist = playlist_result.scalar_one_or_none()
    
    if not playlist:
        raise HTTPException(status_code=404, detail="Playlist non trouvÃ©e")
    
    # RÃ©cupÃ©rer le rÃ©sumÃ© de la vidÃ©o
    video_result = await session.execute(
        select(Summary)
        .where(Summary.id == summary_id)
        .where(Summary.playlist_id == playlist_id)
        .where(Summary.user_id == current_user.id)
    )
    video = video_result.scalar_one_or_none()
    
    if not video:
        raise HTTPException(status_code=404, detail="VidÃ©o non trouvÃ©e dans ce corpus")
    
    print(f"   âœ… Found: {video.video_title[:50]}...", flush=True)
    
    return {
        "id": video.id,
        "video_id": video.video_id,
        "video_title": video.video_title,
        "video_channel": video.video_channel,
        "video_duration": video.video_duration,
        "video_url": video.video_url,
        "thumbnail_url": video.thumbnail_url,
        "category": video.category,
        "mode": video.mode,
        "lang": video.lang,
        "summary_content": video.summary_content,
        "transcript_context": video.transcript_context,
        "word_count": video.word_count,
        "reliability_score": video.reliability_score,
        "position": video.playlist_position,
        "created_at": video.created_at.isoformat() if video.created_at else None,
        "playlist_id": video.playlist_id,
        "playlist_title": playlist.playlist_title
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§  CHAT CORPUS â€” Endpoint principal avec scoring sÃ©mantique
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.post("/{playlist_id}/chat", response_model=ChatCorpusResponse)
async def chat_with_corpus(
    playlist_id: str,
    request: ChatCorpusRequest,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """
    Chat IA avec le corpus complet.
    
    Features v4.0:
    - Scoring sÃ©mantique pour sÃ©lection contextuelle des vidÃ©os
    - Allocation dynamique de tokens selon pertinence
    - Cache intelligent des rÃ©ponses
    - Fusion Mistral + Perplexity
    """
    print(f"\n{'='*60}", flush=True)
    print(f"ğŸ’¬ CORPUS CHAT v4.0", flush=True)
    print(f"   Playlist: {playlist_id}", flush=True)
    print(f"   Question: {request.message[:80]}...", flush=True)
    print(f"   Mode: {request.mode} | Web: {request.web_search}", flush=True)
    
    # FIX v4.1: Prendre la plus rÃ©cente si plusieurs analyses existent
    result = await session.execute(
        select(PlaylistAnalysis)
        .where(PlaylistAnalysis.playlist_id == playlist_id)
        .where(PlaylistAnalysis.user_id == current_user.id)
        .order_by(PlaylistAnalysis.created_at.desc())
        .limit(1)
    )
    playlist = result.scalar_one_or_none()
    
    if not playlist:
        raise HTTPException(status_code=404, detail="Playlist non trouvÃ©e")
    
    plan = current_user.plan or "free"
    chat_config = CHAT_CONFIG.get(plan, CHAT_CONFIG["free"])
    mode_config = MODE_CONFIG.get(request.mode, MODE_CONFIG["standard"])
    
    web_search_enabled = request.web_search and chat_config["web_search"]
    
    videos_result = await session.execute(
        select(Summary)
        .where(Summary.playlist_id == playlist_id)
        .where(Summary.user_id == current_user.id)
        .order_by(Summary.playlist_position)
    )
    videos = videos_result.scalars().all()
    
    if not videos:
        raise HTTPException(status_code=404, detail="Aucune vidÃ©o dans ce corpus")
    
    videos_data = [
        {
            "position": v.playlist_position,
            "video_id": v.video_id,
            "video_title": v.video_title,
            "video_channel": v.video_channel,
            "category": v.category,
            "summary_content": v.summary_content,
            "transcript_context": v.transcript_context,
            "video_duration": v.video_duration
        }
        for v in videos
    ]
    
    scored_videos = []
    for v in videos_data:
        score, matched_terms = SemanticScorer.score_video(request.message, v)
        scored_videos.append({
            **v,
            "relevance_score": score,
            "matched_terms": matched_terms
        })
    
    scored_videos.sort(key=lambda x: x["relevance_score"], reverse=True)
    
    print(f"   ğŸ“Š Relevance scores:", flush=True)
    for sv in scored_videos[:5]:
        print(f"      - {sv['video_title'][:40]}: {sv['relevance_score']:.3f}", flush=True)
    
    history_result = await session.execute(
        select(PlaylistChatMessage)
        .where(PlaylistChatMessage.playlist_id == playlist_id)
        .where(PlaylistChatMessage.user_id == current_user.id)
        .order_by(PlaylistChatMessage.created_at.desc())
        .limit(10)
    )
    chat_history = [
        {"role": m.role, "content": m.content}
        for m in reversed(history_result.scalars().all())
    ]
    
    categories = [v["category"] for v in videos_data if v.get("category")]
    dominant_category = Counter(categories).most_common(1)[0][0] if categories else None
    
    cache_key = _chat_cache._make_key(
        playlist_id, request.message, request.mode, web_search_enabled
    )
    cached_response = _chat_cache.get(cache_key)
    if cached_response:
        print(f"   âœ… Cache HIT!", flush=True)
        return ChatCorpusResponse(
            response=cached_response["response"],
            sources=cached_response.get("sources"),
            model_used=cached_response.get("model_used", "cache"),
            relevance_scores={
                sv["video_title"]: sv["relevance_score"] 
                for sv in scored_videos[:5]
            }
        )
    
    sources = []
    perplexity_context = ""
    web_search_actually_used = False
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ§  DÃ‰TECTION INTELLIGENTE â€” Utiliser Perplexity seulement quand c'est utile
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    should_use_perplexity = False
    perplexity_reason = "none"
    
    if web_search_enabled:
        # Importer la dÃ©tection intelligente
        try:
            from videos.web_enrichment import needs_web_search_for_chat
            should_search, trigger_reason = needs_web_search_for_chat(
                request.message, 
                playlist.playlist_title
            )
            if should_search:
                should_use_perplexity = True
                perplexity_reason = trigger_reason
                print(f"   ğŸ§  Perplexity auto-triggered: {trigger_reason}", flush=True)
        except ImportError:
            # Fallback: utiliser si demandÃ© explicitement
            should_use_perplexity = True
            perplexity_reason = "explicit_request"
        
        # Questions courtes et simples = pas besoin de Perplexity
        word_count = len(request.message.split())
        question_lower = request.message.lower()
        
        # Ne PAS utiliser Perplexity pour les questions de synthÃ¨se du corpus
        CORPUS_ONLY_PATTERNS = [
            "rÃ©sume", "synthÃ¨se", "principaux points", "qu'est-ce qui est dit",
            "que disent les vidÃ©os", "compare les vidÃ©os", "consensus",
            "summarize", "main points", "what do the videos say"
        ]
        
        is_corpus_question = any(p in question_lower for p in CORPUS_ONLY_PATTERNS)
        
        if is_corpus_question:
            should_use_perplexity = False
            perplexity_reason = "corpus_only_question"
            print(f"   â­ï¸ Perplexity skipped: corpus-only question", flush=True)
        elif word_count < 5 and not should_use_perplexity:
            should_use_perplexity = False
            perplexity_reason = "too_short"
            print(f"   â­ï¸ Perplexity skipped: question too short", flush=True)
    
    # ExÃ©cuter Perplexity si dÃ©cidÃ©
    if should_use_perplexity:
        perplexity_result = await _perplexity_chat_corpus_v4(
            question=request.message,
            playlist_title=playlist.playlist_title,
            dominant_category=dominant_category
        )
        if perplexity_result:
            perplexity_context = perplexity_result.get("answer", "")
            sources = perplexity_result.get("sources", [])
            web_search_actually_used = True
            print(f"   ğŸŒ Perplexity: {len(perplexity_context)} chars ({perplexity_reason})", flush=True)
    elif web_search_enabled:
        print(f"   ğŸ’¡ Perplexity available but not needed for this question", flush=True)
    
    response_text = await _chat_with_mistral_corpus_v4(
        question=request.message,
        videos=scored_videos,
        playlist_title=playlist.playlist_title,
        meta_analysis=playlist.meta_analysis,
        chat_history=chat_history,
        chat_config=chat_config,
        mode_config=mode_config,
        mode=request.mode,
        dominant_category=dominant_category,
        perplexity_context=perplexity_context,
        lang=request.lang
    )
    
    model_used = chat_config["model"]
    
    volatile_disclaimer = _detect_volatile_disclaimer(
        question=request.message,
        playlist_title=playlist.playlist_title,
        dominant_category=dominant_category,
        lang=request.lang
    )
    if volatile_disclaimer:
        response_text += f"\n\n---\n{volatile_disclaimer}"
        if not web_search_enabled and chat_config["web_search"]:
            if request.lang == "en":
                response_text += "\n\nğŸ’¡ *Enable ğŸŒ Web Search to verify current information.*"
            else:
                response_text += "\n\nğŸ’¡ *Activez ğŸŒ Recherche Web pour vÃ©rifier les informations actuelles.*"
    
    _chat_cache.set(cache_key, {
        "response": response_text,
        "sources": sources,
        "model_used": model_used
    })
    
    session.add(PlaylistChatMessage(
        user_id=current_user.id,
        playlist_id=playlist_id,
        role="user",
        content=request.message
    ))
    session.add(PlaylistChatMessage(
        user_id=current_user.id,
        playlist_id=playlist_id,
        role="assistant",
        content=response_text
    ))
    await session.commit()
    
    print(f"   âœ… Response: {len(response_text)} chars", flush=True)
    
    return ChatCorpusResponse(
        response=response_text,
        sources=sources,
        model_used=model_used,
        relevance_scores={
            sv["video_title"]: round(sv["relevance_score"], 3)
            for sv in scored_videos[:5]
        }
    )


@router.get("/{playlist_id}/chat/history")
async def get_chat_history(
    playlist_id: str,
    limit: int = Query(default=50, ge=1, le=100),
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """Historique du chat."""
    result = await session.execute(
        select(PlaylistChatMessage)
        .where(PlaylistChatMessage.playlist_id == playlist_id)
        .where(PlaylistChatMessage.user_id == current_user.id)
        .order_by(PlaylistChatMessage.created_at.desc())
        .limit(limit)
    )
    messages = result.scalars().all()
    
    return {
        "messages": [
            {
                "id": m.id,
                "role": m.role,
                "content": m.content,
                "created_at": m.created_at.isoformat() if m.created_at else None
            }
            for m in reversed(messages)
        ]
    }


@router.delete("/{playlist_id}/chat")
async def clear_chat_history(
    playlist_id: str,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """Efface le chat et invalide le cache."""
    await session.execute(
        delete(PlaylistChatMessage)
        .where(PlaylistChatMessage.playlist_id == playlist_id)
        .where(PlaylistChatMessage.user_id == current_user.id)
    )
    await session.commit()
    
    return {"success": True}


@router.delete("/{playlist_id}")
async def delete_playlist(
    playlist_id: str,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """Supprime une playlist."""
    await session.execute(
        delete(PlaylistChatMessage)
        .where(PlaylistChatMessage.playlist_id == playlist_id)
        .where(PlaylistChatMessage.user_id == current_user.id)
    )
    await session.execute(
        delete(Summary)
        .where(Summary.playlist_id == playlist_id)
        .where(Summary.user_id == current_user.id)
    )
    await session.execute(
        delete(PlaylistAnalysis)
        .where(PlaylistAnalysis.playlist_id == playlist_id)
        .where(PlaylistAnalysis.user_id == current_user.id)
    )
    await session.commit()
    return {"success": True}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§  CHAT MISTRAL v4.0 â€” Contexte optimisÃ© avec allocation dynamique
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def _chat_with_mistral_corpus_v4(
    question: str,
    videos: List[Dict],
    playlist_title: str,
    meta_analysis: str,
    chat_history: List[Dict],
    chat_config: Dict,
    mode_config: Dict,
    mode: str,
    dominant_category: str,
    perplexity_context: str = "",
    lang: str = "fr"
) -> str:
    """Chat Mistral v4.1 avec rÃ©ponses INTELLIGENTES et ADAPTÃ‰ES."""
    api_key = get_mistral_key()
    if not api_key:
        return "âŒ ClÃ© API Mistral non configurÃ©e."
    
    if not videos:
        return "âŒ Aucune vidÃ©o dans ce corpus."
    
    model = chat_config["model"]
    max_corpus = chat_config["max_corpus"]
    max_videos_limit = chat_config["max_videos"]
    max_tokens = mode_config["max_tokens"]
    num_segments = mode_config["num_segments"]
    timecode_min = mode_config["timecode_min"]
    style_rule = mode_config["style_fr"] if lang == "fr" else mode_config["style_en"]
    
    print(f"[CHAT v4.1] ğŸ¤– Model: {model} | Videos: {len(videos)} | Mode: {mode}", flush=True)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ§  DÃ‰TECTION INTELLIGENTE DU TYPE DE QUESTION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    question_lower = question.lower().strip()
    
    FACTUAL_PATTERNS = [
        "c'est quoi", "qu'est-ce que", "qui est", "combien", "quand", "oÃ¹",
        "what is", "who is", "how many", "when", "where", "define",
        "quelle est", "quel est", "donne-moi", "cite", "liste", "Ã©numÃ¨re"
    ]
    
    SUMMARY_PATTERNS = [
        "rÃ©sume", "rÃ©sumÃ©", "synthÃ¨se", "en bref", "principaux points",
        "summarize", "summary", "main points", "key takeaways", "tldr",
        "bullet points", "grandes lignes", "idÃ©es principales", "essentiel"
    ]
    
    YES_NO_PATTERNS = [
        "est-ce que", "est-il", "peut-on", "y a-t-il", "faut-il",
        "is it", "does it", "can we", "should", "is there", "are there"
    ]
    
    COMPARISON_PATTERNS = [
        "compare", "diffÃ©rence", "similaire", "commun", "diverge", "oppose",
        "difference", "similar", "common", "vs", "versus", "par rapport"
    ]
    
    OPINION_PATTERNS = [
        "que penses", "ton avis", "conseille", "recommande", "meilleur",
        "what do you think", "your opinion", "recommend", "best", "should i"
    ]
    
    is_factual = any(p in question_lower for p in FACTUAL_PATTERNS)
    is_summary = any(p in question_lower for p in SUMMARY_PATTERNS)
    is_yes_no = any(p in question_lower for p in YES_NO_PATTERNS)
    is_comparison = any(p in question_lower for p in COMPARISON_PATTERNS)
    is_opinion = any(p in question_lower for p in OPINION_PATTERNS)
    word_count = len(question.split())
    is_short_question = word_count < 8
    
    # ğŸ†• v4.2: Instructions bilingues selon le type de question
    if lang == "fr":
        if is_yes_no:
            response_instruction = """ğŸ¯ QUESTION OUI/NON DÃ‰TECTÃ‰E
â†’ Commence IMMÃ‰DIATEMENT par "Oui" ou "Non" ou "Partiellement"
â†’ Puis justifie en 1-2 phrases avec rÃ©fÃ©rences vidÃ©os
â†’ PAS de prÃ©ambule, PAS de "c'est une bonne question" """
            adaptive_max_tokens = min(max_tokens, 600)
        elif is_factual and is_short_question:
            response_instruction = """ğŸ¯ QUESTION FACTUELLE SIMPLE DÃ‰TECTÃ‰E
â†’ RÃ©ponse DIRECTE en 1-3 phrases maximum
â†’ Cite la/les vidÃ©o(s) source avec timecode
â†’ PAS de dÃ©veloppement non demandÃ©"""
            adaptive_max_tokens = min(max_tokens, 500)
        elif is_summary:
            response_instruction = """ğŸ¯ DEMANDE DE SYNTHÃˆSE DÃ‰TECTÃ‰E
â†’ Liste Ã  puces concise (4-6 points max)
â†’ Chaque point = 1 phrase + rÃ©fÃ©rence vidÃ©o
â†’ Structure claire, pas de prose"""
            adaptive_max_tokens = min(max_tokens, 1200)
        elif is_comparison:
            response_instruction = """ğŸ¯ QUESTION COMPARATIVE DÃ‰TECTÃ‰E
â†’ Structure: Points communs | DiffÃ©rences | Conclusion
â†’ Cite les vidÃ©os qui soutiennent chaque point
â†’ Tableau mental: VidÃ©o X dit A, VidÃ©o Y dit B"""
            adaptive_max_tokens = max_tokens
        elif is_opinion:
            response_instruction = """ğŸ¯ DEMANDE D'AVIS DÃ‰TECTÃ‰E
â†’ Base-toi sur le CONSENSUS du corpus si prÃ©sent
â†’ Mentionne les diffÃ©rents points de vue des vidÃ©os
â†’ Conclus par une synthÃ¨se Ã©quilibrÃ©e"""
            adaptive_max_tokens = max_tokens
        else:
            response_instruction = """ğŸ¯ QUESTION STANDARD
â†’ Adapte la longueur Ã  la complexitÃ© de la question
â†’ Question simple (< 10 mots) = rÃ©ponse courte
â†’ Question complexe = rÃ©ponse dÃ©veloppÃ©e mais ciblÃ©e"""
            adaptive_max_tokens = max_tokens if word_count > 12 else min(max_tokens, 1000)
    else:  # English
        if is_yes_no:
            response_instruction = """ğŸ¯ YES/NO QUESTION DETECTED
â†’ Start IMMEDIATELY with "Yes" or "No" or "Partially"
â†’ Then justify in 1-2 sentences with video references
â†’ NO preamble, NO "that's a good question" """
            adaptive_max_tokens = min(max_tokens, 600)
        elif is_factual and is_short_question:
            response_instruction = """ğŸ¯ SIMPLE FACTUAL QUESTION DETECTED
â†’ DIRECT answer in 1-3 sentences maximum
â†’ Cite the source video(s) with timecode
â†’ NO unnecessary elaboration"""
            adaptive_max_tokens = min(max_tokens, 500)
        elif is_summary:
            response_instruction = """ğŸ¯ SUMMARY REQUEST DETECTED
â†’ Concise bullet list (4-6 points max)
â†’ Each point = 1 sentence + video reference
â†’ Clear structure, no prose"""
            adaptive_max_tokens = min(max_tokens, 1200)
        elif is_comparison:
            response_instruction = """ğŸ¯ COMPARISON QUESTION DETECTED
â†’ Structure: Common points | Differences | Conclusion
â†’ Cite videos supporting each point
â†’ Mental table: Video X says A, Video Y says B"""
            adaptive_max_tokens = max_tokens
        elif is_opinion:
            response_instruction = """ğŸ¯ OPINION REQUEST DETECTED
â†’ Base on corpus CONSENSUS if present
â†’ Mention different viewpoints from videos
â†’ Conclude with balanced synthesis"""
            adaptive_max_tokens = max_tokens
        else:
            response_instruction = """ğŸ¯ STANDARD QUESTION
â†’ Adapt length to question complexity
â†’ Simple question (< 10 words) = short answer
â†’ Complex question = developed but focused answer"""
            adaptive_max_tokens = max_tokens if word_count > 12 else min(max_tokens, 1000)
    
    history_text = ""
    if chat_history:
        for msg in chat_history[-4:]:
            role = "Utilisateur" if msg.get("role") == "user" else "Assistant"
            history_text += f"\n{role}: {msg.get('content', '')}"
    
    max_videos = min(len(videos), max_videos_limit)
    
    total_relevance = sum(v.get("relevance_score", 0.1) for v in videos[:max_videos])
    if total_relevance == 0:
        total_relevance = max_videos * 0.1
    
    reserved_chars = 6000
    available_corpus = max_corpus - reserved_chars
    
    corpus_text = ""
    
    if meta_analysis:
        corpus_text += f"\nâ•â•â• ğŸ“Š MÃ‰TA-ANALYSE DU CORPUS â•â•â•\n{meta_analysis[:4000]}\n"
    
    if perplexity_context:
        corpus_text += f"\nâ•â•â• ğŸŒ INFORMATIONS WEB RÃ‰CENTES â•â•â•\n{perplexity_context[:2000]}\n"
    
    for v in videos[:max_videos]:
        relevance = v.get("relevance_score", 0.1)
        position = v.get("position", 0)
        title = v.get("video_title", f"VidÃ©o {position}")
        video_id = v.get("video_id", "")
        summary = v.get("summary_content", "") or ""
        transcript = v.get("transcript_context", "") or ""
        matched_terms = v.get("matched_terms", [])
        
        weight = relevance / total_relevance
        allocated_chars = max(3000, min(15000, int(available_corpus * weight)))
        
        video_section = f"\n\nâ•â•â• VIDÃ‰O {position}: {title} (ID: {video_id}) â•â•â•\n"
        video_section += f"ğŸ“Š Pertinence: {relevance:.2f}"
        if matched_terms:
            video_section += f" | Termes: {', '.join(matched_terms[:5])}"
        video_section += "\n"
        
        if summary:
            max_summary = min(len(summary), int(allocated_chars * 0.4))
            video_section += f"ğŸ“‹ RÃ‰SUMÃ‰:\n{summary[:max_summary]}\n"
        
        if transcript:
            remaining_chars = allocated_chars - len(video_section)
            if remaining_chars > 500:
                if len(transcript) <= remaining_chars:
                    video_section += f"ğŸ“ TRANSCRIPTION:\n{transcript}\n"
                else:
                    seg_size = remaining_chars // num_segments
                    video_section += f"ğŸ“ TRANSCRIPTION ({len(transcript):,} chars, segmentÃ©e):\n"
                    
                    if relevance > 0.5:
                        video_section += f"[DÃ‰BUT] {transcript[:seg_size*2]}\n[...]\n"
                        mid = len(transcript) // 2
                        video_section += f"[MILIEU] {transcript[mid:mid+seg_size]}\n"
                    else:
                        positions = [i / (num_segments - 1) for i in range(num_segments)]
                        for pos in positions:
                            start = int(pos * (len(transcript) - seg_size))
                            video_section += f"{transcript[start:start+seg_size]}\n[...]\n"
        
        corpus_text += video_section
    
    total_chars = len(corpus_text)
    print(f"[CHAT v4.2] ğŸ“Š Corpus: {max_videos} videos, {total_chars:,} chars | Adaptive tokens: {adaptive_max_tokens} | Lang: {lang}", flush=True)

    # ğŸ†• v4.2: System prompt bilingue
    if lang == "fr":
        system_prompt = f"""Tu es l'assistant IA de DeepSight, expert en analyse de corpus vidÃ©o. Tu rÃ©ponds de maniÃ¨re naturelle et conversationnelle, comme un ami intelligent.

ğŸ“š Corpus : "{playlist_title}" ({len(videos)} vidÃ©os)

{response_instruction}

RÃˆGLES :
- Sois concis et direct, pas de prÃ©ambules ("Bien sÃ»r", "Excellente question")
- Pas de formules de fin ("N'hÃ©sitez pas", "J'espÃ¨re que Ã§a aide")
- Adapte ta longueur : question courte = rÃ©ponse courte
- Cite les vidÃ©os : "VidÃ©o 3 (5:23)" ou "Dans la vidÃ©o 2..."
- Si l'info n'est pas dans le corpus, dis-le simplement
- Utilise 1-2 Ã©mojis max pour garder le chat vivant
- Cite au moins {timecode_min} vidÃ©os avec timecodes

Ã‰VALUATION (mode {mode}) : Distingue fait/opinion/hypothÃ¨se. Note consensus et divergences. âœ… Solide | âš–ï¸ Plausible | â“ Incertain

ğŸŒ RÃ©ponds uniquement en franÃ§ais.
"""
        final_instruction = "RÃ‰PONDS DIRECTEMENT (premiÃ¨re phrase = dÃ©but de la rÃ©ponse):"
    else:  # English
        system_prompt = f"""You are DeepSight's AI assistant, an expert in video corpus analysis. You respond naturally and conversationally, like a smart friend.

ğŸ“š Corpus: "{playlist_title}" ({len(videos)} videos)

{response_instruction}

RULES:
- Be concise and direct, no preambles ("Sure", "Great question")
- No closing formulas ("Hope this helps", "Let me know")
- Match length to complexity: short question = short answer
- Cite videos: "Video 3 (5:23)" or "In video 2..."
- If info isn't in the corpus, just say so
- Use 1-2 emojis max to keep the chat lively
- Cite at least {timecode_min} videos with timecodes

EVALUATION (mode {mode}): Distinguish fact/opinion/hypothesis. Note consensus and divergences. âœ… Solid | âš–ï¸ Plausible | â“ Uncertain

ğŸŒ Respond only in English.
"""
        final_instruction = "RESPOND DIRECTLY (first sentence = start of the answer):"

    full_prompt = f"""{system_prompt}

â•â•â• CORPUS ({len(videos)} {"VIDÃ‰OS" if lang == "fr" else "VIDEOS"}) â•â•â•
{corpus_text}

{"HISTORIQUE" if lang == "fr" else "HISTORY"}:{history_text}

QUESTION: {question}

{final_instruction}"""
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.mistral.ai/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": model,
                    "messages": [{"role": "user", "content": full_prompt}],
                    "max_tokens": adaptive_max_tokens,
                    "temperature": 0.7  # Plus naturel et conversationnel
                },
                timeout=120
            )
            
            if response.status_code == 200:
                data = response.json()
                answer = data["choices"][0]["message"]["content"].strip()

                # Post-processing: supprimer les prÃ©ambules rÃ©siduels
                preambles_to_remove = [
                    "Bien sÃ»r!", "Bien sÃ»r,", "Certainement!", "Certainement,",
                    "Excellente question!", "Bonne question!", "C'est une bonne question.",
                    "Je vais rÃ©pondre Ã  votre question.", "Permettez-moi de rÃ©pondre.",
                    "Sure!", "Certainly!", "Great question!", "Good question!",
                    "Let me answer that.", "I'll explain.", "Of course!"
                ]
                for preamble in preambles_to_remove:
                    if answer.startswith(preamble):
                        answer = answer[len(preamble):].strip()

                print(f"[CHAT v4.2] âœ… Response: {len(answer)} chars", flush=True)
                return answer
            else:
                print(f"[CHAT v4.2] âŒ API Error {response.status_code}", flush=True)
                if response.status_code == 429:
                    if lang == "fr":
                        return "â³ Limite de requÃªtes atteinte. RÃ©essayez dans quelques instants."
                    return "â³ Rate limit reached. Please try again in a moment."
                if lang == "fr":
                    return f"âŒ Erreur API: {response.status_code}"
                return f"âŒ API Error: {response.status_code}"

    except Exception as e:
        print(f"[CHAT v4.2] âŒ Exception: {e}", flush=True)
        if lang == "fr":
            return f"âŒ Erreur: {e}"
        return f"âŒ Error: {e}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒ PERPLEXITY v4.0 â€” Recherche contextuelle avec cache
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def _perplexity_chat_corpus_v4(
    question: str,
    playlist_title: str,
    dominant_category: str = None
) -> Optional[Dict]:
    """Recherche Perplexity optimisÃ©e avec contexte corpus."""
    api_key = get_perplexity_key()
    if not api_key:
        return None
    
    cache_key = _perplexity_cache._make_key(question, playlist_title)
    cached = _perplexity_cache.get(cache_key)
    if cached:
        print(f"[PERPLEXITY] ğŸ’¾ Cache hit!", flush=True)
        return cached
    
    context_hint = f"corpus vidÃ©o '{playlist_title}'"
    if dominant_category:
        context_hint += f" (thÃ¨me: {dominant_category})"
    
    prompt = f"""Dans le contexte d'une analyse de {context_hint}, recherche des informations complÃ©mentaires RÃ‰CENTES et VÃ‰RIFIABLES sur:

{question}

Instructions:
1. Priorise les sources officielles et rÃ©centes (< 6 mois)
2. Indique clairement les dates des informations
3. Signale si l'information est sujette Ã  changement rapide
4. Fournis des faits vÃ©rifiables, pas des opinions

RÃ©ponds de maniÃ¨re concise et factuelle."""
    
    try:
        print(f"[PERPLEXITY] ğŸ”® Query: {question[:50]}...", flush=True)
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.perplexity.ai/chat/completions",
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "llama-3.1-sonar-small-128k-online",
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 1500,
                    "temperature": 0.2
                },
                timeout=45
            )
            
            if response.status_code == 200:
                data = response.json()
                answer = data.get("choices", [{}])[0].get("message", {}).get("content", "")
                citations = data.get("citations", [])
                
                sources = []
                if citations:
                    answer += "\n\n**ğŸ” Sources:**\n"
                    for url in citations[:5]:
                        try:
                            domain = url.split("/")[2] if len(url.split("/")) > 2 else url[:40]
                            answer += f"- [{domain}]({url})\n"
                            sources.append({"url": url, "domain": domain})
                        except:
                            pass
                
                result = {"answer": answer, "sources": sources}
                _perplexity_cache.set(cache_key, result)
                
                print(f"[PERPLEXITY] âœ… {len(answer)} chars, {len(citations)} sources", flush=True)
                return result
            else:
                print(f"[PERPLEXITY] âŒ HTTP {response.status_code}", flush=True)
                return None
                
    except Exception as e:
        print(f"[PERPLEXITY] âŒ Exception: {e}", flush=True)
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”„ DÃ‰TECTION SUJETS VOLATILS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _detect_volatile_disclaimer(
    question: str,
    playlist_title: str,
    dominant_category: str,
    lang: str = "fr"
) -> Optional[str]:
    """
    ğŸ†• v4.2: DÃ©tecte si la question concerne un sujet volatil.
    Support bilingue FR/EN.
    """
    text_to_check = f"{question} {playlist_title}".lower()
    disclaimer_key = "disclaimer_en" if lang == "en" else "disclaimer_fr"

    for topic_key, topic_info in VOLATILE_TOPICS.items():
        keywords = topic_info.get("keywords", [])
        for keyword in keywords:
            if keyword.lower() in text_to_check:
                return topic_info.get(disclaimer_key)

    if dominant_category:
        category_lower = dominant_category.lower()
        for topic_key, topic_info in VOLATILE_TOPICS.items():
            if topic_key in category_lower or category_lower in topic_key:
                return topic_info.get(disclaimer_key)

    return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ BACKGROUND TASKS â€” Analyse en arriÃ¨re-plan
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def _analyze_playlist_background(
    task_id: str,
    playlist_id: str,
    url: str,
    max_videos: int,
    mode: str,
    lang: str,
    model: str,
    user_id: int,
    user_plan: str
):
    """Analyse une playlist YouTube en arriÃ¨re-plan."""
    from db.database import async_session_maker
    
    print(f"\nğŸ”§ BACKGROUND PLAYLIST ANALYSIS", flush=True)
    print(f"   Task: {task_id}", flush=True)
    print(f"   Mode: {mode}, Model: {model}", flush=True)
    
    async with async_session_maker() as session:
        try:
            _playlist_task_store[task_id]["status"] = "processing"
            _playlist_task_store[task_id]["message"] = "RÃ©cupÃ©ration de la playlist..."
            
            playlist_info = await get_playlist_info(playlist_id)
            if not playlist_info:
                raise Exception("Impossible de rÃ©cupÃ©rer la playlist")
            
            print(f"ğŸ“š Playlist: {playlist_info.get('title', 'Unknown')}", flush=True)
            
            videos = await get_playlist_videos(playlist_id, max_videos)
            if not videos:
                raise Exception("Aucune vidÃ©o trouvÃ©e")
            
            total_videos = len(videos)
            _playlist_task_store[task_id]["total_videos"] = total_videos
            _playlist_task_store[task_id]["message"] = f"{total_videos} vidÃ©os trouvÃ©es"
            
            print(f"ğŸ“º {total_videos} videos found", flush=True)
            
            playlist_analysis = PlaylistAnalysis(
                user_id=user_id,
                playlist_id=playlist_id,
                playlist_url=url,
                playlist_title=playlist_info.get("title", "Playlist"),
                num_videos=total_videos,
                status="processing",
                started_at=datetime.utcnow()
            )
            session.add(playlist_analysis)
            await session.commit()
            
            summaries = []
            total_duration = 0
            total_words = 0
            
            for idx, video in enumerate(videos):
                position = idx + 1
                _playlist_task_store[task_id]["current_video"] = position
                _playlist_task_store[task_id]["progress"] = int((position / total_videos) * 80)
                
                video_id = video.get("video_id")
                if not video_id:
                    print(f"âš ï¸ Skip video {position}: no video_id", flush=True)
                    continue
                
                _playlist_task_store[task_id]["message"] = f"Analyse {position}/{total_videos}: {video.get('title', '')[:40]}..."
                
                print(f"\nğŸ“¹ [{position}/{total_videos}] {video_id}", flush=True)
                
                try:
                    video_info = await get_video_info(video_id)
                    if not video_info:
                        print(f"   âŒ No video info", flush=True)
                        continue
                    
                    print(f"   Title: {video_info.get('title', '')[:50]}", flush=True)
                    
                    transcript_result = await get_transcript_with_timestamps(video_id, lang)
                    
                    if isinstance(transcript_result, tuple):
                        if len(transcript_result) >= 3:
                            transcript_simple, transcript_timestamped, detected_lang = transcript_result
                        else:
                            transcript_simple = transcript_result[0] if transcript_result else None
                            transcript_timestamped = transcript_simple
                    else:
                        transcript_simple = transcript_result
                        transcript_timestamped = transcript_result
                    
                    if not transcript_simple:
                        print(f"   âš ï¸ No transcript", flush=True)
                        continue
                    
                    print(f"   âœ… Transcript: {len(transcript_simple)} chars", flush=True)
                    
                    category_result = detect_category(
                        title=video_info.get("title", ""),
                        description=video_info.get("description", ""),
                        transcript=transcript_simple[:2000]
                    )
                    category = category_result[0] if isinstance(category_result, tuple) else category_result
                    print(f"   ğŸ“ Category: {category}", flush=True)
                    
                    summary_content = await generate_summary(
                        title=video_info.get("title", ""),
                        transcript=transcript_simple,
                        category=category,
                        lang=lang,
                        mode=mode,
                        model=model,
                        duration=video_info.get("duration", 0),
                        channel=video_info.get("channel", ""),
                        description=video_info.get("description", "")
                    )
                    
                    if not summary_content:
                        print(f"   âš ï¸ No summary generated", flush=True)
                        continue
                    
                    word_count = len(summary_content.split())
                    duration = video_info.get("duration", 0)
                    total_duration += duration
                    total_words += word_count
                    
                    print(f"   âœ… Summary: {word_count} words", flush=True)
                    
                    transcript_context = transcript_timestamped if isinstance(transcript_timestamped, str) else None
                    if transcript_context:
                        transcript_context = transcript_context[:40000]  # ğŸ†• v4.2: AugmentÃ© pour vidÃ©os longues
                    
                    summary = Summary(
                        user_id=user_id,
                        video_id=video_id,
                        video_title=video_info.get("title"),
                        video_channel=video_info.get("channel"),
                        video_duration=duration,
                        video_url=f"https://www.youtube.com/watch?v={video_id}",
                        thumbnail_url=video_info.get("thumbnail_url", video_info.get("thumbnail")),
                        category=category,
                        lang=lang,
                        mode=mode,
                        model_used=model,
                        summary_content=summary_content,
                        transcript_context=transcript_context,
                        word_count=word_count,
                        playlist_id=playlist_id,
                        playlist_position=position
                    )
                    session.add(summary)
                    
                    summaries.append({
                        "position": position,
                        "title": video_info.get("title"),
                        "channel": video_info.get("channel"),
                        "summary": summary_content[:2000],
                        "category": category,
                        "duration": duration,
                        "word_count": word_count
                    })
                    
                    user = await session.get(User, user_id)
                    if user and user.credits > 0:
                        user.credits -= 1
                        user.total_videos += 1
                        user.total_words += word_count
                    
                    await session.commit()
                    
                except Exception as e:
                    print(f"   âŒ Error: {e}", flush=True)
                    await session.rollback()
                    continue
            
            if not summaries:
                raise Exception("Aucune vidÃ©o analysÃ©e")
            
            _playlist_task_store[task_id]["progress"] = 85
            _playlist_task_store[task_id]["message"] = "GÃ©nÃ©ration de la mÃ©ta-analyse..."
            
            meta_analysis = await _generate_meta_analysis_v4(
                summaries=summaries,
                playlist_title=playlist_info.get("title", "Playlist"),
                lang=lang,
                model=model
            )
            
            playlist_analysis.meta_analysis = meta_analysis
            playlist_analysis.total_duration = total_duration
            playlist_analysis.total_words = total_words
            playlist_analysis.num_processed = len(summaries)
            playlist_analysis.status = "completed"
            playlist_analysis.completed_at = datetime.utcnow()
            
            user = await session.get(User, user_id)
            if user:
                user.total_playlists += 1
            
            await session.commit()
            
            _playlist_task_store[task_id]["status"] = "completed"
            _playlist_task_store[task_id]["progress"] = 100
            _playlist_task_store[task_id]["message"] = "Analyse terminÃ©e!"
            _playlist_task_store[task_id]["result"] = {
                "playlist_id": playlist_id,
                "num_videos": len(summaries),
                "total_duration": total_duration,
                "total_words": total_words
            }
            
            print(f"\nâœ… PLAYLIST COMPLETED: {len(summaries)} videos, {total_words} words", flush=True)
            
        except Exception as e:
            print(f"âŒ PLAYLIST FAILED: {e}", flush=True)
            await session.rollback()
            _playlist_task_store[task_id]["status"] = "failed"
            _playlist_task_store[task_id]["message"] = str(e)


async def _analyze_corpus_background(
    task_id: str,
    urls: List[str],
    corpus_name: str,
    mode: str,
    lang: str,
    model: str,
    user_id: int,
    user_plan: str
):
    """Analyse un corpus personnalisÃ© en arriÃ¨re-plan."""
    from db.database import async_session_maker
    
    corpus_id = f"corpus_{uuid4().hex[:12]}"
    
    print(f"\nğŸ”§ BACKGROUND CORPUS ANALYSIS", flush=True)
    print(f"   Task: {task_id}", flush=True)
    print(f"   Corpus: {corpus_name} ({len(urls)} URLs)", flush=True)
    
    async with async_session_maker() as session:
        try:
            _playlist_task_store[task_id]["status"] = "processing"
            
            total_videos = len(urls)
            _playlist_task_store[task_id]["total_videos"] = total_videos
            
            playlist_analysis = PlaylistAnalysis(
                user_id=user_id,
                playlist_id=corpus_id,
                playlist_url=",".join(urls[:5]),
                playlist_title=corpus_name,
                num_videos=total_videos,
                status="processing",
                started_at=datetime.utcnow()
            )
            session.add(playlist_analysis)
            await session.commit()
            
            summaries = []
            total_duration = 0
            total_words = 0
            
            for idx, url in enumerate(urls):
                position = idx + 1
                _playlist_task_store[task_id]["current_video"] = position
                _playlist_task_store[task_id]["progress"] = int((position / total_videos) * 80)
                
                video_id = extract_video_id(url)
                if not video_id:
                    print(f"âš ï¸ Invalid URL: {url}", flush=True)
                    continue
                
                _playlist_task_store[task_id]["message"] = f"Analyse {position}/{total_videos}..."
                
                print(f"\nğŸ“¹ [{position}/{total_videos}] {video_id}", flush=True)
                
                try:
                    video_info = await get_video_info(video_id)
                    if not video_info:
                        continue
                    
                    transcript_result = await get_transcript_with_timestamps(video_id, lang)
                    
                    if isinstance(transcript_result, tuple):
                        transcript_simple, transcript_timestamped, _ = (
                            transcript_result if len(transcript_result) >= 3 
                            else (transcript_result[0], transcript_result[0], lang)
                        )
                    else:
                        transcript_simple = transcript_result
                        transcript_timestamped = transcript_result
                    
                    if not transcript_simple:
                        continue
                    
                    category_result = detect_category(
                        title=video_info.get("title", ""),
                        description=video_info.get("description", ""),
                        transcript=transcript_simple[:2000]
                    )
                    category = category_result[0] if isinstance(category_result, tuple) else category_result
                    
                    summary_content = await generate_summary(
                        title=video_info.get("title", ""),
                        transcript=transcript_simple,
                        category=category,
                        lang=lang,
                        mode=mode,
                        model=model,
                        duration=video_info.get("duration", 0),
                        channel=video_info.get("channel", ""),
                        description=video_info.get("description", "")
                    )
                    
                    if not summary_content:
                        continue
                    
                    word_count = len(summary_content.split())
                    duration = video_info.get("duration", 0)
                    total_duration += duration
                    total_words += word_count
                    
                    transcript_context = transcript_timestamped if isinstance(transcript_timestamped, str) else None
                    if transcript_context:
                        transcript_context = transcript_context[:40000]  # ğŸ†• v4.2: AugmentÃ© pour vidÃ©os longues
                    
                    summary = Summary(
                        user_id=user_id,
                        video_id=video_id,
                        video_title=video_info.get("title"),
                        video_channel=video_info.get("channel"),
                        video_duration=duration,
                        video_url=f"https://www.youtube.com/watch?v={video_id}",
                        thumbnail_url=video_info.get("thumbnail_url", video_info.get("thumbnail")),
                        category=category,
                        lang=lang,
                        mode=mode,
                        model_used=model,
                        summary_content=summary_content,
                        transcript_context=transcript_context,
                        word_count=word_count,
                        playlist_id=corpus_id,
                        playlist_position=position
                    )
                    session.add(summary)
                    
                    summaries.append({
                        "position": position,
                        "title": video_info.get("title"),
                        "channel": video_info.get("channel"),
                        "summary": summary_content[:2000],
                        "category": category,
                        "duration": duration,
                        "word_count": word_count
                    })
                    
                    user = await session.get(User, user_id)
                    if user and user.credits > 0:
                        user.credits -= 1
                        user.total_videos += 1
                        user.total_words += word_count
                    
                    await session.commit()
                    
                except Exception as e:
                    print(f"âŒ Error {video_id}: {e}", flush=True)
                    await session.rollback()
                    continue
            
            if not summaries:
                raise Exception("Aucune vidÃ©o analysÃ©e")
            
            _playlist_task_store[task_id]["progress"] = 85
            _playlist_task_store[task_id]["message"] = "MÃ©ta-analyse..."
            
            meta_analysis = await _generate_meta_analysis_v4(
                summaries=summaries,
                playlist_title=corpus_name,
                lang=lang,
                model=model
            )
            
            playlist_analysis.meta_analysis = meta_analysis
            playlist_analysis.total_duration = total_duration
            playlist_analysis.total_words = total_words
            playlist_analysis.num_processed = len(summaries)
            playlist_analysis.status = "completed"
            playlist_analysis.completed_at = datetime.utcnow()
            
            user = await session.get(User, user_id)
            if user:
                user.total_playlists += 1
            
            await session.commit()
            
            _playlist_task_store[task_id]["status"] = "completed"
            _playlist_task_store[task_id]["progress"] = 100
            _playlist_task_store[task_id]["message"] = "TerminÃ©!"
            _playlist_task_store[task_id]["result"] = {
                "playlist_id": corpus_id,
                "num_videos": len(summaries),
                "total_duration": total_duration,
                "total_words": total_words
            }
            
        except Exception as e:
            print(f"âŒ CORPUS FAILED: {e}", flush=True)
            await session.rollback()
            _playlist_task_store[task_id]["status"] = "failed"
            _playlist_task_store[task_id]["message"] = str(e)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§  META-ANALYSE v4.0 â€” Avec extraction de concepts
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def _generate_meta_analysis_v4(
    summaries: List[Dict],
    playlist_title: str,
    lang: str,
    model: str
) -> str:
    """
    ğŸ†• v4.2: GÃ©nÃ¨re une mÃ©ta-analyse enrichie avec extraction de concepts.
    Support complet FR/EN.
    """
    api_key = get_mistral_key()
    if not api_key:
        return "Meta-analysis unavailable" if lang == "en" else "MÃ©ta-analyse non disponible"

    summaries_text = ""
    categories = set()
    all_concepts = []
    total_duration = 0

    for s in summaries:
        summaries_text += f"\n### {s['position']}. {s['title']}\n"
        if lang == "fr":
            summaries_text += f"**ChaÃ®ne:** {s.get('channel', 'N/A')} | **CatÃ©gorie:** {s.get('category', 'N/A')}\n"
        else:
            summaries_text += f"**Channel:** {s.get('channel', 'N/A')} | **Category:** {s.get('category', 'N/A')}\n"
        summaries_text += f"{s['summary']}\n"

        if s.get('category'):
            categories.add(s['category'])
        total_duration += s.get('duration', 0)

        concepts = SemanticScorer.extract_key_concepts(s['summary'], top_n=5)
        all_concepts.extend(concepts)

    concept_counts = Counter(all_concepts)
    top_concepts = [c for c, _ in concept_counts.most_common(10)]

    duration_str = f"{total_duration // 3600}h {(total_duration % 3600) // 60}min" if total_duration > 3600 else f"{total_duration // 60} min"

    # ğŸ†• v4.2: Prompt bilingue complet
    if lang == "fr":
        prompt = f"""Analyse ce corpus de {len(summaries)} vidÃ©os intitulÃ© "{playlist_title}":

{summaries_text}

**Concepts clÃ©s dÃ©tectÃ©s automatiquement:** {', '.join(top_concepts)}

GÃ©nÃ¨re une mÃ©ta-analyse COMPLÃˆTE en franÃ§ais avec:

## ğŸ¯ Vision d'Ensemble
SynthÃ¨se globale du corpus en 3-4 phrases. Quel est le fil conducteur principal?

## ğŸ“Š ThÃ¨mes Principaux
Liste les 4-6 thÃ¨mes majeurs avec leur frÃ©quence/importance dans le corpus.

## ğŸ”— Connexions & ComplÃ©mentaritÃ©s
Comment les vidÃ©os se complÃ¨tent-elles? Quels liens conceptuels entre elles?

## âš”ï¸ Points de Tension
Y a-t-il des contradictions, nuances ou opinions divergentes entre vidÃ©os?

## ğŸ’¡ Insights ClÃ©s
Les 5 apprentissages les plus importants du corpus, avec rÃ©fÃ©rences aux vidÃ©os.

## ğŸ“ˆ Statistiques
- **VidÃ©os analysÃ©es:** {len(summaries)}
- **DurÃ©e totale:** {duration_str}
- **CatÃ©gories:** {', '.join(categories) if categories else 'VariÃ©es'}
- **Mots gÃ©nÃ©rÃ©s:** {sum(s.get('word_count', 0) for s in summaries):,}

## ğŸ¬ Parcours SuggÃ©rÃ©
Par quelle vidÃ©o commencer? Quel ordre de visionnage recommandes-tu et pourquoi?

ğŸŒ RÃ‰PONDS UNIQUEMENT EN FRANÃ‡AIS.
"""
    else:  # English
        prompt = f"""Analyze this corpus of {len(summaries)} videos titled "{playlist_title}":

{summaries_text}

**Automatically detected key concepts:** {', '.join(top_concepts)}

Generate a COMPLETE meta-analysis in English with:

## ğŸ¯ Overview
Global synthesis of the corpus in 3-4 sentences. What is the main thread?

## ğŸ“Š Main Themes
List the 4-6 major themes with their frequency/importance in the corpus.

## ğŸ”— Connections & Complementarities
How do the videos complement each other? What conceptual links between them?

## âš”ï¸ Points of Tension
Are there contradictions, nuances or divergent opinions between videos?

## ğŸ’¡ Key Insights
The 5 most important learnings from the corpus, with video references.

## ğŸ“ˆ Statistics
- **Videos analyzed:** {len(summaries)}
- **Total duration:** {duration_str}
- **Categories:** {', '.join(categories) if categories else 'Various'}
- **Words generated:** {sum(s.get('word_count', 0) for s in summaries):,}

## ğŸ¬ Suggested Path
Which video to start with? What viewing order do you recommend and why?

ğŸŒ RESPOND ONLY IN ENGLISH.
"""
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.mistral.ai/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": model,
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 4500,
                    "temperature": 0.35
                },
                timeout=120
            )
            if response.status_code == 200:
                content = response.json()["choices"][0]["message"]["content"]
                print(f"âœ… Meta-analysis v4: {len(content)} chars", flush=True)
                return content
    except Exception as e:
        print(f"âŒ Meta-analysis error: {e}", flush=True)
    
    return f"MÃ©ta-analyse de {len(summaries)} vidÃ©os. CatÃ©gories: {', '.join(categories)}. Concepts: {', '.join(top_concepts[:5])}"
