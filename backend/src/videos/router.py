"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“¹ VIDEO ROUTER v6.0 â€” SÃ‰CURITÃ‰ RENFORCÃ‰E + ENRICHISSEMENT PERPLEXITY             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ğŸ†• v6.0: SÃ‰CURITÃ‰ RENFORCÃ‰E                                                       â•‘
â•‘  â€¢ ğŸ” RÃ©servation atomique des crÃ©dits avant analyse                               â•‘
â•‘  â€¢ ğŸ›¡ï¸ Rate limiting par utilisateur                                               â•‘
â•‘  â€¢ âœ… VÃ©rification email obligatoire                                               â•‘
â•‘  â€¢ ğŸ’° CoÃ»t variable selon le modÃ¨le (small=1, medium=2, large=3)                  â•‘
â•‘  â€¢ ğŸŒ Perplexity PRÃ‰-ANALYSE pour Pro/Expert                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import json
import math
from uuid import uuid4
from datetime import datetime
from typing import Optional, Dict, Any, List
from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks, Query, UploadFile, File, Form
from sqlalchemy.ext.asyncio import AsyncSession

from db.database import get_session, User
from auth.dependencies import get_current_user, get_verified_user, require_plan, check_daily_limit, require_feature
from core.config import PLAN_LIMITS, CATEGORIES

# Import du systÃ¨me de sÃ©curitÃ©
try:
    from core.security import (
        check_can_analyze as secure_check_can_analyze,
        reserve_credits, consume_reserved_credits, release_reserved_credits,
        get_credit_cost, generate_secure_operation_id, verify_resource_ownership
    )
    SECURITY_AVAILABLE = True
except ImportError:
    SECURITY_AVAILABLE = False
    print("âš ï¸ [VIDEO] Security module not available", flush=True)

from .schemas import (
    AnalyzeVideoRequest, AnalyzePlaylistRequest, UpdateSummaryRequest,
    SummaryResponse, SummaryListItem, HistoryResponse, CategoryResponse,
    TaskStatusResponse, VideoInfoResponse, ExtensionSummaryResponse
)
from .summary_extractor import extract_extension_summary
from .service import (
    check_can_analyze, deduct_credit, save_summary,
    get_summary_by_id, get_summary_by_video_id, get_user_history,
    update_summary, delete_summary, delete_all_history,
    create_playlist_analysis, get_user_playlists, get_playlist_summaries,
    get_user_stats, create_task, update_task_status, get_task
)
from .analysis import (
    generate_summary, detect_category, extract_entities,
    calculate_reliability_score, CATEGORIES as ANALYSIS_CATEGORIES
)
from .long_video_analyzer import (
    needs_chunking, analyze_long_video, get_chunk_stats
)
from .web_enrichment import (
    get_pre_analysis_context, get_enrichment_level, get_enrichment_badge,
    EnrichmentLevel, format_sources_markdown
)
from .raw_text_enhance import (
    enhance_raw_text, generate_smart_title, generate_thumbnail,
    SourceType, SourceContext, get_source_specific_instructions
)
# ğŸ“š Import du systÃ¨me de dÃ©finitions de concepts
from .concept_definitions import (
    get_concepts_with_definitions, extract_concepts, clean_concept_markers
)
# ğŸ“š Import des dÃ©finitions enrichies v2 (Mistral + Perplexity)
from .enriched_definitions import (
    get_enriched_definitions, extract_terms_from_text, get_category_info, CATEGORIES
)

# ğŸ†• v2.1: Import des nouveaux modules d'analyse avancÃ©e
try:
    from .youtube_comments import analyze_comments
    from .metadata_enriched import get_enriched_metadata, detect_sponsorship, detect_propaganda_risk
    from .anti_ai_prompts import build_customized_prompt, get_anti_ai_prompt, get_style_instruction
    from .schemas import (
        AnalysisCustomization, WritingStyle, AnalyzeRequestV2, AnalyzeResponseV2,
        CommentsAnalysis, VideoMetadataEnriched
    )
    ADVANCED_ANALYSIS_AVAILABLE = True
except ImportError as e:
    ADVANCED_ANALYSIS_AVAILABLE = False
    print(f"âš ï¸ [VIDEO] Advanced analysis modules not available: {e}", flush=True)

# ğŸ• Import du systÃ¨me de fraÃ®cheur et fact-check LITE
try:
    from .freshness_factcheck import (
        analyze_freshness, analyze_claims_lite, analyze_content_reliability,
        FreshnessLevel
    )
    FACTCHECK_LITE_AVAILABLE = True
except ImportError:
    FACTCHECK_LITE_AVAILABLE = False
    print("âš ï¸ [VIDEO] Freshness/FactCheck LITE module not available", flush=True)
from transcripts import (
    extract_video_id, extract_playlist_id,
    get_video_info, get_transcript_with_timestamps,
    get_playlist_videos, get_playlist_info
)

# ğŸ”” Import du systÃ¨me de notifications (SSE)
try:
    from notifications.router import notify_analysis_complete, notify_analysis_failed
    NOTIFICATIONS_AVAILABLE = True
except ImportError:
    NOTIFICATIONS_AVAILABLE = False
    print("âš ï¸ [VIDEO] Notifications module not available", flush=True)
    
    # Fallback: fonctions vides
    async def notify_analysis_complete(*args, **kwargs):
        pass
    async def notify_analysis_failed(*args, **kwargs):
        pass

router = APIRouter()

# Store en mÃ©moire pour les tÃ¢ches (en production: Redis)
_task_store: Dict[str, Dict[str, Any]] = {}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¬ ANALYSE VIDÃ‰O
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.post("/analyze", response_model=TaskStatusResponse)
async def analyze_video(
    request: AnalyzeVideoRequest,
    background_tasks: BackgroundTasks,
    current_user: User = Depends(check_daily_limit),  # ğŸ” Email vÃ©rifiÃ© + limite quotidienne
    session: AsyncSession = Depends(get_session)
):
    """
    ğŸ” Lance l'analyse d'une vidÃ©o YouTube avec SÃ‰CURITÃ‰ RENFORCÃ‰E.
    
    SÃ‰CURITÃ‰:
    - Email vÃ©rifiÃ© obligatoire
    - Rate limiting appliquÃ©
    - CrÃ©dits rÃ©servÃ©s AVANT l'opÃ©ration
    - CoÃ»t variable selon le modÃ¨le
    """
    print(f"ğŸ“¥ [v6.0] Analyze request: {request.url} by user {current_user.id} (plan: {current_user.plan})", flush=True)
    
    # Extraire l'ID vidÃ©o d'abord pour validation
    video_id = extract_video_id(request.url)
    if not video_id:
        raise HTTPException(status_code=400, detail={
            "code": "invalid_url",
            "message": "Invalid YouTube URL"
        })
    
    # DÃ©terminer le modÃ¨le Ã  utiliser
    plan_limits = PLAN_LIMITS.get(current_user.plan, PLAN_LIMITS["free"])
    model = request.model or plan_limits.get("default_model", "mistral-small-latest")
    
    # VÃ©rifier que le modÃ¨le est autorisÃ©
    allowed_models = plan_limits.get("models", ["mistral-small-latest"])
    if model not in allowed_models:
        model = allowed_models[0]  # Fallback au modÃ¨le par dÃ©faut
    
    # ğŸ†• v5.5: VÃ©rifier si deep_research est autorisÃ©
    deep_research = request.deep_research and plan_limits.get("deep_research_enabled", False)
    deep_research_cost = plan_limits.get("deep_research_credits_cost", 0) if deep_research else 0
    
    # ğŸ” Calculer le coÃ»t en crÃ©dits
    if SECURITY_AVAILABLE:
        credit_cost = get_credit_cost("video_analysis", model)
    else:
        credit_cost = 1
    
    # Ajouter le coÃ»t de deep_research
    credit_cost += deep_research_cost
    
    # ğŸ” VÃ©rifier les crÃ©dits avec le systÃ¨me sÃ©curisÃ©
    if SECURITY_AVAILABLE:
        can_analyze, reason, info = await secure_check_can_analyze(
            session, current_user.id, model
        )
    else:
        # check_can_analyze retourne 4 valeurs: (can_analyze, reason, credits, cost)
        can_analyze, reason, credits_remaining, estimated_cost = await check_can_analyze(session, current_user.id)
        info = {"credits": credits_remaining, "cost": estimated_cost}  # Construire info dict
    
    if not can_analyze:
        raise HTTPException(status_code=403, detail={
            "code": reason,
            "message": info.get("message", f"Cannot analyze: {reason}"),
            "credits": info.get("credits", 0),
            "cost": credit_cost,
            **info
        })
    
    print(f"ğŸ¬ Video ID extracted: {video_id}, cost: {credit_cost} credits", flush=True)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ’¾ SYSTÃˆME DE CACHE v2.0 â€” Ã‰conomise les crÃ©dits API
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # VÃ©rifier si dÃ©jÃ  analysÃ©e (mÃªme vidÃ©o, mÃªme mode) - SAUF si force_refresh
    if not request.force_refresh:
        existing = await get_summary_by_video_id(session, video_id, current_user.id)
        
        if existing and existing.mode == request.mode:
            # VÃ©rifier la fraÃ®cheur du cache (7 jours max)
            from datetime import timedelta
            cache_age = datetime.now() - existing.created_at
            cache_valid = cache_age < timedelta(days=7)
            
            if cache_valid:
                print(f"ğŸ’¾ [CACHE HIT] Using cached analysis: summary_id={existing.id} (age: {cache_age.days}d)", flush=True)
                return TaskStatusResponse(
                    task_id=f"cached_{existing.id}",
                    status="completed",
                    progress=100,
                    message=f"âœ… Analyse retrouvÃ©e en cache (gratuit!)",
                    result={
                        "summary_id": existing.id,
                        "cached": True,
                        "cache_age_days": cache_age.days,
                        "video_title": existing.video_title,
                        "category": existing.category,
                        "cost": 0  # Gratuit car cache
                    }
                )
            else:
                print(f"â° [CACHE EXPIRED] Cache too old ({cache_age.days} days), re-analyzing...", flush=True)
    else:
        print(f"ğŸ”„ [FORCE REFRESH] Bypassing cache as requested", flush=True)
    
    # ğŸ” GÃ©nÃ©rer un ID d'opÃ©ration sÃ©curisÃ©
    if SECURITY_AVAILABLE:
        task_id = generate_secure_operation_id(current_user.id, "video_analysis")
    else:
        task_id = str(uuid4())
    
    # ğŸ” RÃ‰SERVER les crÃ©dits AVANT de lancer l'opÃ©ration
    if SECURITY_AVAILABLE:
        reserved, reserve_reason, reserve_info = await reserve_credits(
            session, current_user.id, credit_cost, task_id, "video_analysis"
        )
        if not reserved:
            raise HTTPException(status_code=403, detail={
                "code": reserve_reason,
                "message": f"Could not reserve credits: {reserve_reason}",
                **reserve_info
            })
        print(f"ğŸ”’ Credits reserved: {credit_cost} for task {task_id[:12]}", flush=True)
    
    _task_store[task_id] = {
        "status": "pending",
        "progress": 0,
        "message": "Initializing...",
        "user_id": current_user.id,
        "video_id": video_id,
        "credit_cost": credit_cost,
        "deep_research": deep_research  # ğŸ†• v5.5
    }
    
    print(f"ğŸš€ Task created: {task_id} (deep_research={deep_research})", flush=True)
    
    # CrÃ©er dans la DB aussi
    await create_task(session, task_id, current_user.id, "video_analysis")
    
    # Lancer l'analyse en background
    background_tasks.add_task(
        _analyze_video_background_v6,  # ğŸ†• Nouvelle version
        task_id=task_id,
        video_id=video_id,
        url=request.url,
        mode=request.mode,
        category=request.category,
        lang=request.lang,
        model=model,
        user_id=current_user.id,
        user_plan=current_user.plan,
        credit_cost=credit_cost,
        deep_research=deep_research  # ğŸ†• v5.5
    )
    
    return TaskStatusResponse(
        task_id=task_id,
        status="pending",
        progress=0,
        message="Analysis started",
        result={"cost": credit_cost, "deep_research": deep_research}
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• ANALYSE V2 â€” Customization complÃ¨te
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from .schemas import AnalyzeVideoV2Request, AnalyzeV2Response

@router.post("/analyze/v2", response_model=AnalyzeV2Response)
async def analyze_video_v2(
    request: AnalyzeVideoV2Request,
    background_tasks: BackgroundTasks,
    current_user: User = Depends(check_daily_limit),
    session: AsyncSession = Depends(get_session)
):
    """
    ğŸ†• v2.0: Analyse vidÃ©o avec customization complÃ¨te.

    FonctionnalitÃ©s avancÃ©es:
    - Options de customization dÃ©taillÃ©es
    - ContrÃ´le de la longueur du rÃ©sumÃ©
    - GÃ©nÃ©ration de table des matiÃ¨res (TOC)
    - Webhook de notification
    - PrioritÃ© de traitement (Pro/Expert)

    SÃ‰CURITÃ‰:
    - Email vÃ©rifiÃ© obligatoire
    - Rate limiting appliquÃ©
    - CrÃ©dits rÃ©servÃ©s AVANT l'opÃ©ration
    """
    print(f"ğŸ“¥ [v2.0] Analyze request: {request.url} by user {current_user.id}", flush=True)

    # Extraire l'ID vidÃ©o
    video_id = extract_video_id(request.url)
    if not video_id:
        raise HTTPException(status_code=400, detail={
            "code": "invalid_url",
            "message": "Invalid YouTube URL"
        })

    # DÃ©terminer le modÃ¨le
    plan_limits = PLAN_LIMITS.get(current_user.plan, PLAN_LIMITS["free"])
    model = request.model or plan_limits.get("default_model", "mistral-small-latest")

    # VÃ©rifier que le modÃ¨le est autorisÃ©
    allowed_models = plan_limits.get("models", ["mistral-small-latest"])
    if model not in allowed_models:
        model = allowed_models[0]

    # VÃ©rifier deep_research
    deep_research = request.deep_research and plan_limits.get("deep_research_enabled", False)
    deep_research_cost = plan_limits.get("deep_research_credits_cost", 0) if deep_research else 0

    # Calculer le coÃ»t
    if SECURITY_AVAILABLE:
        credit_cost = get_credit_cost("video_analysis", model)
    else:
        credit_cost = 1
    credit_cost += deep_research_cost

    # Bonus de coÃ»t pour options avancÃ©es
    if request.generate_toc:
        credit_cost += 1  # TOC coÃ»te 1 crÃ©dit supplÃ©mentaire
    if request.summary_length == "detailed":
        credit_cost += 1  # RÃ©sumÃ© dÃ©taillÃ© coÃ»te 1 crÃ©dit supplÃ©mentaire

    # VÃ©rifier les crÃ©dits
    if SECURITY_AVAILABLE:
        can_analyze, reason, info = await secure_check_can_analyze(
            session, current_user.id, model
        )
    else:
        can_analyze, reason, credits_remaining, estimated_cost = await check_can_analyze(session, current_user.id)
        info = {"credits": credits_remaining, "cost": estimated_cost}

    if not can_analyze:
        raise HTTPException(status_code=403, detail={
            "code": reason,
            "message": info.get("message", f"Cannot analyze: {reason}"),
            "credits": info.get("credits", 0),
            "cost": credit_cost,
            **info
        })

    # VÃ©rifier le cache (sauf si force_refresh)
    if not request.force_refresh:
        existing = await get_summary_by_video_id(session, video_id, current_user.id)
        if existing and existing.mode == request.mode:
            from datetime import timedelta
            cache_age = datetime.now() - existing.created_at
            if cache_age < timedelta(days=7):
                print(f"ğŸ’¾ [CACHE HIT] v2: summary_id={existing.id}", flush=True)
                return AnalyzeV2Response(
                    task_id=f"cached_{existing.id}",
                    status="completed",
                    progress=100,
                    message="âœ… Analyse retrouvÃ©e en cache (gratuit!)",
                    cost=0,
                    video_info={
                        "video_id": existing.video_id,
                        "title": existing.video_title,
                        "channel": existing.video_channel,
                    },
                    applied_options={
                        "mode": existing.mode,
                        "lang": existing.lang,
                        "cached": True,
                        "cache_age_days": cache_age.days
                    }
                )

    # GÃ©nÃ©rer l'ID de tÃ¢che
    if SECURITY_AVAILABLE:
        task_id = generate_secure_operation_id(current_user.id, "video_analysis_v2")
    else:
        task_id = str(uuid4())

    # RÃ©server les crÃ©dits
    if SECURITY_AVAILABLE:
        reserved, reserve_reason, reserve_info = await reserve_credits(
            session, current_user.id, credit_cost, task_id, "video_analysis_v2"
        )
        if not reserved:
            raise HTTPException(status_code=403, detail={
                "code": reserve_reason,
                "message": f"Could not reserve credits: {reserve_reason}",
                **reserve_info
            })
        print(f"ğŸ”’ [v2] Credits reserved: {credit_cost} for task {task_id[:12]}", flush=True)

    # PrÃ©parer les options de customization
    customization_options = {
        "summary_length": request.summary_length,
        "highlight_key_points": request.highlight_key_points,
        "generate_toc": request.generate_toc,
        "include_entities": request.include_entities,
        "include_timestamps": request.include_timestamps,
        "include_reliability": request.include_reliability,
        "priority": request.priority if current_user.plan in ["pro", "expert", "unlimited"] else "normal",
        "webhook_url": request.webhook_url,
        "custom": request.customization or {}
    }

    # Stocker la tÃ¢che
    _task_store[task_id] = {
        "status": "pending",
        "progress": 0,
        "message": "Initializing v2 analysis...",
        "user_id": current_user.id,
        "video_id": video_id,
        "credit_cost": credit_cost,
        "deep_research": deep_research,
        "v2_options": customization_options
    }

    print(f"ğŸš€ [v2] Task created: {task_id}", flush=True)

    # CrÃ©er en DB
    await create_task(session, task_id, current_user.id, "video_analysis_v2")

    # Estimer la durÃ©e
    estimated_duration = 30 if request.summary_length == "short" else (60 if request.summary_length == "standard" else 90)
    if deep_research:
        estimated_duration += 30

    # Lancer l'analyse en background
    background_tasks.add_task(
        _analyze_video_background_v2,
        task_id=task_id,
        video_id=video_id,
        url=request.url,
        mode=request.mode,
        category=request.category,
        lang=request.lang,
        model=model,
        user_id=current_user.id,
        user_plan=current_user.plan,
        credit_cost=credit_cost,
        deep_research=deep_research,
        options=customization_options
    )

    return AnalyzeV2Response(
        task_id=task_id,
        status="pending",
        progress=0,
        message="Analysis v2 started with custom options",
        estimated_duration_seconds=estimated_duration,
        cost=credit_cost,
        applied_options=customization_options
    )


async def _analyze_video_background_v2(
    task_id: str,
    video_id: str,
    url: str,
    mode: str,
    category: Optional[str],
    lang: str,
    model: str,
    user_id: int,
    user_plan: str,
    credit_cost: int,
    deep_research: bool,
    options: Dict[str, Any]
):
    """
    ğŸ†• v2.0: Background analysis avec options de customization.

    Ajoute le support de:
    - Longueur de rÃ©sumÃ© variable
    - Table des matiÃ¨res
    - Points clÃ©s mis en Ã©vidence
    - Webhook de notification
    """
    from db.database import async_session_maker
    import httpx

    print(f"ğŸ”§ [v2.0] Background task started: {task_id}", flush=True)

    # DÃ©terminer le niveau d'enrichissement
    if deep_research:
        enrichment_level = EnrichmentLevel.DEEP
    else:
        enrichment_level = get_enrichment_level(user_plan)

    try:
        async with async_session_maker() as session:
            _task_store[task_id]["status"] = "processing"
            _task_store[task_id]["progress"] = 5
            _task_store[task_id]["message"] = "ğŸš€ DÃ©marrage de l'analyse v2..."

            # 1. RÃ©cupÃ©rer les infos vidÃ©o
            _task_store[task_id]["progress"] = 10
            _task_store[task_id]["message"] = "ğŸ“º RÃ©cupÃ©ration des infos vidÃ©o..."

            video_info = await get_video_info(video_id)
            if not video_info:
                raise Exception("Could not fetch video info")

            # 2. Extraire la transcription
            _task_store[task_id]["progress"] = 20
            _task_store[task_id]["message"] = "ğŸ“ Extraction du transcript..."

            transcript, transcript_timestamped, detected_lang = await get_transcript_with_timestamps(video_id)
            if not transcript:
                raise Exception("No transcript available for this video")

            if not lang or lang == "auto":
                lang = detected_lang or "fr"

            # 3. DÃ©tecter la catÃ©gorie
            _task_store[task_id]["progress"] = 30
            _task_store[task_id]["message"] = "ğŸ·ï¸ DÃ©tection de la catÃ©gorie..."

            if not category or category == "auto":
                category, confidence = detect_category(
                    title=video_info["title"],
                    description=video_info.get("description", ""),
                    transcript=transcript[:3000],
                    channel=video_info.get("channel", ""),
                    tags=video_info.get("tags", []),
                    youtube_categories=video_info.get("categories", [])
                )
            else:
                confidence = 0.9

            # 4. Enrichissement web (si activÃ©)
            web_context = None
            enrichment_sources = []

            if enrichment_level != EnrichmentLevel.NONE:
                _task_store[task_id]["progress"] = 40
                _task_store[task_id]["message"] = f"ğŸŒ Recherche web ({enrichment_level.value})..."

                try:
                    web_context, enrichment_sources, actual_level = await get_pre_analysis_context(
                        video_title=video_info["title"],
                        video_channel=video_info.get("channel", ""),
                        category=category,
                        transcript=transcript,
                        plan=user_plan,
                        lang=lang
                    )
                except Exception as e:
                    print(f"âš ï¸ [v2.0] Web enrichment failed: {e}", flush=True)

            # 5. GÃ©nÃ©rer le rÃ©sumÃ© avec les options de customization
            _task_store[task_id]["progress"] = 55
            _task_store[task_id]["message"] = "ğŸ§  GÃ©nÃ©ration du rÃ©sumÃ© personnalisÃ©..."

            # Ajuster le prompt selon les options
            summary_instructions = []
            if options.get("summary_length") == "short":
                summary_instructions.append("Fais un rÃ©sumÃ© COURT et CONCIS (max 500 mots).")
            elif options.get("summary_length") == "detailed":
                summary_instructions.append("Fais un rÃ©sumÃ© DÃ‰TAILLÃ‰ et EXHAUSTIF (1500+ mots).")

            if options.get("highlight_key_points"):
                summary_instructions.append("Mets en Ã©vidence les points clÃ©s avec des marqueurs **gras**.")

            if options.get("generate_toc"):
                summary_instructions.append("Commence par une table des matiÃ¨res structurÃ©e.")

            # Customization utilisateur
            custom = options.get("custom", {})
            if custom.get("focus_topics"):
                summary_instructions.append(f"Concentre-toi sur ces sujets: {', '.join(custom['focus_topics'])}")
            if custom.get("exclude_topics"):
                summary_instructions.append(f"Ã‰vite ces sujets: {', '.join(custom['exclude_topics'])}")
            if custom.get("tone") == "formal":
                summary_instructions.append("Utilise un ton formel et acadÃ©mique.")
            elif custom.get("tone") == "casual":
                summary_instructions.append("Utilise un ton accessible et dÃ©contractÃ©.")

            custom_context = "\n".join(summary_instructions) if summary_instructions else None

            # Combiner web_context et custom_context
            full_context = None
            if web_context and custom_context:
                full_context = f"{web_context}\n\n--- Instructions personnalisÃ©es ---\n{custom_context}"
            elif web_context:
                full_context = web_context
            elif custom_context:
                full_context = custom_context

            # DÃ©tecter si chunking nÃ©cessaire
            transcript_to_analyze = transcript_timestamped or transcript
            video_duration = video_info.get("duration", 0)
            needs_chunk, word_count, chunk_reason = needs_chunking(transcript_to_analyze)

            if needs_chunk:
                _task_store[task_id]["message"] = f"ğŸ“š VidÃ©o longue ({word_count} mots)..."

                def update_progress(progress: int, message: str):
                    _task_store[task_id]["progress"] = progress
                    _task_store[task_id]["message"] = message

                summary_content = await analyze_long_video(
                    title=video_info["title"],
                    transcript=transcript_to_analyze,
                    video_duration=video_duration,
                    category=category,
                    lang=lang,
                    mode=mode,
                    model=model,
                    web_context=full_context,
                    progress_callback=update_progress,
                    transcript_timestamped=transcript_timestamped
                )
            else:
                summary_content = await generate_summary(
                    title=video_info["title"],
                    transcript=transcript_to_analyze,
                    category=category,
                    lang=lang,
                    mode=mode,
                    model=model,
                    duration=video_duration,
                    channel=video_info.get("channel", ""),
                    description=video_info.get("description", ""),
                    web_context=full_context
                )

            if not summary_content:
                raise Exception("Failed to generate summary")

            # 6. Extraire les entitÃ©s (si demandÃ©)
            entities = None
            if options.get("include_entities", True):
                _task_store[task_id]["progress"] = 75
                _task_store[task_id]["message"] = "ğŸ” Extraction des entitÃ©s..."
                entities = await extract_entities(summary_content, lang=lang)

            # 7. Calculer la fiabilitÃ© (si demandÃ©)
            reliability = None
            if options.get("include_reliability", True):
                _task_store[task_id]["progress"] = 85
                _task_store[task_id]["message"] = "âš–ï¸ Calcul du score de fiabilitÃ©..."
                reliability = await calculate_reliability_score(summary_content, entities or {}, lang=lang)

                if enrichment_sources:
                    reliability_bonus = {
                        EnrichmentLevel.FULL: 8,
                        EnrichmentLevel.DEEP: 15
                    }.get(enrichment_level, 0)
                    reliability = min(98, reliability + reliability_bonus)

            # 8. Consommer les crÃ©dits et sauvegarder
            _task_store[task_id]["progress"] = 92
            _task_store[task_id]["message"] = "ğŸ’¾ Sauvegarde des rÃ©sultats..."

            if SECURITY_AVAILABLE:
                await consume_reserved_credits(
                    session, user_id, task_id,
                    f"Video v2: {video_info['title'][:50]} ({model})"
                )
            else:
                await deduct_credit(session, user_id, credit_cost, f"Video v2: {video_info['title'][:50]}")

            enrichment_metadata = None
            if enrichment_sources:
                enrichment_metadata = {
                    "level": enrichment_level.value,
                    "sources": enrichment_sources,
                    "enriched_at": datetime.utcnow().isoformat(),
                    "v2_options": options
                }

            summary_id = await save_summary(
                session=session,
                user_id=user_id,
                video_id=video_id,
                video_title=video_info["title"],
                video_channel=video_info.get("channel", "Unknown"),
                video_duration=video_info.get("duration", 0),
                video_url=url,
                thumbnail_url=video_info.get("thumbnail_url", f"https://img.youtube.com/vi/{video_id}/mqdefault.jpg"),
                category=category,
                category_confidence=confidence,
                lang=lang,
                mode=mode,
                model_used=model,
                summary_content=summary_content,
                transcript_context=transcript_timestamped or transcript,
                video_upload_date=video_info.get("upload_date"),
                entities_extracted=entities,
                reliability_score=reliability,
                enrichment_data=enrichment_metadata
            )

            # IncrÃ©menter le quota quotidien
            try:
                from core.plan_limits import increment_daily_usage
                await increment_daily_usage(session, user_id)
            except Exception as quota_err:
                print(f"âš ï¸ [v2] Quota increment failed: {quota_err}", flush=True)

            # 9. Marquer comme terminÃ©
            final_word_count = len(summary_content.split())
            enrichment_badge = get_enrichment_badge(enrichment_level, lang)

            _task_store[task_id] = {
                "status": "completed",
                "progress": 100,
                "message": f"âœ… Analyse v2 terminÃ©e {enrichment_badge}".strip(),
                "user_id": user_id,
                "result": {
                    "summary_id": summary_id,
                    "video_id": video_id,
                    "video_title": video_info["title"],
                    "word_count": final_word_count,
                    "category": category,
                    "reliability_score": reliability,
                    "v2_options_applied": options,
                    "enrichment": {
                        "level": enrichment_level.value,
                        "sources_count": len(enrichment_sources),
                    } if enrichment_level != EnrichmentLevel.NONE else None
                }
            }

            await update_task_status(
                session, task_id,
                status="completed",
                progress=100,
                result=_task_store[task_id]["result"]
            )

            # Notification SSE
            try:
                await notify_analysis_complete(
                    user_id=user_id,
                    summary_id=summary_id,
                    video_title=video_info["title"],
                    video_id=video_id,
                    cached=False
                )
            except Exception as notify_err:
                print(f"âš ï¸ [v2] Notification failed: {notify_err}", flush=True)

            # Webhook (si configurÃ©)
            webhook_url = options.get("webhook_url")
            if webhook_url:
                try:
                    async with httpx.AsyncClient() as client:
                        await client.post(
                            webhook_url,
                            json={
                                "event": "analysis_complete",
                                "task_id": task_id,
                                "summary_id": summary_id,
                                "video_id": video_id,
                                "status": "completed"
                            },
                            timeout=10.0
                        )
                    print(f"ğŸ”” [v2] Webhook sent to {webhook_url}", flush=True)
                except Exception as webhook_err:
                    print(f"âš ï¸ [v2] Webhook failed: {webhook_err}", flush=True)

            print(f"âœ… [v2.0] Task completed: {task_id}", flush=True)

    except Exception as e:
        error_msg = str(e)
        print(f"âŒ [v2] Analysis error for task {task_id}: {error_msg}", flush=True)

        if SECURITY_AVAILABLE:
            await release_reserved_credits(user_id, task_id)

        _task_store[task_id] = {
            "status": "failed",
            "progress": 0,
            "message": f"Error: {error_msg}",
            "user_id": user_id,
            "error": error_msg
        }

        try:
            await notify_analysis_failed(
                user_id=user_id,
                video_title=video_info.get("title", "VidÃ©o") if 'video_info' in dir() else "VidÃ©o",
                error=error_msg[:200]
            )
        except Exception:
            pass

        try:
            async with async_session_maker() as session:
                await update_task_status(session, task_id, status="failed", progress=0, error=error_msg)
        except Exception:
            pass


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• ANALYSE V2.1 â€” Customization AVANCÃ‰E avec anti-AI, commentaires, etc.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.post("/analyze/v2.1")
async def analyze_video_v2_1(
    request: AnalyzeRequestV2 if ADVANCED_ANALYSIS_AVAILABLE else AnalyzeVideoV2Request,
    background_tasks: BackgroundTasks,
    current_user: User = Depends(check_daily_limit),
    session: AsyncSession = Depends(get_session)
):
    """
    ğŸ†• v2.1: Analyse vidÃ©o avec TOUTES les options de personnalisation avancÃ©es.

    FonctionnalitÃ©s exclusives v2.1:
    - ğŸ”’ Anti-dÃ©tection IA (humanisation du texte)
    - ğŸ¨ Styles d'Ã©criture (acadÃ©mique, journalistique, conversationnel...)
    - ğŸ’¬ Analyse des commentaires YouTube
    - ğŸ“Š MÃ©tadonnÃ©es enrichies (sponsorship, propagande, figures publiques)
    - ğŸ¯ Analyse de l'intention de publication
    - âœï¸ Prompts personnalisÃ©s

    SÃ‰CURITÃ‰:
    - Email vÃ©rifiÃ© obligatoire
    - Pro/Expert requis pour certaines fonctionnalitÃ©s
    - Rate limiting appliquÃ©
    """
    print(f"ğŸ“¥ [v2.1] Advanced analyze request: {request.url} by user {current_user.id}", flush=True)

    if not ADVANCED_ANALYSIS_AVAILABLE:
        raise HTTPException(status_code=501, detail={
            "code": "feature_unavailable",
            "message": "Advanced analysis features are not available"
        })

    # Extraire l'ID vidÃ©o
    video_id = extract_video_id(request.url)
    if not video_id:
        raise HTTPException(status_code=400, detail={
            "code": "invalid_url",
            "message": "Invalid YouTube URL"
        })

    # DÃ©terminer le modÃ¨le
    plan_limits = PLAN_LIMITS.get(current_user.plan, PLAN_LIMITS["free"])
    model = request.model or plan_limits.get("default_model", "mistral-small-latest")

    # VÃ©rifier que le modÃ¨le est autorisÃ©
    allowed_models = plan_limits.get("models", ["mistral-small-latest"])
    if model not in allowed_models:
        model = allowed_models[0]

    # Options de customization
    customization = request.customization or AnalysisCustomization()
    
    # VÃ©rifier les permissions pour fonctionnalitÃ©s avancÃ©es
    is_premium = current_user.plan in ["pro", "expert", "unlimited"]
    
    # Anti-AI detection: Pro/Expert only
    if customization.anti_ai_detection and not is_premium:
        customization.anti_ai_detection = False
        print(f"âš ï¸ [v2.1] Anti-AI disabled (requires Pro/Expert)", flush=True)
    
    # Analyse des commentaires: Pro/Expert only
    if customization.analyze_comments and not is_premium:
        customization.analyze_comments = False
        print(f"âš ï¸ [v2.1] Comments analysis disabled (requires Pro/Expert)", flush=True)
    
    # Analyse de propagande: Expert only
    if customization.detect_propaganda and current_user.plan not in ["expert", "unlimited"]:
        customization.detect_propaganda = False
        print(f"âš ï¸ [v2.1] Propaganda analysis disabled (requires Expert)", flush=True)
    
    # Analyse d'intention: Pro/Expert only
    if customization.analyze_publication_intent and not is_premium:
        customization.analyze_publication_intent = False

    # Deep research
    deep_research = request.deep_research and plan_limits.get("deep_research_enabled", False)
    deep_research_cost = plan_limits.get("deep_research_credits_cost", 0) if deep_research else 0

    # Calculer le coÃ»t de base
    if SECURITY_AVAILABLE:
        credit_cost = get_credit_cost("video_analysis", model)
    else:
        credit_cost = 1
    credit_cost += deep_research_cost

    # CoÃ»ts supplÃ©mentaires pour options avancÃ©es
    if request.generate_toc:
        credit_cost += 1
    if request.summary_length == "detailed":
        credit_cost += 1
    if customization.analyze_comments:
        credit_cost += 2  # Analyse des commentaires coÃ»te 2 crÃ©dits
    if customization.anti_ai_detection and customization.humanize_level >= 2:
        credit_cost += 1  # Humanisation forte coÃ»te 1 crÃ©dit
    if customization.detect_propaganda:
        credit_cost += 1  # Analyse de propagande coÃ»te 1 crÃ©dit

    # VÃ©rifier les crÃ©dits
    if SECURITY_AVAILABLE:
        can_analyze, reason, info = await secure_check_can_analyze(
            session, current_user.id, model
        )
    else:
        can_analyze, reason, credits_remaining, estimated_cost = await check_can_analyze(session, current_user.id)
        info = {"credits": credits_remaining, "cost": estimated_cost}

    if not can_analyze:
        raise HTTPException(status_code=403, detail={
            "code": reason,
            "message": info.get("message", f"Cannot analyze: {reason}"),
            "credits": info.get("credits", 0),
            "cost": credit_cost,
            **info
        })

    # VÃ©rifier le cache (sauf si force_refresh)
    if not request.force_refresh:
        existing = await get_summary_by_video_id(session, video_id, current_user.id)
        if existing and existing.mode == request.mode:
            from datetime import timedelta
            cache_age = datetime.now() - existing.created_at
            if cache_age < timedelta(days=7):
                print(f"ğŸ’¾ [CACHE HIT] v2.1: summary_id={existing.id}", flush=True)
                return {
                    "task_id": f"cached_{existing.id}",
                    "status": "completed",
                    "progress": 100,
                    "message": "âœ… Analyse retrouvÃ©e en cache (gratuit!)",
                    "cost": 0,
                    "video_info": {
                        "video_id": existing.video_id,
                        "title": existing.video_title,
                        "channel": existing.video_channel,
                    },
                    "applied_customization": None,
                    "comments_analysis": None
                }

    # GÃ©nÃ©rer l'ID de tÃ¢che
    if SECURITY_AVAILABLE:
        task_id = generate_secure_operation_id(current_user.id, "video_analysis_v2.1")
    else:
        task_id = str(uuid4())

    # RÃ©server les crÃ©dits
    if SECURITY_AVAILABLE:
        reserved, reserve_reason, reserve_info = await reserve_credits(
            session, current_user.id, credit_cost, task_id, "video_analysis_v2.1"
        )
        if not reserved:
            raise HTTPException(status_code=403, detail={
                "code": reserve_reason,
                "message": f"Could not reserve credits: {reserve_reason}",
                **reserve_info
            })
        print(f"ğŸ”’ [v2.1] Credits reserved: {credit_cost} for task {task_id[:12]}", flush=True)

    # PrÃ©parer les options complÃ¨tes
    full_options = {
        "summary_length": request.summary_length,
        "highlight_key_points": request.highlight_key_points,
        "generate_toc": request.generate_toc,
        "include_entities": request.include_entities,
        "include_timestamps": request.include_timestamps,
        "include_reliability": request.include_reliability,
        "priority": request.priority if is_premium else "normal",
        "webhook_url": request.webhook_url,
        # v2.1 specific options
        "customization": {
            "user_prompt": customization.user_prompt,
            "writing_style": customization.writing_style.value if customization.writing_style else "neutral",
            "anti_ai_detection": customization.anti_ai_detection,
            "humanize_level": customization.humanize_level,
            "focus_topics": customization.focus_topics,
            "exclude_topics": customization.exclude_topics,
            "target_audience": customization.target_audience,
            "expertise_level": customization.expertise_level,
            "include_quotes": customization.include_quotes,
            "include_statistics": customization.include_statistics,
            "bullet_points_preferred": customization.bullet_points_preferred,
            "analyze_comments": customization.analyze_comments,
            "comments_limit": customization.comments_limit,
            "detect_sponsorship": customization.detect_sponsorship,
            "detect_propaganda": customization.detect_propaganda,
            "extract_public_figures": customization.extract_public_figures,
            "analyze_publication_intent": customization.analyze_publication_intent
        }
    }

    # Stocker la tÃ¢che
    _task_store[task_id] = {
        "status": "pending",
        "progress": 0,
        "message": "Initializing v2.1 advanced analysis...",
        "user_id": current_user.id,
        "video_id": video_id,
        "credit_cost": credit_cost,
        "deep_research": deep_research,
        "v2_1_options": full_options
    }

    print(f"ğŸš€ [v2.1] Task created: {task_id} with advanced options", flush=True)

    # CrÃ©er en DB
    await create_task(session, task_id, current_user.id, "video_analysis_v2.1")

    # Estimer la durÃ©e
    estimated_duration = 45  # Base
    if request.summary_length == "detailed":
        estimated_duration += 20
    if deep_research:
        estimated_duration += 30
    if customization.analyze_comments:
        estimated_duration += 20
    if customization.detect_propaganda:
        estimated_duration += 10

    # Lancer l'analyse en background
    background_tasks.add_task(
        _analyze_video_background_v2_1,
        task_id=task_id,
        video_id=video_id,
        url=request.url,
        mode=request.mode,
        category=request.category,
        lang=request.lang,
        model=model,
        user_id=current_user.id,
        user_plan=current_user.plan,
        credit_cost=credit_cost,
        deep_research=deep_research,
        options=full_options
    )

    return {
        "task_id": task_id,
        "status": "pending",
        "progress": 0,
        "message": "Analysis v2.1 started with advanced customization",
        "estimated_duration_seconds": estimated_duration,
        "cost": credit_cost,
        "applied_customization": full_options.get("customization"),
        "comments_analysis": None
    }


async def _analyze_video_background_v2_1(
    task_id: str,
    video_id: str,
    url: str,
    mode: str,
    category: Optional[str],
    lang: str,
    model: str,
    user_id: int,
    user_plan: str,
    credit_cost: int,
    deep_research: bool,
    options: Dict[str, Any]
):
    """
    ğŸ†• v2.1: Background analysis avec TOUTES les fonctionnalitÃ©s avancÃ©es.

    Nouvelles fonctionnalitÃ©s:
    - ğŸ”’ Anti-dÃ©tection IA avec humanisation
    - ğŸ¨ Styles d'Ã©criture personnalisÃ©s
    - ğŸ’¬ Analyse des commentaires YouTube
    - ğŸ“Š MÃ©tadonnÃ©es enrichies
    - ğŸ¯ Analyse d'intention de publication
    """
    from db.database import async_session_maker
    import httpx

    print(f"ğŸ”§ [v2.1] Advanced background task started: {task_id}", flush=True)

    # Extraire les options de customization
    custom_opts = options.get("customization", {})
    
    # DÃ©terminer le niveau d'enrichissement
    if deep_research:
        enrichment_level = EnrichmentLevel.DEEP
    else:
        enrichment_level = get_enrichment_level(user_plan)

    # Variables pour les rÃ©sultats
    comments_analysis_result = None
    metadata_enriched_result = None
    video_info = None

    try:
        async with async_session_maker() as session:
            _task_store[task_id]["status"] = "processing"
            _task_store[task_id]["progress"] = 3
            _task_store[task_id]["message"] = "ğŸš€ DÃ©marrage de l'analyse avancÃ©e v2.1..."

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 1. RÃ‰CUPÃ‰RER LES INFOS VIDÃ‰O
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            _task_store[task_id]["progress"] = 8
            _task_store[task_id]["message"] = "ğŸ“º RÃ©cupÃ©ration des infos vidÃ©o..."

            video_info = await get_video_info(video_id)
            if not video_info:
                raise Exception("Could not fetch video info")

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 2. EXTRAIRE LA TRANSCRIPTION
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            _task_store[task_id]["progress"] = 15
            _task_store[task_id]["message"] = "ğŸ“ Extraction du transcript..."

            transcript, transcript_timestamped, detected_lang = await get_transcript_with_timestamps(video_id)
            if not transcript:
                raise Exception("No transcript available for this video")

            if not lang or lang == "auto":
                lang = detected_lang or "fr"

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 3. DÃ‰TECTER LA CATÃ‰GORIE
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            _task_store[task_id]["progress"] = 22
            _task_store[task_id]["message"] = "ğŸ·ï¸ DÃ©tection de la catÃ©gorie..."

            if not category or category == "auto":
                category, confidence = detect_category(
                    title=video_info["title"],
                    description=video_info.get("description", ""),
                    transcript=transcript[:3000],
                    channel=video_info.get("channel", ""),
                    tags=video_info.get("tags", []),
                    youtube_categories=video_info.get("categories", [])
                )
            else:
                confidence = 0.9

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 4. ğŸ†• ANALYSE DES COMMENTAIRES (si activÃ©e)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if custom_opts.get("analyze_comments", False):
                _task_store[task_id]["progress"] = 28
                _task_store[task_id]["message"] = "ğŸ’¬ Analyse des commentaires YouTube..."
                
                try:
                    comments_limit = custom_opts.get("comments_limit", 100)
                    comments_analysis_result = await analyze_comments(
                        video_id=video_id,
                        limit=comments_limit,
                        use_ai=True,
                        video_title=video_info["title"],
                        lang=lang,
                        model=model
                    )
                    print(f"âœ… [v2.1] Comments analysis: {comments_analysis_result.analyzed_count} comments", flush=True)
                except Exception as e:
                    print(f"âš ï¸ [v2.1] Comments analysis failed: {e}", flush=True)

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 5. ğŸ†• MÃ‰TADONNÃ‰ES ENRICHIES
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            _task_store[task_id]["progress"] = 35
            _task_store[task_id]["message"] = "ğŸ“Š Extraction des mÃ©tadonnÃ©es enrichies..."
            
            try:
                metadata_enriched_result = await get_enriched_metadata(
                    video_id=video_id,
                    title=video_info["title"],
                    description=video_info.get("description", ""),
                    transcript=transcript[:5000],
                    channel=video_info.get("channel", ""),
                    tags=video_info.get("tags", []),
                    category=category,
                    analyze_propaganda=custom_opts.get("detect_propaganda", False),
                    analyze_intent=custom_opts.get("analyze_publication_intent", False),
                    extract_figures=custom_opts.get("extract_public_figures", True),
                    lang=lang
                )
                print(f"âœ… [v2.1] Metadata enriched: sponsorship={metadata_enriched_result.sponsorship.type.value}", flush=True)
            except Exception as e:
                print(f"âš ï¸ [v2.1] Metadata enrichment failed: {e}", flush=True)

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 6. ENRICHISSEMENT WEB
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            web_context = None
            enrichment_sources = []

            if enrichment_level != EnrichmentLevel.NONE:
                _task_store[task_id]["progress"] = 42
                _task_store[task_id]["message"] = f"ğŸŒ Recherche web ({enrichment_level.value})..."

                try:
                    web_context, enrichment_sources, actual_level = await get_pre_analysis_context(
                        video_title=video_info["title"],
                        video_channel=video_info.get("channel", ""),
                        category=category,
                        transcript=transcript,
                        plan=user_plan,
                        lang=lang
                    )
                except Exception as e:
                    print(f"âš ï¸ [v2.1] Web enrichment failed: {e}", flush=True)

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 7. ğŸ†• CONSTRUIRE LE PROMPT PERSONNALISÃ‰
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            _task_store[task_id]["progress"] = 50
            _task_store[task_id]["message"] = "ğŸ§  Construction du prompt personnalisÃ©..."

            # Instructions de base selon les options
            base_instructions = []
            
            if options.get("summary_length") == "short":
                base_instructions.append("Fais un rÃ©sumÃ© COURT et CONCIS (max 500 mots).")
            elif options.get("summary_length") == "detailed":
                base_instructions.append("Fais un rÃ©sumÃ© DÃ‰TAILLÃ‰ et EXHAUSTIF (1500+ mots).")

            if options.get("highlight_key_points"):
                base_instructions.append("Mets en Ã©vidence les points clÃ©s avec des marqueurs **gras**.")

            if options.get("generate_toc"):
                base_instructions.append("Commence par une table des matiÃ¨res structurÃ©e.")

            if custom_opts.get("include_quotes", True):
                base_instructions.append("Inclus des citations directes pertinentes de la vidÃ©o.")

            if custom_opts.get("include_statistics", True):
                base_instructions.append("Mentionne les statistiques et chiffres importants.")

            if custom_opts.get("bullet_points_preferred", False):
                base_instructions.append("Utilise des listes Ã  puces quand c'est pertinent.")

            base_prompt = "\n".join(base_instructions) if base_instructions else ""

            # Utiliser le module anti_ai_prompts pour construire le prompt complet
            writing_style = WritingStyle(custom_opts.get("writing_style", "neutral"))
            
            customized_prompt = build_customized_prompt(
                base_prompt=base_prompt,
                writing_style=writing_style,
                anti_ai_detection=custom_opts.get("anti_ai_detection", False),
                humanize_level=custom_opts.get("humanize_level", 0),
                user_prompt=custom_opts.get("user_prompt"),
                target_audience=custom_opts.get("target_audience"),
                focus_topics=custom_opts.get("focus_topics", []),
                exclude_topics=custom_opts.get("exclude_topics", []),
                lang=lang
            )

            # Combiner avec le contexte web
            full_context = None
            if web_context and customized_prompt:
                full_context = f"{web_context}\n\n{customized_prompt}"
            elif web_context:
                full_context = web_context
            elif customized_prompt:
                full_context = customized_prompt

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 8. GÃ‰NÃ‰RER LE RÃ‰SUMÃ‰
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            _task_store[task_id]["progress"] = 58
            _task_store[task_id]["message"] = "ğŸ§  GÃ©nÃ©ration du rÃ©sumÃ© personnalisÃ©..."

            transcript_to_analyze = transcript_timestamped or transcript
            video_duration = video_info.get("duration", 0)
            needs_chunk, word_count, chunk_reason = needs_chunking(transcript_to_analyze)

            if needs_chunk:
                _task_store[task_id]["message"] = f"ğŸ“š VidÃ©o longue ({word_count} mots)..."

                def update_progress(progress: int, message: str):
                    _task_store[task_id]["progress"] = progress
                    _task_store[task_id]["message"] = message

                summary_content = await analyze_long_video(
                    title=video_info["title"],
                    transcript=transcript_to_analyze,
                    video_duration=video_duration,
                    category=category,
                    lang=lang,
                    mode=mode,
                    model=model,
                    web_context=full_context,
                    progress_callback=update_progress,
                    transcript_timestamped=transcript_timestamped
                )
            else:
                summary_content = await generate_summary(
                    title=video_info["title"],
                    transcript=transcript_to_analyze,
                    category=category,
                    lang=lang,
                    mode=mode,
                    model=model,
                    duration=video_duration,
                    channel=video_info.get("channel", ""),
                    description=video_info.get("description", ""),
                    web_context=full_context
                )

            if not summary_content:
                raise Exception("Failed to generate summary")

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 9. EXTRAIRE LES ENTITÃ‰S
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            entities = None
            if options.get("include_entities", True):
                _task_store[task_id]["progress"] = 75
                _task_store[task_id]["message"] = "ğŸ” Extraction des entitÃ©s..."
                entities = await extract_entities(summary_content, lang=lang)

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 10. CALCULER LA FIABILITÃ‰
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            reliability = None
            if options.get("include_reliability", True):
                _task_store[task_id]["progress"] = 82
                _task_store[task_id]["message"] = "âš–ï¸ Calcul du score de fiabilitÃ©..."
                reliability = await calculate_reliability_score(summary_content, entities or {}, lang=lang)

                # Bonus si enrichi avec web
                if enrichment_sources:
                    reliability_bonus = {
                        EnrichmentLevel.FULL: 8,
                        EnrichmentLevel.DEEP: 15
                    }.get(enrichment_level, 0)
                    reliability = min(98, reliability + reliability_bonus)

                # Malus si propagande dÃ©tectÃ©e
                if metadata_enriched_result and metadata_enriched_result.propaganda_analysis:
                    prop = metadata_enriched_result.propaganda_analysis
                    if prop.risk_level.value in ["high", "critical"]:
                        reliability = max(20, reliability - 20)
                    elif prop.risk_level.value == "medium":
                        reliability = max(30, reliability - 10)

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 11. SAUVEGARDER
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            _task_store[task_id]["progress"] = 90
            _task_store[task_id]["message"] = "ğŸ’¾ Sauvegarde des rÃ©sultats..."

            if SECURITY_AVAILABLE:
                await consume_reserved_credits(
                    session, user_id, task_id,
                    f"Video v2.1: {video_info['title'][:50]} ({model})"
                )
            else:
                await deduct_credit(session, user_id, credit_cost, f"Video v2.1: {video_info['title'][:50]}")

            # PrÃ©parer les mÃ©tadonnÃ©es d'enrichissement
            enrichment_metadata = {
                "level": enrichment_level.value,
                "sources": enrichment_sources,
                "enriched_at": datetime.utcnow().isoformat(),
                "v2_1_options": options,
                "comments_analyzed": comments_analysis_result.analyzed_count if comments_analysis_result else 0,
                "sponsorship_detected": metadata_enriched_result.sponsorship.type.value if metadata_enriched_result else None,
                "propaganda_risk": metadata_enriched_result.propaganda_analysis.risk_level.value if metadata_enriched_result and metadata_enriched_result.propaganda_analysis else None
            }

            summary_id = await save_summary(
                session=session,
                user_id=user_id,
                video_id=video_id,
                video_title=video_info["title"],
                video_channel=video_info.get("channel", "Unknown"),
                video_duration=video_info.get("duration", 0),
                video_url=url,
                thumbnail_url=video_info.get("thumbnail_url", f"https://img.youtube.com/vi/{video_id}/mqdefault.jpg"),
                category=category,
                category_confidence=confidence,
                lang=lang,
                mode=mode,
                model_used=model,
                summary_content=summary_content,
                transcript_context=transcript_timestamped or transcript,
                video_upload_date=video_info.get("upload_date"),
                entities_extracted=entities,
                reliability_score=reliability,
                enrichment_data=enrichment_metadata
            )

            # IncrÃ©menter le quota
            try:
                from core.plan_limits import increment_daily_usage
                await increment_daily_usage(session, user_id)
            except Exception as quota_err:
                print(f"âš ï¸ [v2.1] Quota increment failed: {quota_err}", flush=True)

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 12. MARQUER COMME TERMINÃ‰
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            final_word_count = len(summary_content.split())
            enrichment_badge = get_enrichment_badge(enrichment_level, lang)

            # PrÃ©parer le rÃ©sultat des commentaires
            comments_result = None
            if comments_analysis_result:
                comments_result = {
                    "analyzed_count": comments_analysis_result.analyzed_count,
                    "sentiment_distribution": comments_analysis_result.sentiment_distribution,
                    "average_sentiment": comments_analysis_result.average_sentiment,
                    "constructive_ratio": comments_analysis_result.constructive_ratio,
                    "controversy_score": comments_analysis_result.controversy_score,
                    "top_questions": comments_analysis_result.top_questions,
                    "summary": comments_analysis_result.summary
                }

            # PrÃ©parer les mÃ©tadonnÃ©es enrichies
            metadata_result = None
            if metadata_enriched_result:
                metadata_result = {
                    "public_figures": [
                        {"name": f.name, "role": f.role, "organization": f.organization}
                        for f in metadata_enriched_result.public_figures[:10]
                    ],
                    "sponsorship": {
                        "type": metadata_enriched_result.sponsorship.type.value,
                        "brands": metadata_enriched_result.sponsorship.brands,
                        "disclosed": metadata_enriched_result.sponsorship.disclosed
                    },
                    "propaganda_analysis": {
                        "risk_level": metadata_enriched_result.propaganda_analysis.risk_level.value,
                        "techniques": metadata_enriched_result.propaganda_analysis.detected_techniques,
                        "recommendation": metadata_enriched_result.propaganda_analysis.recommendation
                    } if metadata_enriched_result.propaganda_analysis else None,
                    "publication_intent": {
                        "primary": metadata_enriched_result.publication_intent.primary_intent,
                        "educational_score": metadata_enriched_result.publication_intent.educational_score,
                        "commercial_score": metadata_enriched_result.publication_intent.commercial_score
                    } if metadata_enriched_result.publication_intent else None
                }

            _task_store[task_id] = {
                "status": "completed",
                "progress": 100,
                "message": f"âœ… Analyse v2.1 terminÃ©e {enrichment_badge}".strip(),
                "user_id": user_id,
                "result": {
                    "summary_id": summary_id,
                    "video_id": video_id,
                    "video_title": video_info["title"],
                    "word_count": final_word_count,
                    "category": category,
                    "reliability_score": reliability,
                    "v2_1_options_applied": options.get("customization"),
                    "comments_analysis": comments_result,
                    "metadata_enriched": metadata_result,
                    "enrichment": {
                        "level": enrichment_level.value,
                        "sources_count": len(enrichment_sources),
                    } if enrichment_level != EnrichmentLevel.NONE else None
                }
            }

            await update_task_status(
                session, task_id,
                status="completed",
                progress=100,
                result=_task_store[task_id]["result"]
            )

            # Notification SSE
            try:
                await notify_analysis_complete(
                    user_id=user_id,
                    summary_id=summary_id,
                    video_title=video_info["title"],
                    video_id=video_id,
                    cached=False
                )
            except Exception as notify_err:
                print(f"âš ï¸ [v2.1] Notification failed: {notify_err}", flush=True)

            # Webhook
            webhook_url = options.get("webhook_url")
            if webhook_url:
                try:
                    async with httpx.AsyncClient() as client:
                        await client.post(
                            webhook_url,
                            json={
                                "event": "analysis_complete",
                                "task_id": task_id,
                                "summary_id": summary_id,
                                "video_id": video_id,
                                "status": "completed",
                                "version": "v2.1"
                            },
                            timeout=10.0
                        )
                    print(f"ğŸ”” [v2.1] Webhook sent to {webhook_url}", flush=True)
                except Exception as webhook_err:
                    print(f"âš ï¸ [v2.1] Webhook failed: {webhook_err}", flush=True)

            print(f"âœ… [v2.1] Task completed: {task_id}", flush=True)

    except Exception as e:
        error_msg = str(e)
        print(f"âŒ [v2.1] Analysis error for task {task_id}: {error_msg}", flush=True)

        if SECURITY_AVAILABLE:
            await release_reserved_credits(user_id, task_id)

        _task_store[task_id] = {
            "status": "failed",
            "progress": 0,
            "message": f"Error: {error_msg}",
            "user_id": user_id,
            "error": error_msg
        }

        try:
            await notify_analysis_failed(
                user_id=user_id,
                video_title=video_info.get("title", "VidÃ©o") if video_info else "VidÃ©o",
                error=error_msg[:200]
            )
        except Exception:
            pass

        try:
            async with async_session_maker() as session:
                await update_task_status(session, task_id, status="failed", progress=0, error=error_msg)
        except Exception:
            pass


async def _analyze_video_background_v6(
    task_id: str,
    video_id: str,
    url: str,
    mode: str,
    category: Optional[str],
    lang: str,
    model: str,
    user_id: int,
    user_plan: str,
    credit_cost: int,
    deep_research: bool = False  # ğŸ†• v5.5
):
    """
    ğŸ” Fonction d'analyse v6.0 avec SÃ‰CURITÃ‰ RENFORCÃ‰E.
    
    SÃ‰CURITÃ‰:
    - CrÃ©dits rÃ©servÃ©s AVANT (dans l'endpoint)
    - CrÃ©dits consommÃ©s uniquement si SUCCÃˆS
    - CrÃ©dits libÃ©rÃ©s si Ã‰CHEC
    
    ğŸ“Š Ã‰tapes:
    1. RÃ©cupÃ©rer les infos vidÃ©o
    2. Extraire la transcription
    3. DÃ©tecter la catÃ©gorie
    4. Enrichir le contexte avec Perplexity (Pro/Expert)
    5. GÃ©nÃ©rer le rÃ©sumÃ© (Mistral)
    6. Extraire les entitÃ©s
    7. Calculer le score de fiabilitÃ©
    8. âœ… Consommer les crÃ©dits
    9. Sauvegarder
    """
    from db.database import async_session_maker
    
    print(f"ğŸ”§ [v6.0] Background task started: {task_id} (deep_research={deep_research})", flush=True)
    
    # ğŸ†• v5.5: Si deep_research activÃ©, utiliser enrichissement maximal
    if deep_research:
        enrichment_level = EnrichmentLevel.DEEP
        print(f"ğŸ”¬ [v5.5] Deep research enabled - using DEEP enrichment", flush=True)
    else:
        # DÃ©terminer le niveau d'enrichissement selon le plan
        enrichment_level = get_enrichment_level(user_plan)
    print(f"ğŸŒ [v6.0] Enrichment level: {enrichment_level.value} for plan {user_plan}", flush=True)
    
    try:
        async with async_session_maker() as session:
            # Update status
            _task_store[task_id]["status"] = "processing"
            _task_store[task_id]["progress"] = 5
            _task_store[task_id]["message"] = "ğŸš€ DÃ©marrage de l'analyse..."
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 1. RÃ‰CUPÃ‰RER LES INFOS VIDÃ‰O
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            _task_store[task_id]["progress"] = 10
            _task_store[task_id]["message"] = "ğŸ“º RÃ©cupÃ©ration des infos vidÃ©o..."
            
            print(f"ğŸ“º Fetching video info for {video_id}...", flush=True)
            video_info = await get_video_info(video_id)
            if not video_info:
                raise Exception("Could not fetch video info")
            
            print(f"âœ… Video info: {video_info.get('title', 'Unknown')[:50]}", flush=True)
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 2. EXTRAIRE LA TRANSCRIPTION
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            _task_store[task_id]["progress"] = 20
            _task_store[task_id]["message"] = "ğŸ“ Extraction du transcript..."
            
            transcript, transcript_timestamped, detected_lang = await get_transcript_with_timestamps(video_id)
            
            if not transcript:
                raise Exception("No transcript available for this video")
            
            print(f"âœ… Transcript: {len(transcript)} chars", flush=True)
            
            # Utiliser la langue dÃ©tectÃ©e si pas spÃ©cifiÃ©e
            if not lang or lang == "auto":
                lang = detected_lang or "fr"
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 3. DÃ‰TECTER LA CATÃ‰GORIE (ğŸ†• v3.0: avec mÃ©tadonnÃ©es enrichies)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            _task_store[task_id]["progress"] = 30
            _task_store[task_id]["message"] = "ğŸ·ï¸ DÃ©tection de la catÃ©gorie..."
            
            if not category or category == "auto":
                # ğŸ†• v3.0: Passer TOUTES les mÃ©tadonnÃ©es pour une meilleure dÃ©tection
                category, confidence = detect_category(
                    title=video_info["title"],
                    description=video_info.get("description", ""),
                    transcript=transcript[:3000],
                    channel=video_info.get("channel", ""),
                    tags=video_info.get("tags", []),
                    youtube_categories=video_info.get("categories", [])
                )
                print(f"ğŸ·ï¸ Auto-detected category: {category} ({confidence:.0%})", flush=True)
            else:
                confidence = 0.9
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 4. ğŸ†• ENRICHIR LE CONTEXTE AVEC PERPLEXITY (AVANT Mistral)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            web_context = None
            enrichment_sources = []
            
            if enrichment_level != EnrichmentLevel.NONE:
                _task_store[task_id]["progress"] = 40
                _task_store[task_id]["message"] = f"ğŸŒ Recherche web prÃ©liminaire ({enrichment_level.value})..."
                
                print(f"ğŸŒ [v5.0] PRE-ANALYSIS: Fetching web context from Perplexity...", flush=True)
                
                try:
                    web_context, enrichment_sources, actual_level = await get_pre_analysis_context(
                        video_title=video_info["title"],
                        video_channel=video_info.get("channel", ""),
                        category=category,
                        transcript=transcript,
                        plan=user_plan,
                        lang=lang
                    )
                    
                    if web_context:
                        print(f"âœ… [v5.0] PRE-ANALYSIS: Got {len(web_context)} chars of web context", flush=True)
                        print(f"âœ… [v5.0] PRE-ANALYSIS: {len(enrichment_sources)} sources found", flush=True)
                    else:
                        print(f"âš ï¸ [v5.0] PRE-ANALYSIS: No web context returned", flush=True)
                        
                except Exception as e:
                    print(f"âš ï¸ [v5.0] PRE-ANALYSIS failed (continuing without): {e}", flush=True)
                    web_context = None
                    enrichment_sources = []
            else:
                print(f"â­ï¸ [v5.0] Skipping web enrichment (plan={user_plan})", flush=True)
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 5. GÃ‰NÃ‰RER LE RÃ‰SUMÃ‰ (MISTRAL) AVEC CONTEXTE WEB
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            _task_store[task_id]["progress"] = 55
            
            # DÃ©terminer le modÃ¨le selon le plan
            plan_limits = PLAN_LIMITS.get(user_plan, PLAN_LIMITS["free"])
            if not model:
                model = plan_limits.get("default_model", "mistral-small-latest")
            
            # VÃ©rifier que le modÃ¨le est autorisÃ©
            allowed_models = plan_limits.get("models", ["mistral-small-latest"])
            if model not in allowed_models:
                model = allowed_models[0]
            
            # ğŸ†• v7.0: DÃ‰TECTION VIDÃ‰O LONGUE ET CHUNKING
            transcript_to_analyze = transcript_timestamped or transcript
            video_duration = video_info.get("duration", 0)
            
            needs_chunk, word_count, chunk_reason = needs_chunking(transcript_to_analyze)
            
            if needs_chunk:
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ğŸ“š VIDÃ‰O LONGUE â€” Analyse par chunks
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                print(f"ğŸ“š [v7.0] LONG VIDEO DETECTED: {word_count} words ({chunk_reason})", flush=True)
                _task_store[task_id]["message"] = f"ğŸ“š VidÃ©o longue dÃ©tectÃ©e ({word_count} mots)..."
                
                # Fonction de callback pour le progress
                def update_progress(progress: int, message: str):
                    _task_store[task_id]["progress"] = progress
                    _task_store[task_id]["message"] = message
                
                # ğŸ†• v3.0: Analyser avec les VRAIS timestamps YouTube
                summary_content = await analyze_long_video(
                    title=video_info["title"],
                    transcript=transcript_to_analyze,
                    video_duration=video_duration,
                    category=category,
                    lang=lang,
                    mode=mode,
                    model=model,
                    web_context=web_context,
                    progress_callback=update_progress,
                    transcript_timestamped=transcript_timestamped  # ğŸ†• Vrais timestamps!
                )
                
                if not summary_content:
                    print("âš ï¸ [v7.0] Chunking failed, falling back to truncated analysis", flush=True)
                    # Fallback: analyser seulement les premiers 8000 mots
                    truncated_transcript = " ".join(transcript_to_analyze.split()[:8000])
                    summary_content = await generate_summary(
                        title=video_info["title"],
                        transcript=truncated_transcript,
                        category=category,
                        lang=lang,
                        mode=mode,
                        model=model,
                        duration=video_duration,
                        channel=video_info.get("channel", ""),
                        description=video_info.get("description", "") + "\n\nâš ï¸ NOTE: Cette vidÃ©o est trÃ¨s longue. Seule la premiÃ¨re partie a Ã©tÃ© analysÃ©e.",
                        web_context=web_context
                    )
            else:
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # ğŸ“ VIDÃ‰O STANDARD â€” Analyse directe
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                if web_context:
                    _task_store[task_id]["message"] = "ğŸ§  GÃ©nÃ©ration du rÃ©sumÃ© enrichi avec l'IA..."
                else:
                    _task_store[task_id]["message"] = "ğŸ§  GÃ©nÃ©ration du rÃ©sumÃ© avec l'IA..."
                
                print(f"ğŸ§  Generating summary with {model}...", flush=True)
                if web_context:
                    print(f"ğŸŒ [v5.0] Including {len(web_context)} chars of web context in Mistral prompt", flush=True)
                
                summary_content = await generate_summary(
                    title=video_info["title"],
                    transcript=transcript_to_analyze,
                    category=category,
                    lang=lang,
                    mode=mode,
                    model=model,
                    duration=video_duration,
                    channel=video_info.get("channel", ""),
                    description=video_info.get("description", ""),
                    web_context=web_context
                )
            
            if not summary_content:
                raise Exception("Failed to generate summary")
            
            final_word_count = len(summary_content.split())
            print(f"âœ… Summary generated: {final_word_count} words", flush=True)
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 6. EXTRAIRE LES ENTITÃ‰S
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            _task_store[task_id]["progress"] = 75
            _task_store[task_id]["message"] = "ğŸ” Extraction des entitÃ©s..."
            
            entities = await extract_entities(summary_content, lang=lang)
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 7. CALCULER LE SCORE DE FIABILITÃ‰
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            _task_store[task_id]["progress"] = 85
            _task_store[task_id]["message"] = "âš–ï¸ Calcul du score de fiabilitÃ©..."
            
            reliability = await calculate_reliability_score(summary_content, entities, lang=lang)
            
            # Bonus de fiabilitÃ© si enrichi avec Perplexity (PRÃ‰-ANALYSE)
            if enrichment_sources:
                reliability_bonus = {
                    EnrichmentLevel.FULL: 8,   # Pro: +8
                    EnrichmentLevel.DEEP: 15   # Expert: +15
                }.get(enrichment_level, 0)
                reliability = min(98, reliability + reliability_bonus)
                print(f"ğŸ¯ [v5.0] Reliability boosted by {reliability_bonus} (web-enriched analysis)", flush=True)
            
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 8. SAUVEGARDER LE RÃ‰SUMÃ‰
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            _task_store[task_id]["progress"] = 92
            _task_store[task_id]["message"] = "ğŸ’¾ Sauvegarde des rÃ©sultats..."
            
            # ğŸ” CONSOMMER les crÃ©dits rÃ©servÃ©s (succÃ¨s de l'opÃ©ration)
            if SECURITY_AVAILABLE:
                await consume_reserved_credits(
                    session, user_id, task_id,
                    f"Video: {video_info['title'][:50]} ({model})"
                )
            else:
                await deduct_credit(session, user_id, credit_cost, f"Video: {video_info['title'][:50]}")
            
            # PrÃ©parer les mÃ©tadonnÃ©es d'enrichissement
            enrichment_metadata = None
            if enrichment_sources:
                enrichment_metadata = {
                    "level": enrichment_level.value,
                    "sources": enrichment_sources,
                    "enriched_at": datetime.utcnow().isoformat()
                }
            
            # Sauvegarder le rÃ©sumÃ©
            summary_id = await save_summary(
                session=session,
                user_id=user_id,
                video_id=video_id,
                video_title=video_info["title"],
                video_channel=video_info.get("channel", "Unknown"),
                video_duration=video_info.get("duration", 0),
                video_url=url,
                thumbnail_url=video_info.get("thumbnail_url", f"https://img.youtube.com/vi/{video_id}/mqdefault.jpg"),
                category=category,
                category_confidence=confidence,
                lang=lang,
                mode=mode,
                model_used=model,
                summary_content=summary_content,
                transcript_context=transcript_timestamped or transcript,
                video_upload_date=video_info.get("upload_date"),
                entities_extracted=entities,
                reliability_score=reliability,
                # ğŸ†• MÃ©tadonnÃ©es d'enrichissement
                enrichment_data=enrichment_metadata
            )
            
            print(f"ğŸ’¾ Summary saved: id={summary_id}", flush=True)

            # ğŸ« IncrÃ©menter le compteur quotidien d'analyses
            try:
                from core.plan_limits import increment_daily_usage
                daily_count = await increment_daily_usage(session, user_id)
                print(f"ğŸ“Š [QUOTA] User {user_id} daily usage: {daily_count}", flush=True)
            except Exception as quota_err:
                print(f"âš ï¸ [QUOTA] Failed to increment daily usage: {quota_err}", flush=True)

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # 9. MARQUER COMME TERMINÃ‰
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            enrichment_badge = get_enrichment_badge(enrichment_level, lang)
            
            _task_store[task_id] = {
                "status": "completed",
                "progress": 100,
                "message": f"âœ… Analyse terminÃ©e {enrichment_badge}".strip(),
                "user_id": user_id,
                "result": {
                    "summary_id": summary_id,
                    "video_id": video_id,
                    "video_title": video_info["title"],
                    "video_channel": video_info.get("channel", "Unknown"),
                    "thumbnail_url": video_info.get("thumbnail_url", f"https://img.youtube.com/vi/{video_id}/mqdefault.jpg"),
                    "word_count": final_word_count,
                    "category": category,
                    "reliability_score": reliability,
                    "mode": mode,
                    "lang": lang,
                    # ğŸ†• Infos enrichissement
                    "enrichment": {
                        "level": enrichment_level.value,
                        "sources_count": len(enrichment_sources),
                        "badge": enrichment_badge
                    } if enrichment_level != EnrichmentLevel.NONE else None
                }
            }
            
            await update_task_status(
                session, task_id,
                status="completed",
                progress=100,
                result=_task_store[task_id]["result"]
            )
            
            print(f"âœ… [v6.0] Task completed: {task_id}", flush=True)
            if enrichment_level != EnrichmentLevel.NONE:
                print(f"   â””â”€ Enrichment: {enrichment_level.value}, {len(enrichment_sources)} sources", flush=True)
            
            # ğŸ”” NOTIFICATION PUSH â€” Alerter l'utilisateur que l'analyse est prÃªte
            try:
                await notify_analysis_complete(
                    user_id=user_id,
                    summary_id=summary_id,
                    video_title=video_info["title"],
                    video_id=video_id,
                    cached=False
                )
                print(f"ğŸ”” [NOTIFY] Analysis complete notification sent to user {user_id}", flush=True)
            except Exception as notify_err:
                print(f"âš ï¸ [NOTIFY] Failed to send notification: {notify_err}", flush=True)
            
    except Exception as e:
        error_msg = str(e)
        print(f"âŒ Analysis error for task {task_id}: {error_msg}", flush=True)
        
        # ğŸ” LIBÃ‰RER les crÃ©dits rÃ©servÃ©s (Ã©chec de l'opÃ©ration)
        if SECURITY_AVAILABLE:
            await release_reserved_credits(user_id, task_id)
            print(f"ğŸ”“ [SECURITY] Credits released due to failure: task={task_id[:12]}", flush=True)
        
        _task_store[task_id] = {
            "status": "failed",
            "progress": 0,
            "message": f"Error: {error_msg}",
            "user_id": user_id,
            "error": error_msg
        }
        
        # ğŸ”” NOTIFICATION PUSH â€” Alerter l'utilisateur de l'Ã©chec
        try:
            video_title_for_notif = video_info.get("title", "VidÃ©o") if 'video_info' in dir() else "VidÃ©o"
            await notify_analysis_failed(
                user_id=user_id,
                video_title=video_title_for_notif,
                error=error_msg[:200]
            )
            print(f"ğŸ”” [NOTIFY] Analysis failure notification sent to user {user_id}", flush=True)
        except Exception as notify_err:
            print(f"âš ï¸ [NOTIFY] Failed to send failure notification: {notify_err}", flush=True)
        
        try:
            async with async_session_maker() as session:
                await update_task_status(
                    session, task_id,
                    status="failed",
                    progress=0,
                    error=error_msg
                )
        except:
            pass


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š STATUS & POLLING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.get("/status/{task_id}", response_model=TaskStatusResponse)
async def get_task_status(
    task_id: str,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """RÃ©cupÃ¨re le status d'une tÃ¢che d'analyse"""

    # GÃ©rer les task_id de cache (format: cached_<summary_id>)
    if task_id.startswith("cached_"):
        try:
            summary_id = int(task_id.replace("cached_", ""))
            summary = await get_summary_by_id(session, summary_id, current_user.id)
            if summary:
                return TaskStatusResponse(
                    task_id=task_id,
                    status="completed",
                    progress=100,
                    message="âœ… Analyse retrouvÃ©e en cache (gratuit!)",
                    result={
                        "summary_id": summary.id,
                        "cached": True,
                        "video_title": summary.video_title,
                        "category": summary.category,
                        "cost": 0,
                    }
                )
        except (ValueError, Exception):
            pass
        raise HTTPException(status_code=404, detail="Task not found")

    # VÃ©rifier le cache mÃ©moire d'abord
    if task_id in _task_store:
        task = _task_store[task_id]
        
        # VÃ©rifier que c'est bien la tÃ¢che de cet utilisateur
        if task.get("user_id") != current_user.id:
            raise HTTPException(status_code=404, detail="Task not found")
        
        return TaskStatusResponse(
            task_id=task_id,
            status=task.get("status", "unknown"),
            progress=task.get("progress", 0),
            message=task.get("message", ""),
            result=task.get("result"),
            error=task.get("error")
        )
    
    # Sinon chercher en DB
    task_db = await get_task(session, task_id)
    if not task_db or task_db.user_id != current_user.id:
        raise HTTPException(status_code=404, detail="Task not found")
    
    result = None
    if task_db.result:
        try:
            result = json.loads(task_db.result) if isinstance(task_db.result, str) else task_db.result
        except:
            pass
    
    return TaskStatusResponse(
        task_id=task_id,
        status=task_db.status,
        progress=task_db.progress,
        message="",
        result=result,
        error=task_db.error_message
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“‹ RÃ‰SUMÃ‰S
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.get("/summary/{summary_id}")
async def get_summary(
    summary_id: int,
    format: Optional[str] = Query(default=None, description="Format de rÃ©ponse: full (dÃ©faut) ou extension"),
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """
    RÃ©cupÃ¨re un rÃ©sumÃ© par son ID.

    Query params:
        format: "full" (dÃ©faut) retourne l'analyse complÃ¨te,
                "extension" retourne un JSON condensÃ© pour l'extension Chrome.
    """
    summary = await get_summary_by_id(session, summary_id, current_user.id)
    if not summary:
        raise HTTPException(status_code=404, detail="Summary not found")

    # Format condensÃ© pour l'extension Chrome
    if format == "extension":
        return extract_extension_summary(
            summary_id=summary.id,
            summary_content=summary.summary_content,
            video_title=summary.video_title,
            category=summary.category,
            reliability_score=summary.reliability_score,
            tags=summary.tags,
        )

    # Format complet (dÃ©faut)
    entities = None
    if summary.entities_extracted:
        try:
            entities = json.loads(summary.entities_extracted) if isinstance(summary.entities_extracted, str) else summary.entities_extracted
        except:
            pass

    return SummaryResponse(
        id=summary.id,
        video_id=summary.video_id,
        video_title=summary.video_title,
        video_channel=summary.video_channel or "Unknown",
        video_duration=summary.video_duration or 0,
        video_url=summary.video_url or f"https://youtube.com/watch?v={summary.video_id}",
        thumbnail_url=summary.thumbnail_url or f"https://img.youtube.com/vi/{summary.video_id}/mqdefault.jpg",
        category=summary.category,
        category_confidence=summary.category_confidence,
        lang=summary.lang,
        mode=summary.mode,
        model_used=summary.model_used,
        summary_content=summary.summary_content,
        word_count=summary.word_count or len(summary.summary_content.split()),
        reliability_score=summary.reliability_score,
        is_favorite=summary.is_favorite,
        notes=summary.notes,
        tags=summary.tags,
        entities=entities,
        transcript_context=summary.transcript_context,
        created_at=summary.created_at.isoformat() if summary.created_at else None
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“š CONCEPTS & DÃ‰FINITIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.get("/concepts/{summary_id}")
async def get_summary_concepts(
    summary_id: int,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """
    ğŸ“š Extrait les concepts [[terme]] d'un rÃ©sumÃ© et retourne leurs dÃ©finitions.
    Utilise Perplexity pour gÃ©nÃ©rer des dÃ©finitions courtes.
    """
    # RÃ©cupÃ©rer le rÃ©sumÃ©
    summary = await get_summary_by_id(session, summary_id, current_user.id)
    if not summary:
        raise HTTPException(status_code=404, detail="Summary not found")
    
    # Extraire et dÃ©finir les concepts
    try:
        result = await get_concepts_with_definitions(
            text=summary.summary_content,
            context=summary.video_title or "",
            language=summary.lang or "fr"
        )
        
        print(f"ğŸ“š [Concepts] Got {result['count']} concepts for summary {summary_id}")
        
        return {
            "summary_id": summary_id,
            "video_title": summary.video_title,
            "concepts": result["concepts"],
            "count": result["count"]
        }
        
    except Exception as e:
        print(f"âŒ [Concepts] Error: {e}")
        # Fallback: extraire les termes sans dÃ©finitions
        concepts = extract_concepts(summary.summary_content)
        return {
            "summary_id": summary_id,
            "video_title": summary.video_title,
            "concepts": [
                {
                    "term": c,
                    "definition": "",
                    "category": "other"
                }
                for c in concepts
            ],
            "count": len(concepts)
        }


@router.get("/concepts/{summary_id}/enriched")
async def get_enriched_concepts(
    summary_id: int,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """
    ğŸ“š Extrait les concepts [[terme]] et retourne des dÃ©finitions ENRICHIES.
    
    Combine Mistral (catÃ©gorisation rapide) + Perplexity (dÃ©finitions web).
    
    FonctionnalitÃ©s:
    - DÃ©finitions contextuelles prÃ©cises
    - CatÃ©gorisation intelligente (person, company, technology, etc.)
    - Sources web quand disponibles
    - Pertinence dans le contexte de la vidÃ©o
    
    Plans:
    - Free/Starter: DÃ©finitions Mistral uniquement
    - Pro/Expert: DÃ©finitions enrichies Perplexity + sources
    """
    # RÃ©cupÃ©rer le rÃ©sumÃ©
    summary = await get_summary_by_id(session, summary_id, current_user.id)
    if not summary:
        raise HTTPException(status_code=404, detail="Summary not found")
    
    if not summary.summary_content:
        return {
            "summary_id": summary_id,
            "video_title": summary.video_title,
            "concepts": [],
            "count": 0,
            "provider": "none"
        }
    
    # Extraire les termes [[marquÃ©s]]
    terms = extract_terms_from_text(summary.summary_content)
    
    if not terms:
        return {
            "summary_id": summary_id,
            "video_title": summary.video_title,
            "concepts": [],
            "count": 0,
            "provider": "none"
        }
    
    # DÃ©terminer si on utilise Perplexity (Pro/Expert seulement)
    use_perplexity = current_user.plan in ["pro", "expert", "unlimited"]
    
    try:
        # Obtenir les dÃ©finitions enrichies
        definitions = await get_enriched_definitions(
            terms=terms,
            context=summary.video_title or "",
            language=summary.lang or "fr",
            use_perplexity=use_perplexity
        )
        
        # Convertir en format JSON
        concepts_list = []
        for defn in definitions:
            cat_info = get_category_info(defn.category, summary.lang or "fr")
            concepts_list.append({
                "term": defn.term,
                "definition": defn.definition,
                "category": defn.category,
                "category_label": cat_info["label"],
                "category_icon": cat_info["icon"],
                "context_relevance": defn.context_relevance,
                "sources": defn.sources,
                "confidence": defn.confidence,
                "provider": defn.provider
            })
        
        provider = "perplexity+mistral" if use_perplexity else "mistral"
        print(f"ğŸ“š [Enriched] Got {len(concepts_list)} enriched definitions for summary {summary_id} ({provider})")
        
        return {
            "summary_id": summary_id,
            "video_title": summary.video_title,
            "concepts": concepts_list,
            "count": len(concepts_list),
            "provider": provider,
            "categories": {
                cat_id: {
                    "label": cat_data.get(summary.lang or "fr", cat_data.get("fr")),
                    "icon": cat_data.get("icon"),
                    "count": sum(1 for c in concepts_list if c["category"] == cat_id)
                }
                for cat_id, cat_data in CATEGORIES.items()
            }
        }
        
    except Exception as e:
        print(f"âŒ [Enriched] Error: {e}")
        # Fallback: termes sans dÃ©finitions
        return {
            "summary_id": summary_id,
            "video_title": summary.video_title,
            "concepts": [
                {
                    "term": t,
                    "definition": "",
                    "category": "other",
                    "category_label": "Autres",
                    "category_icon": "ğŸ“Œ",
                    "context_relevance": "",
                    "sources": [],
                    "confidence": 0,
                    "provider": "none"
                }
                for t in terms
            ],
            "count": len(terms),
            "provider": "fallback"
        }


@router.get("/history", response_model=HistoryResponse)
async def get_history(
    page: int = Query(1, ge=1),
    per_page: int = Query(20, ge=1, le=100),
    category: Optional[str] = None,
    search: Optional[str] = None,
    favorites_only: bool = False,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """RÃ©cupÃ¨re l'historique des rÃ©sumÃ©s de l'utilisateur"""
    items, total = await get_user_history(
        session=session,
        user_id=current_user.id,
        page=page,
        per_page=per_page,
        category=category,
        search=search,
        favorites_only=favorites_only
    )
    
    return HistoryResponse(
        items=[
            SummaryListItem(
                id=item.id,
                video_id=item.video_id,
                video_title=item.video_title,
                video_channel=item.video_channel or "Unknown",
                video_duration=item.video_duration or 0,
                thumbnail_url=item.thumbnail_url or f"https://img.youtube.com/vi/{item.video_id}/mqdefault.jpg",
                category=item.category,
                mode=item.mode,
                word_count=item.word_count or 0,
                reliability_score=item.reliability_score,
                is_favorite=item.is_favorite,
                created_at=item.created_at.isoformat() if item.created_at else None
            )
            for item in items
        ],
        total=total,
        page=page,
        per_page=per_page,
        pages=math.ceil(total / per_page) if per_page > 0 else 0
    )


@router.post("/summary/{summary_id}/favorite")
async def toggle_favorite(
    summary_id: int,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """Toggle le statut favori d'un rÃ©sumÃ©"""
    summary = await get_summary_by_id(session, summary_id, current_user.id)
    if not summary:
        raise HTTPException(status_code=404, detail="Summary not found")
    
    new_status = not summary.is_favorite
    await update_summary(session, summary_id, current_user.id, is_favorite=new_status)
    
    return {"is_favorite": new_status}


@router.put("/summary/{summary_id}/notes")
async def update_notes(
    summary_id: int,
    data: dict,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """Met Ã  jour les notes d'un rÃ©sumÃ©"""
    from core.sanitize import sanitize_text

    summary = await get_summary_by_id(session, summary_id, current_user.id)
    if not summary:
        raise HTTPException(status_code=404, detail="Summary not found")

    # ğŸ›¡ï¸ Sanitize user input
    notes = sanitize_text(data.get("notes", ""), max_length=10000)
    await update_summary(session, summary_id, current_user.id, notes=notes)
    return {"success": True}


@router.put("/summary/{summary_id}/tags")
async def update_tags(
    summary_id: int,
    data: dict,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """Met Ã  jour les tags d'un rÃ©sumÃ©"""
    from core.sanitize import sanitize_text

    summary = await get_summary_by_id(session, summary_id, current_user.id)
    if not summary:
        raise HTTPException(status_code=404, detail="Summary not found")

    # ğŸ›¡ï¸ Sanitize user input
    tags = sanitize_text(data.get("tags", ""), max_length=500)
    await update_summary(session, summary_id, current_user.id, tags=tags)
    return {"success": True}


@router.delete("/summary/{summary_id}")
async def remove_summary(
    summary_id: int,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """Supprime un rÃ©sumÃ©"""
    summary = await get_summary_by_id(session, summary_id, current_user.id)
    if not summary:
        raise HTTPException(status_code=404, detail="Summary not found")
    
    await delete_summary(session, summary_id, current_user.id)
    return {"success": True}


@router.delete("/history")
async def clear_history(
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """Efface tout l'historique de l'utilisateur"""
    count = await delete_all_history(session, current_user.id)
    return {"success": True, "deleted": count}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“‚ CATÃ‰GORIES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.get("/categories", response_model=CategoryResponse)
async def get_categories():
    """Liste toutes les catÃ©gories disponibles"""
    return CategoryResponse(
        categories=[
            {"id": cat_id, "name": cat_info["fr"], "icon": cat_info.get("icon", "ğŸ“‹")}
            for cat_id, cat_info in CATEGORIES.items()
        ]
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š STATISTIQUES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.get("/stats")
async def get_stats(
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """RÃ©cupÃ¨re les statistiques de l'utilisateur"""
    stats = await get_user_stats(session, current_user.id)
    return stats


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“š OUTILS D'Ã‰TUDE â€” Fiches de rÃ©vision & Arbres pÃ©dagogiques
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from .study_tools import generate_study_card, generate_concept_map, generate_study_materials

@router.post("/study/{summary_id}/card")
async def create_study_card(
    summary_id: int,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """
    ğŸ“ GÃ©nÃ¨re une fiche de rÃ©vision pour une vidÃ©o analysÃ©e.
    
    Inclut:
    - Points clÃ©s classÃ©s par importance
    - DÃ©finitions des termes techniques
    - Questions/RÃ©ponses de comprÃ©hension
    - Quiz QCM avec corrections
    - Conseils d'apprentissage
    """
    
    # RÃ©cupÃ©rer le rÃ©sumÃ©
    summary = await get_summary_by_id(session, summary_id, current_user.id)
    if not summary:
        raise HTTPException(status_code=404, detail="RÃ©sumÃ© non trouvÃ©")
    
    # VÃ©rifier les crÃ©dits (1 crÃ©dit pour une fiche)
    if current_user.credits < 1:
        raise HTTPException(status_code=402, detail="CrÃ©dits insuffisants")
    
    # DÃ©duire 1 crÃ©dit
    await deduct_credit(session, current_user.id, 1, "study_card")
    
    # GÃ©nÃ©rer la fiche
    try:
        study_card = await generate_study_card(
            title=summary.video_title or "VidÃ©o",
            channel=summary.video_channel or "ChaÃ®ne inconnue",
            summary=summary.summary_content or "",
            transcript=summary.transcript_context or "",
            lang=summary.lang or "fr",
            model="mistral-small-latest"
        )
        
        return {
            "success": True,
            "summary_id": summary_id,
            "study_card": study_card
        }
        
    except Exception as e:
        print(f"âŒ [STUDY_CARD] Erreur: {e}", flush=True)
        raise HTTPException(status_code=500, detail=f"Erreur gÃ©nÃ©ration: {str(e)}")


@router.post("/study/{summary_id}/mindmap")
async def create_concept_map(
    summary_id: int,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """
    ğŸŒ³ GÃ©nÃ¨re un arbre pÃ©dagogique (mindmap) au format Mermaid.
    
    Inclut:
    - Code Mermaid prÃªt Ã  afficher
    - Liste des concepts avec relations
    - Parcours d'apprentissage suggÃ©rÃ©
    """
    
    # RÃ©cupÃ©rer le rÃ©sumÃ©
    summary = await get_summary_by_id(session, summary_id, current_user.id)
    if not summary:
        raise HTTPException(status_code=404, detail="RÃ©sumÃ© non trouvÃ©")
    
    # VÃ©rifier les crÃ©dits (1 crÃ©dit pour un mindmap)
    if current_user.credits < 1:
        raise HTTPException(status_code=402, detail="CrÃ©dits insuffisants")
    
    # DÃ©duire 1 crÃ©dit
    await deduct_credit(session, current_user.id, 1, "concept_map")
    
    # GÃ©nÃ©rer le mindmap
    try:
        concept_map = await generate_concept_map(
            title=summary.video_title or "VidÃ©o",
            channel=summary.video_channel or "ChaÃ®ne inconnue",
            summary=summary.summary_content or "",
            lang=summary.lang or "fr",
            model="mistral-small-latest"
        )
        
        return {
            "success": True,
            "summary_id": summary_id,
            "concept_map": concept_map
        }
        
    except Exception as e:
        print(f"âŒ [CONCEPT_MAP] Erreur: {e}", flush=True)
        raise HTTPException(status_code=500, detail=f"Erreur gÃ©nÃ©ration: {str(e)}")


@router.post("/study/{summary_id}/all")
async def create_all_study_materials(
    summary_id: int,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """
    ğŸ“š GÃ©nÃ¨re tous les outils d'Ã©tude en une fois.
    
    Inclut:
    - Fiche de rÃ©vision complÃ¨te
    - Arbre pÃ©dagogique (mindmap)
    
    CoÃ»t: 2 crÃ©dits
    """
    
    # RÃ©cupÃ©rer le rÃ©sumÃ©
    summary = await get_summary_by_id(session, summary_id, current_user.id)
    if not summary:
        raise HTTPException(status_code=404, detail="RÃ©sumÃ© non trouvÃ©")
    
    # VÃ©rifier les crÃ©dits (2 crÃ©dits pour tout)
    if current_user.credits < 2:
        raise HTTPException(status_code=402, detail="CrÃ©dits insuffisants (2 requis)")
    
    # DÃ©duire 2 crÃ©dits
    await deduct_credit(session, current_user.id, 2, "study_all")
    
    # GÃ©nÃ©rer tout
    try:
        materials = await generate_study_materials(
            title=summary.video_title or "VidÃ©o",
            channel=summary.video_channel or "ChaÃ®ne inconnue",
            summary=summary.summary_content or "",
            transcript=summary.transcript_context or "",
            lang=summary.lang or "fr",
            model="mistral-small-latest",
            include_card=True,
            include_map=True
        )
        
        return {
            "success": True,
            "summary_id": summary_id,
            "materials": materials
        }
        
    except Exception as e:
        print(f"âŒ [STUDY_ALL] Erreur: {e}", flush=True)
        raise HTTPException(status_code=500, detail=f"Erreur gÃ©nÃ©ration: {str(e)}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ” INTELLIGENT DISCOVERY â€” Recherche intelligente de vidÃ©os
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from .intelligent_discovery import (
    IntelligentDiscoveryService, 
    generate_text_video_id, 
    validate_raw_text
)
from .schemas import (
    SmartDiscoveryRequest, DiscoveryResponse, VideoCandidateResponse,
    HybridAnalyzeRequest, HybridAnalysisResponse, InputType,
    CreditEstimation, RawTextAnalysisResponse
)


@router.post("/discover", response_model=DiscoveryResponse)
async def discover_videos(
    request: SmartDiscoveryRequest,
    current_user: User = Depends(get_current_user),
):
    """
    ğŸ” DÃ©couverte intelligente de vidÃ©os YouTube.
    
    GRATUIT - Ne consomme pas de crÃ©dits.
    Recherche les meilleures vidÃ©os avec scoring multi-critÃ¨res:
    - Score Tournesol (Ã©thique et qualitÃ©)
    - Score acadÃ©mique (sources, rÃ©fÃ©rences)
    - Engagement (likes/vues)
    - FraÃ®cheur (date de publication)
    - PÃ©nalitÃ© clickbait
    
    La dÃ©couverte est GRATUITE, seule l'analyse coÃ»te des crÃ©dits.
    """
    import time
    start = time.time()
    
    print(f"ğŸ” [DISCOVER] User {current_user.email} searching: {request.query}", flush=True)
    
    try:
        result = await IntelligentDiscoveryService.discover(
            query=request.query,
            languages=request.languages,
            max_results=request.max_results,
            min_quality=request.min_quality,
            target_duration=request.target_duration,
        )
        
        # Convertir en response
        candidates = [
            VideoCandidateResponse(**c.to_dict())
            for c in result.candidates
        ]
        
        duration_ms = int((time.time() - start) * 1000)
        print(f"âœ… [DISCOVER] Found {len(candidates)} candidates in {duration_ms}ms", flush=True)
        
        return DiscoveryResponse(
            query=result.query,
            reformulated_queries=result.reformulated_queries,
            candidates=candidates,
            total_searched=result.total_searched,
            languages_searched=result.languages_searched,
            search_duration_ms=result.search_duration_ms,
            tournesol_available=result.tournesol_available,
        )
        
    except Exception as e:
        print(f"âŒ [DISCOVER] Error: {e}", flush=True)
        raise HTTPException(status_code=500, detail=f"Erreur de recherche: {str(e)}")


@router.post("/discover/best", response_model=VideoCandidateResponse)
async def discover_best_video(
    query: str = Query(..., description="RequÃªte de recherche"),
    languages: str = Query("fr,en", description="Langues sÃ©parÃ©es par virgule"),
    current_user: User = Depends(get_current_user),
):
    """
    ğŸ† Trouve LA meilleure vidÃ©o pour une requÃªte.
    
    GRATUIT - Ne consomme pas de crÃ©dits.
    Retourne directement le meilleur candidat.
    """
    print(f"ğŸ† [DISCOVER/BEST] User {current_user.email} searching: {query}", flush=True)
    
    lang_list = [l.strip() for l in languages.split(",")]
    
    try:
        result = await IntelligentDiscoveryService.discover_single_best(
            query=query,
            languages=lang_list,
        )
        
        if not result:
            raise HTTPException(
                status_code=404, 
                detail="Aucune vidÃ©o de qualitÃ© trouvÃ©e pour cette recherche"
            )
        
        return VideoCandidateResponse(**result.to_dict())
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ [DISCOVER/BEST] Error: {e}", flush=True)
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}")


@router.post("/discover/search")
async def discover_search_videos(
    query: str = Query(..., description="RequÃªte de recherche"),
    languages: str = Query("fr,en", description="Langues sÃ©parÃ©es par virgule"),
    limit: int = Query(15, ge=1, le=50, description="Nombre max de rÃ©sultats"),
    sort_by: str = Query("quality", description="Tri: quality, views, date, academic"),
    current_user: User = Depends(get_current_user),
):
    """
    ğŸ” Recherche de vidÃ©os pour le mobile â€” retourne une liste triÃ©e.

    GRATUIT - Ne consomme pas de crÃ©dits.
    Retourne toujours { videos: [...], total: N, query: str }, jamais de 404.
    """
    print(f"ğŸ” [DISCOVER/SEARCH] User {current_user.email} query='{query}' sort={sort_by} limit={limit}", flush=True)

    lang_list = [l.strip() for l in languages.split(",")]

    try:
        result = await IntelligentDiscoveryService.discover(
            query=query,
            languages=lang_list,
            max_results=limit,
            min_quality=15.0,
        )

        # Convert candidates to dicts
        videos = []
        for c in result.candidates:
            d = c.to_dict()
            videos.append({
                "video_id": d.get("video_id", ""),
                "title": d.get("title", ""),
                "channel": d.get("channel", ""),
                "thumbnail_url": d.get("thumbnail_url", ""),
                "duration": d.get("duration", 0),
                "view_count": d.get("view_count", 0),
                "quality_score": d.get("quality_score", 0),
                "tournesol_score": d.get("tournesol_score", 0),
                "published_at": d.get("published_at"),
                "is_tournesol_pick": d.get("is_tournesol_pick", False),
            })

        # Sort according to sort_by
        if sort_by == "views":
            videos.sort(key=lambda v: v["view_count"], reverse=True)
        elif sort_by == "date":
            videos.sort(key=lambda v: v["published_at"] or "", reverse=True)
        elif sort_by == "academic":
            videos.sort(key=lambda v: v["tournesol_score"], reverse=True)
        else:  # quality (default)
            videos.sort(key=lambda v: v["quality_score"], reverse=True)

        # Limit results
        videos = videos[:limit]

        print(f"âœ… [DISCOVER/SEARCH] Returning {len(videos)} videos", flush=True)

        return {
            "videos": videos,
            "total": len(videos),
            "query": query,
        }

    except Exception as e:
        print(f"âŒ [DISCOVER/SEARCH] Error: {e}", flush=True)
        # Always return valid JSON, never 404
        return {
            "videos": [],
            "total": 0,
            "query": query,
        }


@router.post("/analyze/hybrid", response_model=HybridAnalysisResponse)
async def analyze_hybrid(
    request: HybridAnalyzeRequest,
    background_tasks: BackgroundTasks,
    current_user: User = Depends(get_verified_user),
    session: AsyncSession = Depends(get_session)
):
    """
    ğŸ”€ Analyse hybride unifiÃ©e.
    
    Supporte 3 modes d'entrÃ©e:
    1. **URL** - Analyse classique d'une vidÃ©o YouTube
    2. **RAW_TEXT** - Analyse de texte brut (comme si c'Ã©tait une transcription)
    3. **SEARCH** - DÃ©couverte intelligente puis sÃ©lection
    
    COÃ›T:
    - DÃ©couverte (SEARCH sans auto_select): GRATUIT
    - Analyse (URL, RAW_TEXT, SEARCH avec auto_select): 1+ crÃ©dits selon le modÃ¨le
    """
    try:
        input_type = request.detect_input_type()
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    
    print(f"ğŸ”€ [HYBRID] User {current_user.email} - Type: {input_type.value}", flush=True)
    
    # === MODE URL ===
    if input_type == InputType.URL:
        # RÃ©utiliser le endpoint d'analyse classique
        from .schemas import AnalyzeVideoRequest
        
        analyze_request = AnalyzeVideoRequest(
            url=request.url,
            mode=request.mode,
            category=request.category,
            lang=request.lang,
            model=request.model,
            deep_research=request.deep_research,
        )
        
        result = await analyze_video(
            request=analyze_request,
            background_tasks=background_tasks,
            current_user=current_user,
            session=session
        )
        
        return HybridAnalysisResponse(
            input_type=InputType.URL,
            task_id=result.task_id,
            status=result.status,
            message=result.message,
            result=result.result,
        )
    
    # === MODE RAW_TEXT ===
    elif input_type == InputType.RAW_TEXT:
        # Valider le texte
        is_valid, error = validate_raw_text(request.raw_text)
        if not is_valid:
            raise HTTPException(status_code=400, detail=error)
        
        # VÃ©rifier les crÃ©dits
        model = request.model or "mistral-small-latest"
        credit_cost = get_credit_cost(model) if SECURITY_AVAILABLE else 1
        
        if current_user.credits < credit_cost:
            raise HTTPException(
                status_code=402, 
                detail=f"CrÃ©dits insuffisants ({current_user.credits}/{credit_cost})"
            )
        
        # GÃ©nÃ©rer un ID unique pour ce texte
        text_id = generate_text_video_id(request.raw_text)
        
        # CrÃ©er une tÃ¢che avec user_id pour le tracking
        task_id = str(uuid4())
        _task_store[task_id] = {
            "status": "processing",
            "progress": 0,
            "message": "Analyse du texte en cours...",
            "text_id": text_id,
            "user_id": current_user.id,  # ğŸ”§ FIX: NÃ©cessaire pour le status endpoint
        }
        
        # Lancer l'analyse en background
        background_tasks.add_task(
            _analyze_raw_text_background,
            task_id=task_id,
            text=request.raw_text,
            text_id=text_id,
            title=request.text_title or "Texte analysÃ©",
            source=request.text_source or "Import manuel",
            user_id=current_user.id,
            mode=request.mode,
            lang=request.lang,
            model=model,
            category=request.category,
        )
        
        char_count = len(request.raw_text)
        word_count = len(request.raw_text.split())
        
        return HybridAnalysisResponse(
            input_type=InputType.RAW_TEXT,
            task_id=task_id,
            status="processing",
            message=f"Analyse de {word_count} mots en cours...",
        )
    
    # === MODE SEARCH ===
    else:
        # Valider la requÃªte de recherche
        if not request.search_query or not request.search_query.strip():
            raise HTTPException(
                status_code=400,
                detail="search_query est requis pour le mode recherche"
            )

        # DÃ©couverte intelligente
        discovery_result = await IntelligentDiscoveryService.discover(
            query=request.search_query.strip(),
            languages=request.search_languages,
            max_results=10 if not request.auto_select_best else 1,
            min_quality=25.0,
        )
        
        candidates = [
            VideoCandidateResponse(**c.to_dict())
            for c in discovery_result.candidates
        ]
        
        discovery_response = DiscoveryResponse(
            query=discovery_result.query,
            reformulated_queries=discovery_result.reformulated_queries,
            candidates=candidates,
            total_searched=discovery_result.total_searched,
            languages_searched=discovery_result.languages_searched,
            search_duration_ms=discovery_result.search_duration_ms,
            tournesol_available=discovery_result.tournesol_available,
        )
        
        # Si auto_select, lancer l'analyse du meilleur
        if request.auto_select_best and candidates:
            best = candidates[0]
            
            analyze_request = AnalyzeVideoRequest(
                url=f"https://youtube.com/watch?v={best.video_id}",
                mode=request.mode,
                category=request.category,
                lang=request.lang,
                model=request.model,
                deep_research=request.deep_research,
            )
            
            result = await analyze_video(
                request=analyze_request,
                background_tasks=background_tasks,
                current_user=current_user,
                session=session
            )
            
            return HybridAnalysisResponse(
                input_type=InputType.SEARCH,
                task_id=result.task_id,
                status=result.status,
                message=f"Analyse de '{best.title}' en cours...",
                discovery=discovery_response,
                selected_video=best,
            )
        
        # Sinon, retourner les candidats pour sÃ©lection manuelle
        return HybridAnalysisResponse(
            input_type=InputType.SEARCH,
            status="discovery_complete",
            message=f"{len(candidates)} vidÃ©os trouvÃ©es",
            discovery=discovery_response,
        )


@router.post("/estimate-credits", response_model=CreditEstimation)
async def estimate_credits(
    num_videos: int = Query(1, ge=1, le=50),
    model: str = Query("mistral-small-latest"),
    current_user: User = Depends(get_current_user),
):
    """
    ğŸ’° Estime le coÃ»t en crÃ©dits pour une analyse.
    
    Utile avant de lancer une analyse multiple ou playlist.
    """
    # Multiplicateur selon le modÃ¨le
    multipliers = {
        "mistral-small-latest": 1.0,
        "mistral-medium-latest": 2.0,
        "mistral-large-latest": 3.0,
    }
    
    multiplier = multipliers.get(model, 1.0)
    base_cost = num_videos
    total_cost = int(math.ceil(base_cost * multiplier))
    sufficient = current_user.credits >= total_cost
    
    return CreditEstimation(
        base_cost=base_cost,
        model_multiplier=multiplier,
        total_cost=total_cost,
        user_credits=current_user.credits,
        sufficient=sufficient,
        message="" if sufficient else f"Il vous manque {total_cost - current_user.credits} crÃ©dits"
    )


async def _analyze_raw_text_background(
    task_id: str,
    text: str,
    text_id: str,
    title: str,
    source: str,
    user_id: int,
    mode: str,
    lang: str,
    model: str,
    category: Optional[str] = None,
):
    """
    ğŸ“ Analyse un texte brut en background.
    
    Simule une vidÃ©o avec:
    - video_id = txt_XXXX (hash du contenu)
    - video_url = text://txt_XXXX
    - Pas de durÃ©e/thumbnail rÃ©elles
    """
    from sqlalchemy.ext.asyncio import AsyncSession
    from db.database import async_session_maker
    
    print(f"ğŸ“ [RAW_TEXT] Starting analysis for {text_id}", flush=True)
    
    try:
        _task_store[task_id]["progress"] = 5
        _task_store[task_id]["message"] = "DÃ©tection de catÃ©gorie..."
        
        # DÃ©tecter la catÃ©gorie
        if category and category != "auto":
            detected_category = category
            category_confidence = 1.0
        else:
            detected_category, category_confidence = detect_category(title="", transcript=text[:5000])
        
        _task_store[task_id]["progress"] = 15
        _task_store[task_id]["message"] = "Analyse du contexte et gÃ©nÃ©ration du titre..."
        
        # ğŸ¨ v2.0: GÃ©nÃ©rer titre intelligent, thumbnail ET dÃ©tecter le type de source
        smart_title, thumbnail_url, source_context = await enhance_raw_text(
            text=text,
            provided_title=title,
            category=detected_category,
            lang=lang,
            source_hint=source  # Utiliser la source comme indice
        )
        
        print(f"ğŸ¯ [RAW_TEXT] Smart title: {smart_title}", flush=True)
        print(f"ğŸ“š [RAW_TEXT] Source type: {source_context.source_type.value}", flush=True)
        if source_context.detected_origin:
            print(f"   Origin: {source_context.detected_origin}", flush=True)
        print(f"ğŸ–¼ï¸ [RAW_TEXT] Thumbnail: {len(thumbnail_url) if thumbnail_url else 0} chars", flush=True)
        
        _task_store[task_id]["progress"] = 30
        _task_store[task_id]["message"] = "GÃ©nÃ©ration du rÃ©sumÃ© adaptÃ© au contexte..."
        
        # ğŸ†• GÃ©nÃ©rer les instructions spÃ©cifiques au type de source
        source_instructions = get_source_specific_instructions(source_context, lang)
        
        # GÃ©nÃ©rer le rÃ©sumÃ© avec le contexte source
        word_count = len(text.split())
        summary_content = await generate_summary(
            title=smart_title,
            transcript=text,
            category=detected_category,
            lang=lang,
            mode=mode,
            model=model,
            channel=source or source_context.detected_origin or "",
            web_context=source_instructions if source_instructions else None  # Injecter les instructions
        )
        
        _task_store[task_id]["progress"] = 70
        _task_store[task_id]["message"] = "Extraction des entitÃ©s..."
        
        # Extraire les entitÃ©s
        entities = await extract_entities(summary_content or text[:10000], lang=lang)
        
        _task_store[task_id]["progress"] = 85
        _task_store[task_id]["message"] = "Calcul du score de fiabilitÃ©..."
        
        # Score de fiabilitÃ©
        reliability = await calculate_reliability_score(summary_content or text, entities, lang=lang)
        
        _task_store[task_id]["progress"] = 95
        _task_store[task_id]["message"] = "Sauvegarde..."
        
        # Sauvegarder en base
        async with async_session_maker() as session:
            # DÃ©duire les crÃ©dits
            credit_cost = get_credit_cost(model) if SECURITY_AVAILABLE else 1
            await deduct_credit(session, user_id, credit_cost, f"raw_text:{text_id}")
            
            # Sauvegarder le rÃ©sumÃ©
            summary_id = await save_summary(
                session=session,
                user_id=user_id,
                video_id=text_id,
                video_title=smart_title,  # ğŸ¯ Titre intelligent
                video_channel=source or "Import manuel",
                video_duration=0,  # Pas de durÃ©e pour du texte
                video_url=f"text://{text_id}",
                thumbnail_url=thumbnail_url or "",  # ğŸ–¼ï¸ Thumbnail Nano Banana 2
                category=detected_category,
                category_confidence=category_confidence,
                lang=lang,
                mode=mode,
                model_used=model,
                summary_content=summary_content,
                entities_extracted=entities,
                reliability_score=reliability,
                transcript_context=text[:50000],
            )
            
            await session.commit()
        
        _task_store[task_id]["status"] = "completed"
        _task_store[task_id]["progress"] = 100
        _task_store[task_id]["message"] = "Analyse terminÃ©e"
        _task_store[task_id]["result"] = {
            "summary_id": summary_id,
            "text_id": text_id,
            "word_count": word_count,
            "category": detected_category,
        }
        
        # Notification SSE
        if NOTIFICATIONS_AVAILABLE:
            await notify_analysis_complete(
                user_id=user_id,
                summary_id=summary_id,
                video_title=title,
                video_id=text_id,
            )
        
        print(f"âœ… [RAW_TEXT] Analysis completed: {text_id}", flush=True)
        
    except Exception as e:
        print(f"âŒ [RAW_TEXT] Error: {e}", flush=True)
        import traceback
        traceback.print_exc()
        
        _task_store[task_id]["status"] = "failed"
        _task_store[task_id]["error"] = str(e)
        _task_store[task_id]["message"] = f"Erreur: {str(e)}"
        
        if NOTIFICATIONS_AVAILABLE:
            await notify_analysis_failed(
                user_id=user_id,
                video_title=title,
                error=str(e),
            )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ• FRESHNESS & FACT-CHECK LITE â€” Disponible pour TOUS les plans
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.get("/reliability/{summary_id}")
async def get_content_reliability(
    summary_id: int,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """
    ğŸ• Analyse la fiabilitÃ© d'un contenu : fraÃ®cheur + fact-check LITE.
    
    DISPONIBLE POUR TOUS LES PLANS (Free, Starter, Pro, Expert)
    
    Returns:
        - freshness: Indicateur de fraÃ®cheur de la vidÃ©o
        - fact_check_lite: Analyse heuristique des affirmations
    """
    if not FACTCHECK_LITE_AVAILABLE:
        raise HTTPException(
            status_code=503,
            detail="Service de vÃ©rification temporairement indisponible"
        )
    
    # RÃ©cupÃ©rer le rÃ©sumÃ©
    summary = await get_summary_by_id(session, summary_id, current_user.id)
    if not summary:
        raise HTTPException(status_code=404, detail="Analyse non trouvÃ©e")
    
    # RÃ©cupÃ©rer la date de publication depuis video_url ou utiliser created_at
    video_date = None
    
    # Essayer d'obtenir la vraie date de publication
    try:
        video_id = extract_video_id(summary.video_url)
        if video_id:
            video_info = await get_video_info(video_id)
            if video_info and video_info.get("publish_date"):
                video_date = video_info["publish_date"]
    except Exception:
        pass
    
    # Fallback sur la date de crÃ©ation de l'analyse
    if not video_date:
        video_date = summary.created_at.isoformat() if summary.created_at else datetime.utcnow().isoformat()
    
    # Analyser la fiabilitÃ©
    result = analyze_content_reliability(
        video_date=video_date,
        video_title=summary.video_title or "",
        summary_content=summary.summary_content or "",
        video_description="",  # Pas stockÃ© actuellement
        lang=summary.lang or "fr"
    )
    
    # Ajouter les infos du rÃ©sumÃ©
    result["summary_id"] = summary_id
    result["video_title"] = summary.video_title
    result["video_channel"] = summary.video_channel
    result["user_plan"] = current_user.plan or "free"
    
    # Indiquer si l'utilisateur peut avoir un fact-check complet
    result["full_factcheck_available"] = current_user.plan in ["pro", "expert", "unlimited"]
    
    return result


@router.post("/reliability/analyze")
async def analyze_text_reliability(
    text: str = Form(..., description="Texte Ã  analyser"),
    title: str = Form(default="", description="Titre (optionnel)"),
    video_date: str = Form(default="", description="Date de publication (optionnel, ISO format)"),
    lang: str = Form(default="fr", description="Langue"),
    current_user: User = Depends(get_current_user)
):
    """
    ğŸ” Analyse directe d'un texte sans rÃ©sumÃ© prÃ©alable.
    
    Utile pour analyser du contenu brut ou des extraits.
    """
    if not FACTCHECK_LITE_AVAILABLE:
        raise HTTPException(
            status_code=503,
            detail="Service de vÃ©rification temporairement indisponible"
        )
    
    # Validation
    if len(text) < 100:
        raise HTTPException(
            status_code=400,
            detail="Texte trop court (minimum 100 caractÃ¨res)"
        )
    
    if len(text) > 50000:
        text = text[:50000]  # Limiter
    
    # Date par dÃ©faut = maintenant (considÃ©rÃ© frais)
    if not video_date:
        video_date = datetime.utcnow().isoformat()
    
    result = analyze_content_reliability(
        video_date=video_date,
        video_title=title,
        summary_content=text,
        lang=lang
    )
    
    result["user_plan"] = current_user.plan or "free"
    result["full_factcheck_available"] = current_user.plan in ["pro", "expert", "unlimited"]
    
    return result


@router.get("/freshness/{summary_id}")
async def get_video_freshness(
    summary_id: int,
    current_user: User = Depends(get_current_user),
    session: AsyncSession = Depends(get_session)
):
    """
    ğŸ“… Obtient uniquement l'indicateur de fraÃ®cheur d'une vidÃ©o.
    
    Endpoint lÃ©ger pour afficher rapidement l'alerte de fraÃ®cheur.
    """
    if not FACTCHECK_LITE_AVAILABLE:
        raise HTTPException(status_code=503, detail="Service indisponible")
    
    summary = await get_summary_by_id(session, summary_id, current_user.id)
    if not summary:
        raise HTTPException(status_code=404, detail="Analyse non trouvÃ©e")
    
    # RÃ©cupÃ©rer la date de publication
    video_date = None
    try:
        video_id = extract_video_id(summary.video_url)
        if video_id:
            video_info = await get_video_info(video_id)
            if video_info and video_info.get("publish_date"):
                video_date = video_info["publish_date"]
    except Exception:
        pass
    
    if not video_date:
        video_date = summary.created_at.isoformat() if summary.created_at else datetime.utcnow().isoformat()
    
    freshness = analyze_freshness(
        video_date=video_date,
        video_title=summary.video_title or "",
        video_description="",
        transcript_excerpt=summary.summary_content[:2000] if summary.summary_content else ""
    )
    
    return {
        "summary_id": summary_id,
        "video_title": summary.video_title,
        **freshness.to_dict()
    }


