"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  üìπ VIDEO SERVICE v5.0 ‚Äî Gestion des vid√©os et analyses                            ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë  üÜï v5.0: D√âTECTION INTELLIGENTE pour Chat IA                                      ‚ïë
‚ïë  ‚Ä¢ Recherche web automatique si question post-cutoff 2024                          ‚ïë
‚ïë  ‚Ä¢ D√©tection des donn√©es dynamiques (prix, positions, stats)                       ‚ïë
‚ïë  ‚Ä¢ V√©rification de faits en temps r√©el                                             ‚ïë
‚ïë  ‚Ä¢ Uniquement pour Pro et Expert                                                   ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""

import json
import httpx
from uuid import uuid4
from datetime import datetime, date
from typing import Optional, List, Dict, Any, Tuple, AsyncGenerator
from sqlalchemy import select, func, desc, delete as sql_delete
from sqlalchemy.ext.asyncio import AsyncSession

from db.database import (
    ChatMessage, ChatQuota, Summary, User, WebSearchUsage,
    PlaylistAnalysis, TaskStatus, CreditTransaction
)
from core.config import get_mistral_key, get_perplexity_key, PLAN_LIMITS


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üé´ GESTION DES CR√âDITS ET QUOTAS (via module centralis√©)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

from core.credits import (
    calculate_analysis_cost,
    calculate_chat_cost,
    check_credits,
    deduct_credits,
    MODEL_COSTS
)


async def check_can_analyze(
    session: AsyncSession,
    user_id: int,
    model: str = "mistral-small-latest",
    duration_minutes: int = 15,
    with_web_search: bool = False
) -> Tuple[bool, str, int, int]:
    """
    V√©rifie si l'utilisateur peut analyser une vid√©o.
    Retourne: (can_analyze, reason, credits_remaining, cost)
    """
    result = await session.execute(select(User).where(User.id == user_id))
    user = result.scalar_one_or_none()
    
    if not user:
        return False, "user_not_found", 0, 0
    
    credits = user.credits or 0
    
    # Calculer le co√ªt estim√©
    cost_info = calculate_analysis_cost(
        model=model,
        duration_minutes=duration_minutes,
        with_web_search=with_web_search
    )
    required_credits = cost_info["total"]
    
    if credits < required_credits:
        return False, f"insufficient_credits:{required_credits - credits}", credits, required_credits
    
    return True, "ok", credits, required_credits


async def deduct_credit(
    session: AsyncSession,
    user_id: int,
    amount: int = 1,
    description: str = "Video analysis",
    action_type: str = "analysis"
) -> bool:
    """D√©duit des cr√©dits √† l'utilisateur"""
    success, _ = await deduct_credits(
        session=session,
        user_id=user_id,
        amount=amount,
        action_type=action_type,
        description=description
    )
    return success


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üíæ GESTION DES R√âSUM√âS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def save_summary(
    session: AsyncSession,
    user_id: int,
    video_id: str,
    video_title: str,
    video_channel: str,
    video_duration: int,
    video_url: str,
    thumbnail_url: str,
    category: str,
    category_confidence: float,
    lang: str,
    mode: str,
    model_used: str,
    summary_content: str,
    transcript_context: Optional[str] = None,
    video_upload_date: Optional[str] = None,
    entities_extracted: Optional[Dict] = None,
    reliability_score: Optional[float] = None,
    fact_check_result: Optional[str] = None,
    enrichment_data: Optional[Dict] = None
) -> int:
    """Sauvegarde un nouveau r√©sum√© et retourne son ID"""
    print(f"üíæ [save_summary v2] Saving video_id={video_id}, user_id={user_id}", flush=True)
    
    # üè∑Ô∏è Extraire automatiquement les concepts [[marqu√©s]] du r√©sum√©
    extracted_tags = []
    if summary_content:
        import re
        pattern = r'\[\[([^\]|]+?)(?:\|[^\]]+?)?\]\]'
        matches = re.findall(pattern, summary_content)
        seen = set()
        for match in matches:
            term = match.strip()
            if term and term.lower() not in seen:
                extracted_tags.append(term)
                seen.add(term.lower())
        if extracted_tags:
            print(f"üè∑Ô∏è [save_summary] Extracted {len(extracted_tags)} concepts: {extracted_tags[:5]}...")

    # üîÑ FALLBACK: Si pas de [[concepts]], extraire des mots-cl√©s automatiquement
    if not extracted_tags and summary_content:
        print("‚ö†Ô∏è [save_summary] No [[concepts]] found, using fallback extraction...")

        # 1. Utiliser les entit√©s extraites si disponibles
        if entities_extracted:
            for entity in entities_extracted[:10]:
                if isinstance(entity, dict):
                    name = entity.get('name', entity.get('term', ''))
                elif isinstance(entity, str):
                    name = entity
                else:
                    continue
                if name and len(name) > 2 and name.lower() not in seen:
                    extracted_tags.append(name)
                    seen.add(name.lower())

        # 2. Extraire les noms propres (mots avec majuscule au milieu du texte)
        if len(extracted_tags) < 5:
            # Pattern pour noms propres: mots capitalis√©s qui ne sont pas en d√©but de phrase
            proper_nouns = re.findall(r'(?<=[.!?]\s|:\s|,\s|\n)([A-Z√Ä-√ú][a-z√†-√º]+(?:\s+[A-Z√Ä-√ú][a-z√†-√º]+)*)', summary_content)
            # Aussi chercher les groupes de mots capitalis√©s
            proper_nouns += re.findall(r'\b([A-Z√Ä-√ú][a-z√†-√º]+(?:\s+[A-Z√Ä-√ú][a-z√†-√º]+)+)\b', summary_content)

            # Mots √† ignorer
            stopwords = {'Le', 'La', 'Les', 'Un', 'Une', 'Des', 'Ce', 'Cette', 'Ces', 'Il', 'Elle',
                        'Ils', 'Elles', 'On', 'Nous', 'Vous', 'The', 'This', 'That', 'These', 'Those',
                        'Dans', 'Pour', 'Avec', 'Sans', 'Sur', 'Sous', 'Par', 'En', 'De', 'Du',
                        'Mais', 'Ou', 'Et', 'Donc', 'Or', 'Ni', 'Car', 'Cela', 'Ceci', 'Ainsi'}

            for noun in proper_nouns:
                noun = noun.strip()
                if (noun and len(noun) > 2
                    and noun not in stopwords
                    and noun.lower() not in seen
                    and not noun.isdigit()):
                    extracted_tags.append(noun)
                    seen.add(noun.lower())
                    if len(extracted_tags) >= 8:
                        break

        if extracted_tags:
            print(f"üè∑Ô∏è [save_summary] Fallback extracted {len(extracted_tags)} keywords: {extracted_tags[:5]}...")
    
    summary = Summary(
        user_id=user_id,
        video_id=video_id,
        video_title=video_title,
        video_channel=video_channel,
        video_duration=video_duration,
        video_url=video_url,
        thumbnail_url=thumbnail_url,
        video_upload_date=video_upload_date,
        category=category,
        category_confidence=category_confidence,
        lang=lang,
        mode=mode,
        model_used=model_used,
        summary_content=summary_content,
        transcript_context=transcript_context,
        word_count=len(summary_content.split()) if summary_content else 0,
        fact_check_result=fact_check_result,
        entities_extracted=json.dumps(entities_extracted) if entities_extracted else None,
        reliability_score=reliability_score,
        tags=','.join(extracted_tags) if extracted_tags else None,  # üè∑Ô∏è Stocker les concepts
        is_favorite=False
    )
    
    # Ajouter enrichment_data si le mod√®le le supporte
    if enrichment_data and hasattr(summary, 'enrichment_data'):
        summary.enrichment_data = json.dumps(enrichment_data)
    
    session.add(summary)
    
    # Mettre √† jour les stats utilisateur
    user_result = await session.execute(select(User).where(User.id == user_id))
    user = user_result.scalar_one_or_none()
    if user:
        user.total_videos = (user.total_videos or 0) + 1
        user.total_words = (user.total_words or 0) + summary.word_count
    
    await session.commit()
    await session.refresh(summary)
    return summary.id


async def get_summary_by_id(
    session: AsyncSession,
    summary_id: int,
    user_id: int
) -> Optional[Summary]:
    """R√©cup√®re un r√©sum√© par ID"""
    result = await session.execute(
        select(Summary).where(
            Summary.id == summary_id,
            Summary.user_id == user_id
        )
    )
    return result.scalar_one_or_none()


async def get_summary_by_video_id(
    session: AsyncSession,
    video_id: str,
    user_id: int
) -> Optional[Summary]:
    """
    R√©cup√®re le r√©sum√© le plus r√©cent pour une vid√©o (pour le cache).
    
    IMPORTANT: Un utilisateur peut avoir PLUSIEURS r√©sum√©s pour la m√™me vid√©o
    (diff√©rents modes, re-analyses). On retourne le plus r√©cent avec limit(1).
    
    BUG FIX: scalar_one_or_none() √©choue si plusieurs lignes existent.
    Solution: limit(1) + scalars().first()
    """
    result = await session.execute(
        select(Summary).where(
            Summary.video_id == video_id,
            Summary.user_id == user_id
        ).order_by(desc(Summary.created_at)).limit(1)
    )
    return result.scalars().first()


async def get_user_history(
    session: AsyncSession,
    user_id: int,
    page: int = 1,
    per_page: int = 20,
    category: Optional[str] = None,
    search: Optional[str] = None,
    favorites_only: bool = False
) -> Tuple[List[Summary], int]:
    """
    R√©cup√®re l'historique des r√©sum√©s d'un utilisateur.

    SECURITY: Le param√®tre search est √©chapp√© pour √©viter les injections SQL LIKE.
    PERFORMANCE: Utilise une seule requ√™te optimis√©e avec COUNT OVER().
    """
    query = select(Summary).where(Summary.user_id == user_id)

    if category:
        query = query.where(Summary.category == category)

    if search:
        # SECURITY: √âchapper les caract√®res sp√©ciaux SQL LIKE (%, _, \)
        safe_search = search.replace("\\", "\\\\").replace("%", "\\%").replace("_", "\\_")
        search_pattern = f"%{safe_search}%"
        query = query.where(
            Summary.video_title.ilike(search_pattern) |
            Summary.video_channel.ilike(search_pattern)
        )

    if favorites_only:
        query = query.where(Summary.is_favorite == True)

    # Compter le total
    count_result = await session.execute(
        select(func.count()).select_from(query.subquery())
    )
    total = count_result.scalar() or 0

    # Pagination
    query = query.order_by(desc(Summary.created_at))
    query = query.offset((page - 1) * per_page).limit(per_page)

    result = await session.execute(query)
    summaries = result.scalars().all()

    return list(summaries), total


async def update_summary(
    session: AsyncSession,
    summary_id: int,
    user_id: int,
    updates: Dict[str, Any]
) -> Optional[Summary]:
    """Met √† jour un r√©sum√©"""
    summary = await get_summary_by_id(session, summary_id, user_id)
    if not summary:
        return None
    
    for key, value in updates.items():
        if hasattr(summary, key):
            setattr(summary, key, value)
    
    await session.commit()
    await session.refresh(summary)
    return summary


async def delete_summary(
    session: AsyncSession,
    summary_id: int,
    user_id: int
) -> bool:
    """Supprime un r√©sum√©"""
    summary = await get_summary_by_id(session, summary_id, user_id)
    if not summary:
        return False
    
    await session.delete(summary)
    await session.commit()
    return True


async def delete_all_history(
    session: AsyncSession,
    user_id: int
) -> int:
    """Supprime tout l'historique d'un utilisateur"""
    result = await session.execute(
        sql_delete(Summary).where(Summary.user_id == user_id)
    )
    await session.commit()
    return result.rowcount


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üìö GESTION DES PLAYLISTS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def create_playlist_analysis(
    session: AsyncSession,
    user_id: int,
    playlist_id: str,
    playlist_url: str,
    playlist_title: str,
    num_videos: int
) -> PlaylistAnalysis:
    """Cr√©e une nouvelle analyse de playlist"""
    analysis = PlaylistAnalysis(
        user_id=user_id,
        playlist_id=playlist_id,
        playlist_url=playlist_url,
        playlist_title=playlist_title,
        num_videos=num_videos,
        status="pending"
    )
    session.add(analysis)
    await session.commit()
    await session.refresh(analysis)
    return analysis


async def get_user_playlists(
    session: AsyncSession,
    user_id: int,
    limit: int = 20,
    offset: int = 0
) -> Tuple[List[PlaylistAnalysis], int]:
    """R√©cup√®re les playlists d'un utilisateur"""
    count_result = await session.execute(
        select(func.count()).where(PlaylistAnalysis.user_id == user_id)
    )
    total = count_result.scalar() or 0
    
    result = await session.execute(
        select(PlaylistAnalysis)
        .where(PlaylistAnalysis.user_id == user_id)
        .order_by(desc(PlaylistAnalysis.created_at))
        .offset(offset)
        .limit(limit)
    )
    playlists = result.scalars().all()
    
    return list(playlists), total


async def get_playlist_summaries(
    session: AsyncSession,
    playlist_id: str,
    user_id: int
) -> List[Summary]:
    """R√©cup√®re les r√©sum√©s d'une playlist"""
    result = await session.execute(
        select(Summary)
        .where(
            Summary.playlist_id == playlist_id,
            Summary.user_id == user_id
        )
        .order_by(Summary.playlist_position)
    )
    return list(result.scalars().all())


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üìä STATISTIQUES
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def get_user_stats(
    session: AsyncSession,
    user_id: int
) -> Dict[str, Any]:
    """R√©cup√®re les statistiques d'un utilisateur"""
    result = await session.execute(select(User).where(User.id == user_id))
    user = result.scalar_one_or_none()
    
    if not user:
        return {}
    
    # Compter les r√©sum√©s
    summary_count = await session.execute(
        select(func.count()).where(Summary.user_id == user_id)
    )
    
    # Compter les playlists
    playlist_count = await session.execute(
        select(func.count()).where(PlaylistAnalysis.user_id == user_id)
    )
    
    return {
        "total_videos": summary_count.scalar() or 0,
        "total_words": user.total_words or 0,
        "total_playlists": playlist_count.scalar() or 0,
        "credits": user.credits,
        "plan": user.plan
    }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üîÑ GESTION DES T√ÇCHES ASYNCHRONES
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def create_task(
    session: AsyncSession,
    task_id: str,
    user_id: int,
    task_type: str
) -> str:
    """Cr√©e une nouvelle t√¢che et retourne son ID"""
    task = TaskStatus(
        task_id=task_id,
        user_id=user_id,
        task_type=task_type,
        status="pending",
        progress=0
    )
    session.add(task)
    await session.commit()
    
    return task_id


async def update_task_status(
    session: AsyncSession,
    task_id: str,
    status: str,
    progress: int = 0,
    result: Optional[Dict] = None,
    error: Optional[str] = None
):
    """Met √† jour le statut d'une t√¢che"""
    query_result = await session.execute(
        select(TaskStatus).where(TaskStatus.task_id == task_id)
    )
    task = query_result.scalar_one_or_none()
    
    if task:
        task.status = status
        task.progress = progress
        if result:
            task.result = json.dumps(result)
        if error:
            task.error_message = error
        task.updated_at = datetime.now()
        await session.commit()


async def get_task(
    session: AsyncSession,
    task_id: str
) -> Optional[TaskStatus]:
    """R√©cup√®re le statut d'une t√¢che (ORM object)"""
    result = await session.execute(
        select(TaskStatus).where(TaskStatus.task_id == task_id)
    )
    return result.scalar_one_or_none()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üåê IMPORT DU SERVICE D'ENRICHISSEMENT v3.0
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

try:
    from videos.web_enrichment import (
        enrich_chat_if_needed, needs_web_search_for_chat,
        get_enrichment_level, get_enrichment_badge,
        EnrichmentLevel, get_enrichment_config
    )
    ENRICHMENT_AVAILABLE = True
except ImportError:
    ENRICHMENT_AVAILABLE = False
    print("‚ö†Ô∏è [CHAT] Web enrichment not available", flush=True)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üìä QUOTAS CHAT
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def check_chat_quota(
    session: AsyncSession,
    user_id: int,
    summary_id: int
) -> Tuple[bool, str, Dict[str, int]]:
    """
    V√©rifie si l'utilisateur peut poser une question.
    Retourne: (can_ask, reason, quota_info)
    """
    result = await session.execute(select(User).where(User.id == user_id))
    user = result.scalar_one_or_none()
    
    if not user:
        return False, "user_not_found", {}
    
    plan = user.plan or "free"
    limits = PLAN_LIMITS.get(plan, PLAN_LIMITS["free"])
    
    daily_limit = limits.get("chat_daily_limit", 10)
    per_video_limit = limits.get("chat_per_video_limit", 5)
    
    # -1 = illimit√©
    if daily_limit == -1 and per_video_limit == -1:
        return True, "unlimited", {"daily_limit": -1, "per_video_limit": -1}
    
    today = date.today().isoformat()
    
    # V√©rifier le quota journalier
    if daily_limit != -1:
        daily_result = await session.execute(
            select(ChatQuota).where(
                ChatQuota.user_id == user_id,
                ChatQuota.quota_date == today
            )
        )
        daily_quota = daily_result.scalar_one_or_none()
        daily_used = daily_quota.daily_count if daily_quota else 0
        
        if daily_used >= daily_limit:
            return False, "daily_limit_reached", {
                "daily_limit": daily_limit,
                "daily_used": daily_used,
                "per_video_limit": per_video_limit
            }
    else:
        daily_used = 0
    
    # V√©rifier le quota par vid√©o
    if per_video_limit != -1:
        video_result = await session.execute(
            select(func.count(ChatMessage.id)).where(
                ChatMessage.user_id == user_id,
                ChatMessage.summary_id == summary_id,
                ChatMessage.role == "user"
            )
        )
        video_used = video_result.scalar() or 0
        
        if video_used >= per_video_limit:
            return False, "video_limit_reached", {
                "daily_limit": daily_limit,
                "daily_used": daily_used,
                "per_video_limit": per_video_limit,
                "video_used": video_used
            }
    else:
        video_used = 0
    
    return True, "ok", {
        "daily_limit": daily_limit,
        "daily_used": daily_used,
        "per_video_limit": per_video_limit,
        "video_used": video_used
    }


async def increment_chat_quota(session: AsyncSession, user_id: int):
    """Incr√©mente le quota de chat journalier"""
    today = date.today().isoformat()
    
    result = await session.execute(
        select(ChatQuota).where(
            ChatQuota.user_id == user_id,
            ChatQuota.quota_date == today
        )
    )
    quota = result.scalar_one_or_none()
    
    if quota:
        quota.daily_count += 1
    else:
        quota = ChatQuota(
            user_id=user_id,
            quota_date=today,
            daily_count=1
        )
        session.add(quota)
    
    await session.commit()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üí¨ MESSAGES CHAT
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def save_chat_message(
    session: AsyncSession,
    user_id: int,
    summary_id: int,
    role: str,
    content: str
) -> int:
    """Sauvegarde un message de chat"""
    message = ChatMessage(
        user_id=user_id,
        summary_id=summary_id,
        role=role,
        content=content
    )
    session.add(message)
    await session.commit()
    await session.refresh(message)
    return message.id


async def get_chat_history(
    session: AsyncSession,
    summary_id: int,
    user_id: int,
    limit: int = 20
) -> List[Dict[str, Any]]:
    """R√©cup√®re l'historique de chat pour une vid√©o"""
    result = await session.execute(
        select(ChatMessage)
        .where(
            ChatMessage.summary_id == summary_id,
            ChatMessage.user_id == user_id
        )
        .order_by(ChatMessage.created_at.desc())
        .limit(limit)
    )
    messages = result.scalars().all()
    
    return [
        {"role": m.role, "content": m.content, "created_at": m.created_at}
        for m in reversed(messages)
    ]


async def clear_chat_history(
    session: AsyncSession,
    summary_id: int,
    user_id: int
) -> int:
    """Efface l'historique de chat pour une vid√©o"""
    from sqlalchemy import delete
    
    result = await session.execute(
        delete(ChatMessage).where(
            ChatMessage.summary_id == summary_id,
            ChatMessage.user_id == user_id
        )
    )
    await session.commit()
    return result.rowcount


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ü§ñ G√âN√âRATION R√âPONSE CHAT v4.0
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Import du syst√®me de recherche intelligente
try:
    from .smart_search import get_smart_transcript_context
    SMART_SEARCH_AVAILABLE = True
except ImportError:
    SMART_SEARCH_AVAILABLE = False
    print("‚ö†Ô∏è Smart search not available", flush=True)


def build_chat_prompt(
    question: str,
    video_title: str,
    transcript: str,
    summary: str,
    chat_history: List[Dict],
    mode: str,
    lang: str,
    video_duration: int = 0  # üÜï Ajout dur√©e pour les timecodes
) -> Tuple[str, str]:
    """
    Construit le prompt pour le chat.
    üÜï v4.1: Utilise la recherche intelligente pour les vid√©os longues.
    Retourne: (system_prompt, user_prompt)
    """
    MODE_CONFIG = {
        "accessible": {
            "max_context": 12000,  # üÜï v3.1: Augment√© pour meilleur contexte
            "style_fr": "R√©ponds de fa√ßon concise (2-4 phrases). Langage simple, accessible.",
            "style_en": "Answer concisely (2-4 sentences). Simple, accessible language."
        },
        "standard": {
            "max_context": 25000,  # üÜï v3.1: Augment√© pour vid√©os longues
            "style_fr": "R√©ponds de fa√ßon compl√®te (4-8 phrases). √âquilibre clart√© et d√©tail.",
            "style_en": "Answer completely (4-8 sentences). Balance clarity and detail."
        },
        "expert": {
            "max_context": 40000,  # üÜï v3.1: Augment√© pour analyses exhaustives
            "style_fr": "R√©ponds de fa√ßon exhaustive et rigoureuse. Analyse critique.",
            "style_en": "Answer exhaustively and rigorously. Critical analysis."
        }
    }
    
    config = MODE_CONFIG.get(mode, MODE_CONFIG["standard"])
    style = config["style_fr"] if lang == "fr" else config["style_en"]
    max_context = config["max_context"]
    
    # Construire l'historique
    history_text = ""
    if chat_history:
        for msg in chat_history[-6:]:
            role = "Utilisateur" if msg["role"] == "user" else "Assistant"
            history_text += f"\n{role}: {msg['content']}"
    
    # üÜï v4.1: Recherche intelligente pour les vid√©os longues
    smart_search_used = False
    num_passages = 1
    
    if SMART_SEARCH_AVAILABLE and transcript:
        transcript_context, smart_search_used, num_passages = get_smart_transcript_context(
            question=question,
            transcript=transcript,
            video_duration=video_duration,
            max_context_words=max_context
        )
        if smart_search_used:
            print(f"üîç [SMART SEARCH] Extracted {num_passages} relevant passages for: {question[:50]}...", flush=True)
    else:
        # Fallback: troncature simple
        transcript_context = transcript[:max_context] if transcript else ""
    
    # Note pour le LLM sur la recherche intelligente
    smart_search_note = ""
    if smart_search_used:
        if lang == "fr":
            smart_search_note = f"""
‚ö†Ô∏è NOTE: Cette vid√©o est LONGUE. Seuls les {num_passages} passages les plus pertinents pour ta question ont √©t√© extraits.
Si tu ne trouves pas l'information, sugg√®re √† l'utilisateur de reformuler sa question avec d'autres mots-cl√©s.
"""
        else:
            smart_search_note = f"""
‚ö†Ô∏è NOTE: This is a LONG video. Only the {num_passages} most relevant passages for your question were extracted.
If you can't find the information, suggest the user rephrase their question with different keywords.
"""
    
    if lang == "fr":
        system_prompt = f"""Tu es Deep Sight, assistant IA expert pour r√©pondre aux questions sur les vid√©os YouTube.

üì∫ VID√âO: {video_title}

{style}
{smart_search_note}

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚è±Ô∏è TIMECODES CLIQUABLES OBLIGATOIRES
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

IMPORTANT: Quand tu r√©ponds, INCLUS des timecodes [MM:SS] avec CROCHETS pour que l'utilisateur puisse cliquer dessus et acc√©der directement au passage.

Format STRICT: "√Ä [5:23], l'auteur explique que..."

‚úÖ EXEMPLES CORRECTS:
- "Ce concept est introduit √† [2:15] puis d√©velopp√© √† [7:30]"
- "L'intervenant mentionne √† [12:45] que..."
- "Voir les explications d√©taill√©es entre [3:00] et [5:30]"

‚ùå INTERDIT: Format (MM:SS) avec parenth√®ses - utilise [MM:SS] avec crochets!

R√àGLES:
1. Base tes r√©ponses UNIQUEMENT sur le contenu de la vid√©o
2. Si l'info n'est pas dans la vid√©o, dis-le clairement
3. Cite les passages pertinents avec timecodes
4. Distingue ce qui vient de la vid√©o de ton analyse
"""
        
        user_prompt = f"""üìã R√âSUM√â DE LA VID√âO:
{summary[:3000] if summary else "Non disponible"}

üìù TRANSCRIPTION:
{transcript_context}

HISTORIQUE DE LA CONVERSATION:{history_text}

QUESTION: {question}

R√©ponds en fran√ßais avec des timecodes:"""

    else:
        system_prompt = f"""You are Deep Sight, AI assistant expert for answering questions about YouTube videos.

üì∫ VIDEO: {video_title}

{style}
{smart_search_note}

MANDATORY CLICKABLE TIMECODES: Include timecodes [MM:SS] with BRACKETS in your answers.
Format: "At [5:23], the author explains..."
DO NOT use (MM:SS) format - use [MM:SS] with square brackets!

RULES:
1. Base answers ONLY on video content
2. If info isn't in the video, say so clearly
3. Cite relevant passages with timecodes
4. Distinguish video content from your analysis
"""
        
        user_prompt = f"""üìã VIDEO SUMMARY:
{summary[:3000] if summary else "Not available"}

üìù TRANSCRIPT:
{transcript_context}

CONVERSATION HISTORY:{history_text}

QUESTION: {question}

Answer in English with timecodes:"""

    return system_prompt, user_prompt


async def generate_chat_response(
    question: str,
    video_title: str,
    transcript: str,
    summary: str,
    chat_history: List[Dict],
    mode: str = "standard",
    lang: str = "fr",
    model: str = "mistral-small-latest",
    api_key: str = None,
    video_duration: int = 0  # üÜï Pour la recherche intelligente
) -> Optional[str]:
    """G√©n√®re une r√©ponse de chat avec Mistral"""
    api_key = api_key or get_mistral_key()
    if not api_key:
        return None
    
    system_prompt, user_prompt = build_chat_prompt(
        question, video_title, transcript, summary, chat_history, mode, lang,
        video_duration=video_duration  # üÜï
    )
    
    max_tokens = {
        "accessible": 800,
        "standard": 1500,
        "expert": 3000
    }.get(mode, 1500)
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.mistral.ai/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": model,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    "max_tokens": max_tokens,
                    "temperature": 0.3
                },
                timeout=60
            )
            
            if response.status_code == 200:
                return response.json()["choices"][0]["message"]["content"].strip()
            else:
                print(f"‚ùå Chat API error: {response.status_code}", flush=True)
                return None
                
    except Exception as e:
        print(f"‚ùå Chat generation error: {e}", flush=True)
        return None


async def generate_chat_response_stream(
    question: str,
    video_title: str,
    transcript: str,
    summary: str,
    chat_history: List[Dict],
    mode: str = "standard",
    lang: str = "fr",
    model: str = "mistral-small-latest",
    api_key: str = None,
    video_duration: int = 0  # üÜï Pour la recherche intelligente
) -> AsyncGenerator[str, None]:
    """G√©n√®re une r√©ponse de chat en streaming"""
    api_key = api_key or get_mistral_key()
    if not api_key:
        yield "Error: API key not configured"
        return
    
    system_prompt, user_prompt = build_chat_prompt(
        question, video_title, transcript, summary, chat_history, mode, lang,
        video_duration=video_duration  # üÜï
    )
    
    max_tokens = {"accessible": 800, "standard": 1500, "expert": 3000}.get(mode, 1500)
    
    try:
        async with httpx.AsyncClient() as client:
            async with client.stream(
                "POST",
                "https://api.mistral.ai/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": model,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    "max_tokens": max_tokens,
                    "temperature": 0.3,
                    "stream": True
                },
                timeout=120
            ) as response:
                async for line in response.aiter_lines():
                    if line.startswith("data: "):
                        data = line[6:]
                        if data == "[DONE]":
                            break
                        try:
                            chunk = json.loads(data)
                            content = chunk["choices"][0]["delta"].get("content", "")
                            if content:
                                yield content
                        except:
                            continue
    except Exception as e:
        yield f"Error: {e}"


async def generate_chat_response_v4(
    question: str,
    video_title: str,
    transcript: str,
    summary: str,
    chat_history: List[Dict],
    user_plan: str,
    mode: str = "standard",
    lang: str = "fr",
    model: str = "mistral-small-latest",
    web_search_requested: bool = False,
    video_duration: int = 0  # üÜï Pour la recherche intelligente
) -> Tuple[str, List[Dict[str, str]], bool]:
    """
    üÜï v5.0: G√©n√®re une r√©ponse chat avec d√©tection INTELLIGENTE des infos post-cutoff.
    
    La recherche web est d√©clench√©e automatiquement si:
    - La question concerne des √©v√©nements post-2024 (cutoff Mistral)
    - La question demande des donn√©es qui changent (prix, positions, stats)
    - La question est une v√©rification de faits actuels
    - L'utilisateur a demand√© explicitement une recherche web
    
    UNIQUEMENT pour Pro et Expert.
    
    Args:
        question: Question de l'utilisateur
        video_title: Titre de la vid√©o
        transcript: Transcription
        summary: R√©sum√© de la vid√©o
        chat_history: Historique du chat
        user_plan: Plan de l'utilisateur
        mode: Mode d'analyse
        lang: Langue
        model: Mod√®le Mistral
        web_search_requested: Si l'utilisateur a demand√© explicitement une recherche web
    
    Returns:
        Tuple[response, sources, web_search_used]
    """
    print(f"üí¨ [CHAT v5.0] Generating response for plan: {user_plan}", flush=True)
    
    # Variables pour l'enrichissement web
    web_context = None
    sources = []
    web_search_used = False
    
    # 1. V√©rifier si on doit faire une recherche web AVANT Mistral
    if ENRICHMENT_AVAILABLE:
        enrichment_level = get_enrichment_level(user_plan)
        
        # Seuls Pro et Expert ont l'enrichissement
        if enrichment_level != EnrichmentLevel.NONE:
            should_search = False
            search_reason = ""
            
            if web_search_requested:
                # L'utilisateur a demand√© explicitement une recherche web
                should_search = True
                search_reason = "user_requested"
                print(f"üåê [CHAT v5.0] Web search explicitly requested by user", flush=True)
            else:
                # D√©tection INTELLIGENTE: la question n√©cessite-t-elle des infos r√©centes?
                should_search, search_reason = needs_web_search_for_chat(question, video_title)
                if should_search:
                    print(f"üîç [CHAT v5.0] Intelligent detection triggered: {search_reason}", flush=True)
            
            if should_search:
                try:
                    video_context = f"Vid√©o: {video_title}\n\nR√©sum√©: {summary[:1500]}"
                    
                    web_context, sources, was_enriched = await enrich_chat_if_needed(
                        question=question,
                        video_title=video_title,
                        video_context=video_context,
                        plan=user_plan,
                        lang=lang
                    )
                    
                    if was_enriched and web_context:
                        web_search_used = True
                        print(f"‚úÖ [CHAT v5.0] Got web context: {len(web_context)} chars, {len(sources)} sources", flush=True)
                    else:
                        print(f"‚ö†Ô∏è [CHAT v5.0] Web search returned no useful context", flush=True)
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è [CHAT v5.0] Web enrichment failed: {e}", flush=True)
    
    # 2. G√©n√©rer la r√©ponse avec Mistral (avec contexte web si disponible)
    base_response = await generate_chat_response(
        question=question,
        video_title=video_title,
        transcript=transcript,
        summary=summary,
        chat_history=chat_history,
        mode=mode,
        lang=lang,
        model=model,
        video_duration=video_duration  # üÜï Pour la recherche intelligente
    )
    
    if not base_response:
        return "D√©sol√©, je n'ai pas pu g√©n√©rer de r√©ponse.", [], False
    
    print(f"‚úÖ [CHAT v5.0] Base response: {len(base_response)} chars", flush=True)
    
    # 3. Si on a du contexte web, l'ajouter √† la r√©ponse
    if web_search_used and web_context:
        # Ajouter le contexte web √† la fin de la r√©ponse
        web_section_header = "üì° **Informations web actuelles:**" if lang == "fr" else "üì° **Current web information:**"
        
        base_response = f"""{base_response}

---

{web_section_header}

{web_context}"""
        
        print(f"‚úÖ [CHAT v5.0] Added web context to response", flush=True)
    
    return base_response, sources, web_search_used


def _should_auto_enrich_chat(question: str, video_title: str) -> bool:
    """
    D√©termine si une question devrait automatiquement d√©clencher 
    un enrichissement Perplexity (pour Pro/Expert).
    """
    question_lower = question.lower()
    
    # Mots-cl√©s qui d√©clenchent l'enrichissement
    TRIGGER_KEYWORDS = [
        # V√©rification
        "vrai", "faux", "v√©rifier", "confirmer", "exact", "correct",
        "true", "false", "verify", "confirm", "accurate",
        # Actualit√©
        "actuel", "r√©cent", "aujourd'hui", "maintenant", "derni√®re",
        "current", "recent", "today", "now", "latest",
        # Sources
        "source", "preuve", "√©tude", "recherche", "donn√©es",
        "evidence", "study", "research", "data",
        # Comparaison
        "comparer", "diff√©rence", "alternative", "autre",
        "compare", "difference", "alternative", "other",
        # Questions factuelles
        "combien", "quand", "o√π", "qui a", "statistique",
        "how many", "when", "where", "who", "statistic"
    ]
    
    # V√©rifier si la question contient des mots-cl√©s d√©clencheurs
    for keyword in TRIGGER_KEYWORDS:
        if keyword in question_lower:
            return True
    
    # Questions longues et complexes m√©ritent souvent un enrichissement
    if len(question.split()) > 15:
        return True
    
    return False


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üîç PERPLEXITY (Recherche Web) - LEGACY + v4.0
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def check_web_search_quota(
    session: AsyncSession,
    user_id: int
) -> Tuple[bool, int, int]:
    """
    V√©rifie le quota de recherche web.
    Retourne: (can_search, used, limit)
    """
    result = await session.execute(select(User).where(User.id == user_id))
    user = result.scalar_one_or_none()
    
    if not user:
        return False, 0, 0
    
    plan = user.plan or "free"
    limits = PLAN_LIMITS.get(plan, PLAN_LIMITS["free"])
    
    if not limits.get("web_search_enabled", False):
        return False, 0, 0
    
    monthly_limit = limits.get("web_search_monthly", 0)
    if monthly_limit == -1:
        return True, 0, -1  # Illimit√©
    
    # V√©rifier l'usage ce mois
    month = date.today().strftime("%Y-%m")
    usage_result = await session.execute(
        select(WebSearchUsage).where(
            WebSearchUsage.user_id == user_id,
            WebSearchUsage.month_year == month
        )
    )
    usage = usage_result.scalar_one_or_none()
    used = usage.search_count if usage else 0
    
    return used < monthly_limit, used, monthly_limit


async def increment_web_search_usage(session: AsyncSession, user_id: int):
    """Incr√©mente le compteur de recherche web"""
    month = date.today().strftime("%Y-%m")
    
    result = await session.execute(
        select(WebSearchUsage).where(
            WebSearchUsage.user_id == user_id,
            WebSearchUsage.month_year == month
        )
    )
    usage = result.scalar_one_or_none()
    
    if usage:
        usage.search_count += 1
        usage.last_search_at = datetime.now()
    else:
        usage = WebSearchUsage(
            user_id=user_id,
            month_year=month,
            search_count=1,
            last_search_at=datetime.now()
        )
        session.add(usage)
    
    await session.commit()


async def search_with_perplexity(
    question: str,
    context: str,
    lang: str = "fr"
) -> Optional[str]:
    """Fait une recherche web avec Perplexity (Legacy - utilis√© pour le chat explicite)"""
    api_key = get_perplexity_key()
    if not api_key:
        return None
    
    prompt = f"""Recherche des informations actuelles sur cette question en lien avec le contexte suivant.

Contexte: {context[:2000]}

Question: {question}

R√©ponds en {"fran√ßais" if lang == "fr" else "anglais"} avec des sources web r√©centes."""
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.perplexity.ai/chat/completions",
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "llama-3.1-sonar-small-128k-online",
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 1500,
                    "temperature": 0.2
                },
                timeout=30
            )
            
            if response.status_code == 200:
                return response.json()["choices"][0]["message"]["content"]
            return None
    except Exception as e:
        print(f"‚ùå Perplexity error: {e}", flush=True)
        return None


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üéØ FONCTION PRINCIPALE DE CHAT v4.0
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def process_chat_message_v4(
    session: AsyncSession,
    user_id: int,
    summary_id: int,
    question: str,
    web_search: bool = False,
    mode: str = "standard"
) -> Dict[str, Any]:
    """
    üÜï v4.0: Traite un message chat avec enrichissement progressif.
    
    Returns:
        {
            "response": str,
            "web_search_used": bool,
            "sources": List[Dict],
            "enrichment_level": str,
            "quota_info": Dict
        }
    """
    # 1. V√©rifier les quotas
    can_ask, reason, quota_info = await check_chat_quota(session, user_id, summary_id)
    if not can_ask:
        return {
            "response": f"‚ùå Limite atteinte: {reason}",
            "web_search_used": False,
            "sources": [],
            "enrichment_level": "none",
            "quota_info": quota_info,
            "error": reason
        }
    
    # 2. R√©cup√©rer le r√©sum√© et le contexte
    result = await session.execute(select(Summary).where(Summary.id == summary_id))
    summary = result.scalar_one_or_none()
    
    if not summary:
        return {
            "response": "‚ùå R√©sum√© non trouv√©",
            "web_search_used": False,
            "sources": [],
            "enrichment_level": "none",
            "quota_info": quota_info,
            "error": "summary_not_found"
        }
    
    # 3. R√©cup√©rer l'utilisateur pour le plan
    user_result = await session.execute(select(User).where(User.id == user_id))
    user = user_result.scalar_one_or_none()
    user_plan = user.plan if user else "free"
    
    # 4. R√©cup√©rer l'historique
    chat_history = await get_chat_history(session, summary_id, user_id, limit=10)
    
    # 5. D√©terminer le mod√®le selon le plan
    plan_limits = PLAN_LIMITS.get(user_plan, PLAN_LIMITS["free"])
    model = plan_limits.get("default_model", "mistral-small-latest")
    
    # 6. G√©n√©rer la r√©ponse avec enrichissement v4.0
    response, sources, web_search_used = await generate_chat_response_v4(
        question=question,
        video_title=summary.video_title,
        transcript=summary.transcript_context or "",
        summary=summary.summary_content,
        chat_history=chat_history,
        user_plan=user_plan,
        mode=mode,
        lang=summary.lang or "fr",
        model=model,
        web_search_requested=web_search,
        video_duration=summary.video_duration or 0  # üÜï Pour la recherche intelligente
    )
    
    # 7. Sauvegarder les messages
    await save_chat_message(session, user_id, summary_id, "user", question)
    await save_chat_message(session, user_id, summary_id, "assistant", response)
    
    # 8. Incr√©menter les quotas
    await increment_chat_quota(session, user_id)
    if web_search_used:
        await increment_web_search_usage(session, user_id)
    
    # 9. D√©terminer le niveau d'enrichissement
    enrichment_level = "none"
    if ENRICHMENT_AVAILABLE:
        level = get_enrichment_level(user_plan)
        enrichment_level = level.value
    
    return {
        "response": response,
        "web_search_used": web_search_used,
        "sources": sources,
        "enrichment_level": enrichment_level,
        "quota_info": quota_info
    }
