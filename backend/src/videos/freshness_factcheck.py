"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ• FRESHNESS & FACT-CHECK LITE v1.0 â€” Deep Sight                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  FONCTIONNALITÃ‰S:                                                                  â•‘
â•‘  â€¢ ğŸ“… Indicateur de fraÃ®cheur vidÃ©o (alerte si donnÃ©es potentiellement obsolÃ¨tes)  â•‘
â•‘  â€¢ ğŸ” Fact-check LITE gratuit (sans Perplexity, pour Free/Starter)                 â•‘
â•‘  â€¢ âš ï¸ DÃ©tection des affirmations Ã  risque                                          â•‘
â•‘  â€¢ ğŸ“Š Score de confiance basÃ© sur heuristiques                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import re
import httpx
from datetime import datetime, timedelta
from typing import Dict, Any, List, Tuple, Optional
from enum import Enum
from dataclasses import dataclass, field


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“… FRESHNESS INDICATOR â€” Indicateur de fraÃ®cheur vidÃ©o
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class FreshnessLevel(Enum):
    """Niveaux de fraÃ®cheur d'une vidÃ©o"""
    FRESH = "fresh"           # < 3 mois
    RECENT = "recent"         # 3-6 mois
    AGING = "aging"           # 6-12 mois
    OLD = "old"               # 1-2 ans
    OUTDATED = "outdated"     # > 2 ans


@dataclass
class FreshnessResult:
    """RÃ©sultat de l'analyse de fraÃ®cheur"""
    level: FreshnessLevel
    age_days: int
    warning_message: Optional[str] = None
    warning_level: str = "none"  # none, info, warning, critical
    is_fast_changing_topic: bool = False
    topic_category: Optional[str] = None
    recommendations: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "level": self.level.value,
            "age_days": self.age_days,
            "warning_message": self.warning_message,
            "warning_level": self.warning_level,
            "is_fast_changing_topic": self.is_fast_changing_topic,
            "topic_category": self.topic_category,
            "recommendations": self.recommendations
        }


# Sujets qui Ã©voluent rapidement (besoin de donnÃ©es rÃ©centes)
FAST_CHANGING_TOPICS = {
    # Technologie & IA
    "tech": {
        "keywords": [
            "ia", "ai", "intelligence artificielle", "artificial intelligence",
            "chatgpt", "gpt", "claude", "llm", "machine learning", "deep learning",
            "openai", "anthropic", "google ai", "gemini", "mistral",
            "blockchain", "crypto", "bitcoin", "ethereum", "nft", "web3",
            "startup", "tech", "silicon valley", "innovation"
        ],
        "max_fresh_days": 90,
        "category_name": "Technologie/IA"
    },
    # ActualitÃ©s & Politique
    "news": {
        "keywords": [
            "Ã©lection", "election", "vote", "prÃ©sident", "president",
            "gouvernement", "government", "politique", "political",
            "ukraine", "russia", "guerre", "war", "gaza", "israel", "palestine",
            "conflit", "conflict", "crise", "crisis", "actualitÃ©", "news"
        ],
        "max_fresh_days": 30,
        "category_name": "ActualitÃ©s/Politique"
    },
    # Finance & Ã‰conomie
    "finance": {
        "keywords": [
            "bourse", "stock", "cac40", "nasdaq", "dow jones", "s&p",
            "inflation", "taux", "interest rate", "fed", "bce", "ecb",
            "Ã©conomie", "economy", "recession", "croissance", "growth",
            "immobilier", "real estate", "prix", "price"
        ],
        "max_fresh_days": 60,
        "category_name": "Finance/Ã‰conomie"
    },
    # SantÃ©
    "health": {
        "keywords": [
            "covid", "coronavirus", "vaccin", "vaccine", "pandemic",
            "traitement", "treatment", "mÃ©dicament", "drug", "fda", "oms", "who",
            "Ã©tude clinique", "clinical trial", "santÃ© publique", "public health"
        ],
        "max_fresh_days": 90,
        "category_name": "SantÃ©"
    },
    # Science (plus tolÃ©rant mais attention aux dÃ©couvertes rÃ©centes)
    "science": {
        "keywords": [
            "dÃ©couverte", "discovery", "Ã©tude rÃ©cente", "recent study",
            "2024", "2025", "nouveau", "new", "breakthrough"
        ],
        "max_fresh_days": 180,
        "category_name": "Science"
    }
}


def analyze_freshness(
    video_date: str,
    video_title: str,
    video_description: str = "",
    transcript_excerpt: str = ""
) -> FreshnessResult:
    """
    ğŸ• Analyse la fraÃ®cheur d'une vidÃ©o et gÃ©nÃ¨re des avertissements appropriÃ©s.
    
    Args:
        video_date: Date de publication (ISO format ou "YYYY-MM-DD")
        video_title: Titre de la vidÃ©o
        video_description: Description (optionnel)
        transcript_excerpt: Extrait de la transcription (optionnel)
    
    Returns:
        FreshnessResult avec niveau, avertissements et recommandations
    """
    
    # Parser la date
    try:
        if "T" in video_date:
            pub_date = datetime.fromisoformat(video_date.replace("Z", "+00:00"))
        else:
            pub_date = datetime.strptime(video_date[:10], "%Y-%m-%d")
    except (ValueError, TypeError):
        # Si date invalide, supposer rÃ©cent
        pub_date = datetime.now() - timedelta(days=30)
    
    # Calculer l'Ã¢ge en jours
    age_days = (datetime.now() - pub_date.replace(tzinfo=None)).days
    
    # DÃ©terminer le niveau de fraÃ®cheur de base
    if age_days < 90:
        base_level = FreshnessLevel.FRESH
    elif age_days < 180:
        base_level = FreshnessLevel.RECENT
    elif age_days < 365:
        base_level = FreshnessLevel.AGING
    elif age_days < 730:
        base_level = FreshnessLevel.OLD
    else:
        base_level = FreshnessLevel.OUTDATED
    
    # Analyser le contenu pour dÃ©tecter les sujets Ã  Ã©volution rapide
    content = f"{video_title} {video_description} {transcript_excerpt}".lower()
    
    detected_topic = None
    is_fast_changing = False
    max_fresh_days = 365  # Par dÃ©faut 1 an
    
    for topic_id, topic_config in FAST_CHANGING_TOPICS.items():
        for keyword in topic_config["keywords"]:
            if keyword in content:
                detected_topic = topic_config["category_name"]
                is_fast_changing = True
                max_fresh_days = min(max_fresh_days, topic_config["max_fresh_days"])
                break
        if detected_topic:
            break
    
    # GÃ©nÃ©rer les avertissements et recommandations
    warning_message = None
    warning_level = "none"
    recommendations = []
    
    if is_fast_changing and age_days > max_fresh_days:
        # Sujet Ã  Ã©volution rapide ET vidÃ©o trop ancienne
        warning_level = "critical" if age_days > max_fresh_days * 2 else "warning"
        
        if warning_level == "critical":
            warning_message = f"âš ï¸ ATTENTION : Cette vidÃ©o sur {detected_topic} date de {age_days} jours. Les informations sont probablement obsolÃ¨tes."
            recommendations = [
                f"VÃ©rifiez les informations avec des sources datant de moins de {max_fresh_days} jours",
                "Les chiffres, statistiques et faits mentionnÃ©s ont pu changer significativement",
                "Utilisez le chat pour demander une vÃ©rification des points clÃ©s"
            ]
        else:
            warning_message = f"ğŸ“… Cette vidÃ©o sur {detected_topic} a {age_days} jours. Certaines informations peuvent avoir Ã©voluÃ©."
            recommendations = [
                "Les donnÃ©es chiffrÃ©es mÃ©ritent une vÃ©rification",
                "Posez des questions dans le chat pour obtenir des mises Ã  jour"
            ]
    
    elif age_days > 365:
        # VidÃ©o de plus d'un an (tous sujets)
        warning_level = "info"
        years = age_days // 365
        warning_message = f"ğŸ“… VidÃ©o publiÃ©e il y a {years} an{'s' if years > 1 else ''}. VÃ©rifiez l'actualitÃ© des informations."
        recommendations = [
            "Les positions, rÃ´les et statuts mentionnÃ©s ont pu changer",
            "Les statistiques et chiffres peuvent Ãªtre obsolÃ¨tes"
        ]
    
    elif age_days > 180 and not is_fast_changing:
        # VidÃ©o de 6+ mois sur sujet stable
        warning_level = "info"
        warning_message = f"ğŸ“… VidÃ©o de {age_days // 30} mois. Les informations factuelles sont gÃ©nÃ©ralement fiables."
    
    return FreshnessResult(
        level=base_level,
        age_days=age_days,
        warning_message=warning_message,
        warning_level=warning_level,
        is_fast_changing_topic=is_fast_changing,
        topic_category=detected_topic,
        recommendations=recommendations
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ” FACT-CHECK LITE â€” VÃ©rification basique sans API payante
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class ClaimAnalysis:
    """Analyse d'une affirmation"""
    claim: str
    claim_type: str  # statistic, fact, opinion, prediction
    confidence: int  # 0-100
    risk_level: str  # low, medium, high
    verification_hint: Optional[str] = None
    suggested_search: Optional[str] = None


@dataclass
class FactCheckLiteResult:
    """RÃ©sultat du fact-check LITE"""
    overall_confidence: int  # 0-100
    risk_summary: str
    claims_analyzed: int
    high_risk_claims: List[ClaimAnalysis]
    medium_risk_claims: List[ClaimAnalysis]
    verification_suggestions: List[str]
    disclaimers: List[str]
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "overall_confidence": self.overall_confidence,
            "risk_summary": self.risk_summary,
            "claims_analyzed": self.claims_analyzed,
            "high_risk_claims": [
                {
                    "claim": c.claim[:200],
                    "claim_type": c.claim_type,
                    "confidence": c.confidence,
                    "risk_level": c.risk_level,
                    "verification_hint": c.verification_hint,
                    "suggested_search": c.suggested_search
                }
                for c in self.high_risk_claims
            ],
            "medium_risk_claims": [
                {
                    "claim": c.claim[:200],
                    "claim_type": c.claim_type,
                    "confidence": c.confidence,
                    "risk_level": c.risk_level,
                    "verification_hint": c.verification_hint
                }
                for c in self.medium_risk_claims[:5]  # Limiter Ã  5
            ],
            "verification_suggestions": self.verification_suggestions,
            "disclaimers": self.disclaimers
        }


# Patterns pour dÃ©tecter les types d'affirmations
CLAIM_PATTERNS = {
    # Statistiques et chiffres
    "statistics": [
        r'\b(\d+(?:[.,]\d+)?)\s*(%|pour\s*cent|percent)',
        r'\b(\d+(?:[.,]\d+)?)\s*(millions?|milliards?|billions?|trillions?)',
        r'(un|une|le|la)\s+sur\s+(\d+)',
        r'(\d+)\s*fois\s+(plus|moins)',
        r'(augment|diminu|croÃ®t|baisse|hausse).*?(\d+)',
    ],
    # Affirmations temporelles (dates, Ã©vÃ©nements)
    "temporal": [
        r'(en|depuis|avant|aprÃ¨s)\s+(\d{4})',
        r'(il y a|ago)\s+(\d+)\s+(ans?|annÃ©es?|mois|years?|months?)',
        r'(rÃ©cemment|derniÃ¨rement|recently|lately)',
        r'(le|la|les)\s+(premier|derniÃ¨re?|first|last)',
    ],
    # Opinions prÃ©sentÃ©es comme faits
    "opinion_markers": [
        r'\b(Ã©videmment|obviously|clairement|clearly)\b',
        r'\b(tout le monde sait|everyone knows)\b',
        r'\b(il est (Ã©vident|clair)|it\'s (obvious|clear))\b',
        r'\b(sans aucun doute|undoubtedly|sans conteste)\b',
        r'\b(c\'est (un fait|prouvÃ©)|it\'s (a fact|proven))\b',
    ],
    # PrÃ©dictions
    "predictions": [
        r'\b(va|will|going to)\s+(devenir|become|Ãªtre|be)\b',
        r'\b(dans les prochains?|in the next)\s+(\d+)',
        r'\b(d\'ici|by)\s+(\d{4})',
        r'\b(prÃ©dit|prÃ©voit|predicts|forecasts)\b',
    ],
    # Sources vagues
    "vague_sources": [
        r'\b(des Ã©tudes|studies|recherches|research)\s+(montrent|show|prouvent|prove)\b',
        r'\b(on dit que|they say|il paraÃ®t|apparently)\b',
        r'\b(selon (des|les) experts?|according to experts?)\b',
        r'\b(la science (dit|montre)|science (says|shows))\b',
    ],
    # Affirmations extraordinaires
    "extraordinary": [
        r'\b(rÃ©volution|revolutionary|breakthrough)\b',
        r'\b(jamais vu|never seen|sans prÃ©cÃ©dent|unprecedented)\b',
        r'\b(100%|totally|complÃ¨tement|entiÃ¨rement)\s+(efficace|effective|sÃ»r|safe)\b',
        r'\b(guÃ©rit?|cure[sd]?|Ã©limine|eliminates)\s+(tout|all|le)\b',
    ]
}

# Mots-clÃ©s de fiabilitÃ© (augmentent la confiance)
RELIABILITY_BOOSTERS = [
    r'\b(selon|according to)\s+(l\'|the\s+)?(INSEE|Eurostat|OMS|WHO|ONU|UN|FMI|IMF|BCE|ECB)\b',
    r'\b(Ã©tude|study)\s+(publiÃ©e?|published)\s+(dans|in)\s+(Nature|Science|Lancet|NEJM)\b',
    r'\b(rapport|report)\s+(officiel|official)\b',
    r'\b(source|donnÃ©es?|data)\s*:\s*\w+',
    r'\bhttps?://\S+\b',
]

# Mots-clÃ©s qui rÃ©duisent la confiance
RELIABILITY_REDUCERS = [
    r'\b(je pense|I think|Ã  mon avis|in my opinion)\b',
    r'\b(peut-Ãªtre|maybe|perhaps|possibly)\b',
    r'\b(certains disent|some say|on raconte)\b',
    r'\b(rumeur|rumor|buzz)\b',
    r'\b(thÃ©orie du complot|conspiracy)\b',
]


def analyze_claims_lite(
    text: str,
    video_title: str = "",
    lang: str = "fr"
) -> FactCheckLiteResult:
    """
    ğŸ” Analyse les affirmations dans un texte sans API externe.
    Utilise des heuristiques et patterns pour identifier les claims Ã  risque.
    
    Args:
        text: Texte Ã  analyser (rÃ©sumÃ© ou transcription)
        video_title: Titre pour contexte
        lang: Langue (fr/en)
    
    Returns:
        FactCheckLiteResult avec analyse des affirmations
    """
    
    full_text = f"{video_title}\n{text}".lower()
    claims_found = []
    
    # DÃ©tecter les patterns
    for claim_type, patterns in CLAIM_PATTERNS.items():
        for pattern in patterns:
            matches = re.finditer(pattern, full_text, re.IGNORECASE)
            for match in matches:
                # Extraire le contexte autour du match
                start = max(0, match.start() - 100)
                end = min(len(full_text), match.end() + 100)
                context = full_text[start:end].strip()
                
                # Calculer le risque et la confiance
                confidence, risk_level = _calculate_claim_risk(
                    context, claim_type, full_text
                )
                
                # GÃ©nÃ©rer des suggestions de vÃ©rification
                verification_hint = _get_verification_hint(claim_type, match.group(), lang)
                suggested_search = _get_search_suggestion(match.group(), claim_type, lang)
                
                claims_found.append(ClaimAnalysis(
                    claim=context,
                    claim_type=claim_type,
                    confidence=confidence,
                    risk_level=risk_level,
                    verification_hint=verification_hint,
                    suggested_search=suggested_search
                ))
    
    # DÃ©dupliquer et trier par risque
    unique_claims = _deduplicate_claims(claims_found)
    high_risk = [c for c in unique_claims if c.risk_level == "high"]
    medium_risk = [c for c in unique_claims if c.risk_level == "medium"]
    
    # Calculer le score global
    overall_confidence = _calculate_overall_confidence(full_text, unique_claims)
    
    # GÃ©nÃ©rer le rÃ©sumÃ©
    risk_summary = _generate_risk_summary(overall_confidence, high_risk, medium_risk, lang)
    
    # Suggestions de vÃ©rification
    suggestions = _generate_verification_suggestions(high_risk, medium_risk, lang)
    
    # Disclaimers
    disclaimers = [
        "Cette analyse est basÃ©e sur des heuristiques, pas sur une vÃ©rification factuelle complÃ¨te.",
        "Les scores de confiance sont indicatifs et ne garantissent pas l'exactitude.",
        "Pour une vÃ©rification approfondie, utilisez le plan Pro avec recherche web Perplexity."
    ] if lang == "fr" else [
        "This analysis is based on heuristics, not complete fact-checking.",
        "Confidence scores are indicative and don't guarantee accuracy.",
        "For thorough verification, use Pro plan with Perplexity web search."
    ]
    
    return FactCheckLiteResult(
        overall_confidence=overall_confidence,
        risk_summary=risk_summary,
        claims_analyzed=len(unique_claims),
        high_risk_claims=high_risk[:10],  # Limiter
        medium_risk_claims=medium_risk[:10],
        verification_suggestions=suggestions,
        disclaimers=disclaimers
    )


def _calculate_claim_risk(
    context: str,
    claim_type: str,
    full_text: str
) -> Tuple[int, str]:
    """Calcule le risque et la confiance d'une affirmation"""
    
    base_confidence = 70  # Confiance de base
    
    # Ajustements selon le type
    type_adjustments = {
        "statistics": -10,  # Chiffres = besoin de vÃ©rification
        "temporal": -5,
        "opinion_markers": -25,  # Opinions = basse confiance
        "predictions": -20,
        "vague_sources": -30,  # Sources vagues = trÃ¨s risquÃ©
        "extraordinary": -35,  # Affirmations extraordinaires
    }
    
    confidence = base_confidence + type_adjustments.get(claim_type, 0)
    
    # Boosters (augmentent la confiance)
    for pattern in RELIABILITY_BOOSTERS:
        if re.search(pattern, context, re.IGNORECASE):
            confidence += 15
    
    # Reducers (diminuent la confiance)
    for pattern in RELIABILITY_REDUCERS:
        if re.search(pattern, context, re.IGNORECASE):
            confidence -= 10
    
    # Clamp entre 10 et 95
    confidence = max(10, min(95, confidence))
    
    # DÃ©terminer le niveau de risque
    if confidence < 40:
        risk_level = "high"
    elif confidence < 65:
        risk_level = "medium"
    else:
        risk_level = "low"
    
    return confidence, risk_level


def _get_verification_hint(claim_type: str, match_text: str, lang: str) -> str:
    """GÃ©nÃ¨re un conseil de vÃ©rification selon le type"""
    
    hints_fr = {
        "statistics": "VÃ©rifiez ce chiffre sur INSEE, Eurostat ou la source primaire",
        "temporal": "Confirmez cette date/pÃ©riode avec une source officielle",
        "opinion_markers": "Ceci semble Ãªtre une opinion, pas un fait Ã©tabli",
        "predictions": "Les prÃ©dictions sont par nature incertaines",
        "vague_sources": "Source vague - recherchez la source primaire",
        "extraordinary": "Affirmation forte - exige des preuves solides",
    }
    
    hints_en = {
        "statistics": "Verify this figure on official statistical sources",
        "temporal": "Confirm this date/period with an official source",
        "opinion_markers": "This appears to be an opinion, not an established fact",
        "predictions": "Predictions are inherently uncertain",
        "vague_sources": "Vague source - search for the primary source",
        "extraordinary": "Strong claim - requires solid evidence",
    }
    
    hints = hints_fr if lang == "fr" else hints_en
    return hints.get(claim_type, "VÃ©rification recommandÃ©e" if lang == "fr" else "Verification recommended")


def _get_search_suggestion(match_text: str, claim_type: str, lang: str) -> Optional[str]:
    """GÃ©nÃ¨re une suggestion de recherche Google"""
    
    # Extraire les nombres et mots-clÃ©s importants
    numbers = re.findall(r'\d+(?:[.,]\d+)?', match_text)
    
    if numbers and claim_type == "statistics":
        return f"statistique {numbers[0]} site:insee.fr OR site:eurostat.ec.europa.eu"
    
    return None


def _deduplicate_claims(claims: List[ClaimAnalysis]) -> List[ClaimAnalysis]:
    """DÃ©duplique les claims similaires"""
    seen = set()
    unique = []
    
    for claim in claims:
        # Simplifier pour comparaison
        key = claim.claim[:50].lower()
        if key not in seen:
            seen.add(key)
            unique.append(claim)
    
    return unique


def _calculate_overall_confidence(text: str, claims: List[ClaimAnalysis]) -> int:
    """Calcule un score de confiance global"""
    
    if not claims:
        return 75  # Par dÃ©faut si pas de claims dÃ©tectÃ©s
    
    # Moyenne pondÃ©rÃ©e par risque
    weights = {"high": 3, "medium": 1.5, "low": 0.5}
    total_weight = 0
    weighted_sum = 0
    
    for claim in claims:
        weight = weights.get(claim.risk_level, 1)
        weighted_sum += claim.confidence * weight
        total_weight += weight
    
    if total_weight == 0:
        return 75
    
    base_score = weighted_sum / total_weight
    
    # PÃ©nalitÃ© si beaucoup de claims Ã  risque
    high_risk_count = sum(1 for c in claims if c.risk_level == "high")
    if high_risk_count > 5:
        base_score -= 10
    elif high_risk_count > 2:
        base_score -= 5
    
    return max(20, min(90, int(base_score)))


def _generate_risk_summary(
    confidence: int,
    high_risk: List[ClaimAnalysis],
    medium_risk: List[ClaimAnalysis],
    lang: str
) -> str:
    """GÃ©nÃ¨re un rÃ©sumÃ© du niveau de risque"""
    
    high_count = len(high_risk)
    medium_count = len(medium_risk)
    
    if lang == "fr":
        if confidence >= 75:
            return f"âœ… FiabilitÃ© correcte. {high_count} point(s) Ã  vÃ©rifier."
        elif confidence >= 50:
            return f"âš–ï¸ FiabilitÃ© moyenne. {high_count} affirmation(s) Ã  risque, {medium_count} Ã  surveiller."
        else:
            return f"âš ï¸ Prudence recommandÃ©e. {high_count} affirmation(s) potentiellement douteuses dÃ©tectÃ©es."
    else:
        if confidence >= 75:
            return f"âœ… Reasonable reliability. {high_count} point(s) to verify."
        elif confidence >= 50:
            return f"âš–ï¸ Medium reliability. {high_count} risky claim(s), {medium_count} to watch."
        else:
            return f"âš ï¸ Caution advised. {high_count} potentially dubious claim(s) detected."


def _generate_verification_suggestions(
    high_risk: List[ClaimAnalysis],
    medium_risk: List[ClaimAnalysis],
    lang: str
) -> List[str]:
    """GÃ©nÃ¨re des suggestions de vÃ©rification"""
    
    suggestions = []
    
    # Statistiques
    has_stats = any(c.claim_type == "statistics" for c in high_risk + medium_risk)
    if has_stats:
        suggestions.append(
            "VÃ©rifiez les statistiques citÃ©es sur INSEE, Eurostat ou les sources officielles" 
            if lang == "fr" else 
            "Verify cited statistics on official sources like national statistics offices"
        )
    
    # Sources vagues
    has_vague = any(c.claim_type == "vague_sources" for c in high_risk)
    if has_vague:
        suggestions.append(
            "Plusieurs sources sont vagues - recherchez les Ã©tudes/rapports originaux"
            if lang == "fr" else
            "Several sources are vague - look for original studies/reports"
        )
    
    # Affirmations extraordinaires
    has_extraordinary = any(c.claim_type == "extraordinary" for c in high_risk)
    if has_extraordinary:
        suggestions.append(
            "Des affirmations extraordinaires nÃ©cessitent des preuves extraordinaires"
            if lang == "fr" else
            "Extraordinary claims require extraordinary evidence"
        )
    
    # Suggestion gÃ©nÃ©rale
    if not suggestions:
        suggestions.append(
            "Croisez les informations avec d'autres sources pour plus de fiabilitÃ©"
            if lang == "fr" else
            "Cross-reference information with other sources for better reliability"
        )
    
    return suggestions[:5]  # Max 5 suggestions


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¯ FONCTION COMBINÃ‰E â€” FraÃ®cheur + Fact-Check
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_content_reliability(
    video_date: str,
    video_title: str,
    summary_content: str,
    video_description: str = "",
    lang: str = "fr"
) -> Dict[str, Any]:
    """
    ğŸ¯ Analyse complÃ¨te : fraÃ®cheur + fact-check LITE.
    
    Cette fonction est le point d'entrÃ©e principal pour les plans Free/Starter.
    
    Returns:
        Dict avec freshness et fact_check_lite
    """
    
    # Analyse de fraÃ®cheur
    freshness = analyze_freshness(
        video_date=video_date,
        video_title=video_title,
        video_description=video_description,
        transcript_excerpt=summary_content[:2000]
    )
    
    # Fact-check LITE
    fact_check = analyze_claims_lite(
        text=summary_content,
        video_title=video_title,
        lang=lang
    )
    
    return {
        "freshness": freshness.to_dict(),
        "fact_check_lite": fact_check.to_dict(),
        "analysis_type": "lite",
        "analyzed_at": datetime.utcnow().isoformat()
    }
