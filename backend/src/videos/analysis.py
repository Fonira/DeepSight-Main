"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ§  ANALYSIS SERVICE v3.0 â€” GÃ©nÃ©ration de synthÃ¨ses avec Mistral AI                â•‘
â•‘  ğŸ†• v3.0: Support du contexte web prÃ©-analyse (Perplexity)                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import httpx
import json
import re
from typing import Optional, Dict, Any, List, Tuple
from datetime import datetime

from core.config import get_mistral_key, get_perplexity_key, MISTRAL_MODELS, VERSION

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“‹ RÃˆGLES Ã‰PISTÃ‰MIQUES (Raisonnement BayÃ©sien)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EPISTEMIC_RULES_FR = """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ IMPÃ‰RATIF Ã‰PISTÃ‰MIQUE â€” Ã€ APPLIQUER Ã€ CHAQUE AFFIRMATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Tu es un analyste critique qui distingue SYSTÃ‰MATIQUEMENT :
â€¢ FAIT VÃ‰RIFIÃ‰ : Information factuelle vÃ©rifiable (date, chiffre, Ã©vÃ©nement)
â€¢ OPINION : Point de vue subjectif de l'auteur (signalÃ© par "Selon X...", "L'auteur affirme...")
â€¢ HYPOTHÃˆSE : Proposition non prouvÃ©e mais argumentÃ©e
â€¢ SPÃ‰CULATION : Conjecture sans preuve solide

RÃˆGLES D'OR :
1. Ne jamais prÃ©senter une opinion comme un fait
2. Toujours attribuer les affirmations ("Selon l'auteur...", "L'intervenant affirme...")
3. Signaler les affirmations extraordinaires ou non Ã©tayÃ©es
4. Utiliser le conditionnel pour les hypothÃ¨ses

MARQUEURS Ã€ UTILISER :
âœ… SOLIDE â€” Fait vÃ©rifiÃ©, consensus scientifique
âš–ï¸ PLAUSIBLE â€” Argument cohÃ©rent mais preuves limitÃ©es
â“ INCERTAIN â€” IntÃ©ressant mais non dÃ©montrÃ©
âš ï¸ Ã€ VÃ‰RIFIER â€” Affirmation forte sans source
"""

EPISTEMIC_RULES_EN = """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ EPISTEMIC IMPERATIVE â€” APPLY TO EVERY CLAIM
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

You are a critical analyst who SYSTEMATICALLY distinguishes:
â€¢ VERIFIED FACT: Verifiable factual information (date, number, event)
â€¢ OPINION: Author's subjective viewpoint (signaled by "According to X...", "The author claims...")
â€¢ HYPOTHESIS: Unproven but argued proposition
â€¢ SPECULATION: Conjecture without solid evidence

GOLDEN RULES:
1. Never present an opinion as a fact
2. Always attribute claims ("According to the author...", "The speaker states...")
3. Flag extraordinary or unsupported claims
4. Use conditional for hypotheses

MARKERS TO USE:
âœ… SOLID â€” Verified fact, scientific consensus
âš–ï¸ PLAUSIBLE â€” Coherent argument but limited evidence
â“ UNCERTAIN â€” Interesting but undemonstrated
âš ï¸ TO VERIFY â€” Strong claim without source
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“‚ CATÃ‰GORIES ET TEMPLATES v2.0 â€” DÃ©tection AmÃ©liorÃ©e
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CATEGORIES = {
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ™ï¸ INTERVIEWS & PODCASTS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "interview": {
        "name": {"fr": "ğŸ™ï¸ Interview/Podcast", "en": "ğŸ™ï¸ Interview/Podcast"},
        "keywords": [
            # Termes directs
            "interview", "podcast", "entretien", "invitÃ©", "guest", "talk", "discussion",
            # Formats d'Ã©mission
            "live", "Ã©pisode", "episode", "Ã©mission", "show", "thinkerview", "quotidien",
            "brut", "clique", "konbini", "hugodecrypte", "mcfly et carlito",
            # Structure interview
            "nous recevons", "aujourd'hui avec nous", "bienvenue Ã ", "welcome",
            "on accueille", "notre invitÃ©", "joining us", "sit down with"
        ],
        "min_words": 1500,
        "max_words": 5000,
        "template_focus": "dialogue_structure"  # Focus sur les Ã©changes Q/R
    },
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“½ï¸ DOCUMENTAIRES & REPORTAGES
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "documentary": {
        "name": {"fr": "ğŸ“½ï¸ Documentaire", "en": "ğŸ“½ï¸ Documentary"},
        "keywords": [
            # Termes directs
            "documentaire", "documentary", "reportage", "enquÃªte", "investigation",
            # Format narratif
            "histoire de", "story of", "l'affaire", "the case of", "true story",
            "au coeur de", "inside", "dans les coulisses", "behind the scenes",
            # ChaÃ®nes documentaires
            "arte", "national geographic", "netflix documentary", "bbc documentary",
            "france 5", "histoire", "discovery"
        ],
        "min_words": 1800,
        "max_words": 6000,
        "template_focus": "narrative_arc"  # Focus sur l'arc narratif
    },
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“ TUTORIELS & HOW-TO
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "tutorial": {
        "name": {"fr": "ğŸ“ Tutoriel", "en": "ğŸ“ Tutorial"},
        "keywords": [
            # Termes directs
            "tutoriel", "tutorial", "guide", "how to", "comment", "apprendre", "learn",
            # Actions pratiques
            "Ã©tape par Ã©tape", "step by step", "pas Ã  pas", "tuto", "dÃ©butant",
            "beginner", "facile", "easy", "crÃ©er", "create", "faire", "make",
            # Domaines spÃ©cifiques
            "coding", "programmation", "diy", "bricolage", "cuisine", "cooking",
            "photoshop", "premiere", "excel", "python", "javascript"
        ],
        "min_words": 1000,
        "max_words": 3500,
        "template_focus": "actionable_steps"  # Focus sur les Ã©tapes pratiques
    },
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ”¬ SCIENCE & VULGARISATION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "science": {
        "name": {"fr": "ğŸ”¬ Science", "en": "ğŸ”¬ Science"},
        "keywords": [
            # Termes scientifiques gÃ©nÃ©raux
            "science", "scientifique", "recherche", "Ã©tude", "study", "research",
            "expÃ©rience", "experiment", "thÃ©orie", "theory", "dÃ©couverte", "discovery",
            "hypothÃ¨se", "hypothesis", "dÃ©monstration", "preuve", "proof",
            # Disciplines - Physique & Cosmologie
            "physique", "physics", "cosmologie", "cosmology", "astrophysique", "astrophysics",
            "univers", "universe", "cosmos", "big bang", "relativitÃ©", "relativity",
            "quantique", "quantum", "mÃ©canique quantique", "quantum mechanics",
            "trou noir", "black hole", "gravitÃ©", "gravity", "masse", "mass",
            "Ã©nergie noire", "dark energy", "matiÃ¨re noire", "dark matter",
            "modÃ¨le", "model", "Ã©quation", "equation", "constante", "constant",
            # Disciplines - Autres
            "chimie", "chemistry", "biologie", "biology", "astronomie", "astronomy", 
            "mÃ©decine", "medicine", "neuroscience", "neurologie", "gÃ©nÃ©tique", "genetics",
            "Ã©volution", "evolution", "Ã©cologie", "ecology", "gÃ©ologie", "geology",
            # Termes Ã©pistÃ©miques
            "falsifiable", "rÃ©futable", "peer review", "publication", "consensus",
            "Nobel", "chercheur", "researcher", "laboratoire", "laboratory",
            # ChaÃ®nes scientifiques connues
            "e-penser", "scilabus", "dirty biology", "veritasium", "kurzgesagt",
            "vsauce", "smarter every day", "science Ã©tonnante", "scienceclic"
        ],
        "min_words": 1200,
        "max_words": 4500,
        "template_focus": "evidence_based"  # Focus sur les preuves et mÃ©thodologie
    },
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“° ACTUALITÃ‰S & NEWS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "news": {
        "name": {"fr": "ğŸ“° ActualitÃ©s", "en": "ğŸ“° News"},
        "keywords": [
            # Termes d'actualitÃ©
            "actualitÃ©", "news", "breaking", "journalisme", "info", "report",
            "derniÃ¨res nouvelles", "breaking news", "flash info", "journal",
            # Contexte temporel
            "aujourd'hui", "today", "cette semaine", "this week", "rÃ©cent", "recent",
            "2024", "2025", "ce matin", "hier", "yesterday",
            # MÃ©dias
            "bfm", "cnews", "lci", "france info", "cnn", "bbc news", "reuters"
        ],
        "min_words": 800,
        "max_words": 2500,
        "template_focus": "5w1h"  # Focus sur Qui/Quoi/OÃ¹/Quand/Pourquoi/Comment
    },
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“ CONFÃ‰RENCES & PRÃ‰SENTATIONS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "conference": {
        "name": {"fr": "ğŸ“ ConfÃ©rence", "en": "ğŸ“ Conference"},
        "keywords": [
            # Termes directs
            "confÃ©rence", "conference", "ted", "tedx", "talk", "keynote", "prÃ©sentation",
            "presentation", "speech", "discours", "lecture",
            # Contexte acadÃ©mique
            "colloque", "symposium", "summit", "forum", "sÃ©minaire", "seminar",
            "universitÃ©", "university", "acadÃ©mie", "academy"
        ],
        "min_words": 1400,
        "max_words": 4500,
        "template_focus": "thesis_arguments"  # Focus sur thÃ¨se centrale et arguments
    },
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # âš–ï¸ DÃ‰BATS & CONTROVERSES
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "debate": {
        "name": {"fr": "âš–ï¸ DÃ©bat", "en": "âš–ï¸ Debate"},
        "keywords": [
            # Termes directs
            "dÃ©bat", "debate", "controverse", "opposition", "versus", "vs",
            "face Ã  face", "confrontation", "clash", "polÃ©mique", "controversy",
            # Structure de dÃ©bat
            "pour ou contre", "pros and cons", "d'un cÃ´tÃ©... de l'autre",
            "on one hand... on the other", "disagreement", "dÃ©saccord"
        ],
        "min_words": 1500,
        "max_words": 5000,
        "template_focus": "balanced_perspectives"  # Focus sur les deux cÃ´tÃ©s
    },
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ’° FINANCE & Ã‰CONOMIE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "finance": {
        "name": {"fr": "ğŸ’° Finance", "en": "ğŸ’° Finance"},
        "keywords": [
            # Termes financiers
            "finance", "investissement", "investment", "bourse", "stock", "trading",
            "Ã©conomie", "economy", "crypto", "bitcoin", "ethereum", "nft",
            # Concepts spÃ©cifiques
            "portefeuille", "portfolio", "rendement", "return", "dividende", "dividend",
            "action", "obligation", "bond", "etf", "marchÃ©", "market",
            # Immobilier
            "immobilier", "real estate", "scpi", "location", "rental"
        ],
        "min_words": 1200,
        "max_words": 4000,
        "template_focus": "risk_return"  # Focus sur risques et opportunitÃ©s
    },
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ’» TECH & IA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "tech": {
        "name": {"fr": "ğŸ’» Tech", "en": "ğŸ’» Tech"},
        "keywords": [
            # Termes tech
            "tech", "technology", "digital", "software", "hardware", "ai", "ia",
            "intelligence artificielle", "artificial intelligence", "machine learning",
            # Produits
            "apple", "google", "microsoft", "meta", "openai", "chatgpt", "claude",
            "iphone", "android", "startup", "licorne", "unicorn",
            # Concepts
            "algorithme", "algorithm", "data", "donnÃ©es", "cloud", "cybersÃ©curitÃ©"
        ],
        "min_words": 1200,
        "max_words": 4000,
        "template_focus": "implications"  # Focus sur implications et tendances
    },
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ¥ SANTÃ‰ & BIEN-ÃŠTRE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "health": {
        "name": {"fr": "ğŸ¥ SantÃ©", "en": "ğŸ¥ Health"},
        "keywords": [
            # Termes mÃ©dicaux
            "santÃ©", "health", "mÃ©dical", "medical", "bien-Ãªtre", "wellness",
            "maladie", "disease", "traitement", "treatment", "symptÃ´me", "symptom",
            # PrÃ©vention
            "nutrition", "rÃ©gime", "diet", "exercice", "exercise", "sommeil", "sleep",
            "mental", "psychologie", "psychology", "stress", "anxiÃ©tÃ©", "anxiety",
            # Sources fiables
            "oms", "who", "mÃ©decin", "doctor", "hÃ´pital", "hospital", "Ã©tude clinique"
        ],
        "min_words": 1200,
        "max_words": 4000,
        "template_focus": "evidence_caution"  # Focus sur preuves + avertissements
    },
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸŒ GÃ‰OPOLITIQUE & SOCIÃ‰TÃ‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "geopolitics": {
        "name": {"fr": "ğŸŒ GÃ©opolitique", "en": "ğŸŒ Geopolitics"},
        "keywords": [
            # Termes gÃ©opolitiques
            "gÃ©opolitique", "geopolitics", "relations internationales", "international relations",
            "diplomatie", "diplomacy", "conflit", "conflict", "guerre", "war",
            # EntitÃ©s
            "onu", "un", "otan", "nato", "union europÃ©enne", "european union",
            "Ã©tats-unis", "usa", "chine", "china", "russie", "russia",
            # Concepts
            "souverainetÃ©", "sovereignty", "sanctions", "embargo", "traitÃ©", "treaty"
        ],
        "min_words": 1400,
        "max_words": 5000,
        "template_focus": "stakeholders"  # Focus sur les acteurs et enjeux
    },
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ¨ CULTURE & ARTS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "culture": {
        "name": {"fr": "ğŸ¨ Culture", "en": "ğŸ¨ Culture"},
        "keywords": [
            # Arts
            "culture", "art", "musique", "music", "cinÃ©ma", "cinema", "film",
            "littÃ©rature", "literature", "thÃ©Ã¢tre", "theatre", "peinture", "painting",
            # Critique
            "critique", "review", "analyse", "analysis", "chef d'oeuvre", "masterpiece",
            "artiste", "artist", "rÃ©alisateur", "director", "auteur", "author"
        ],
        "min_words": 1000,
        "max_words": 3500,
        "template_focus": "artistic_analysis"  # Focus sur l'analyse artistique
    },
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“‹ GÃ‰NÃ‰RAL (Fallback)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "general": {
        "name": {"fr": "ğŸ“‹ GÃ©nÃ©ral", "en": "ğŸ“‹ General"},
        "keywords": [],
        "min_words": 1000,
        "max_words": 3500,
        "template_focus": "balanced"
    }
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ·ï¸ CHAÃNES CONNUES PAR CATÃ‰GORIE (pour amÃ©liorer la dÃ©tection)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

KNOWN_CHANNELS = {
    "science": [
        # FranÃ§ais - Science & Vulgarisation
        "e-penser", "scilabus", "dirty biology", "science Ã©tonnante", "le blob",
        "balade mentale", "astronogeek", "nota bene", "science4all", "monsieur phi",
        "hygiÃ¨ne mentale", "defakator", "le sense of wonder", "scienceclic",
        "biomÃ©canique", "science de comptoir", "string theory", "les chroniques de la science",
        "l'esprit sorcier", "scienticfiz", "c'est pas sorcier", "florence porcel",
        "espace des sciences", "palais de la dÃ©couverte", "science&vie tv",
        # Jean-Pierre Petit et autres physiciens
        "jean-pierre petit", "jp petit", "janus cosmological model",
        "etienne klein", "aurÃ©lien barrau", "thibault damour",
        # Anglais
        "veritasium", "kurzgesagt", "vsauce", "smarter every day", "numberphile",
        "minutephysics", "3blue1brown", "pbs space time", "physics girl",
        "scishow", "tom scott", "real engineering", "mark rober", "primer",
        "up and atom", "sabine hossenfelder", "sean carroll", "pbs eons",
        "sixty symbols", "periodic videos", "computerphile", "lex fridman science",
    ],
    "interview": [
        # FranÃ§ais
        "thinkerview", "blast", "mediapart", "le mÃ©dia", "clique", "quotidien",
        "brut", "konbini", "hugodecrypte", "mcfly et carlito", "popcorn",
        "first team", "osmose podcast", "generation do it yourself", "gdiy",
        "les grandes gueules", "on n'est pas couchÃ©", "la grande librairie",
        # Anglais
        "joe rogan", "lex fridman", "jordan peterson", "tim ferriss", 
        "naval ravikant", "diary of a ceo", "impact theory", "london real",
        "h3 podcast", "hot ones", "the breakfast club", "conan o'brien",
    ],
    "tech": [
        # FranÃ§ais
        "underscore", "micode", "lÃ©o duff", "guillaume slash", "nowtech",
        "tech lead fr", "cookie connectÃ©", "parfaitement web",
        # Anglais
        "linus tech tips", "mkbhd", "the verge", "wired", "cnet",
        "fireship", "tech lead", "traversy media", "joma tech",
        "dave2d", "unbox therapy", "austin evans", "jayztwocents",
    ],
    "finance": [
        # FranÃ§ais
        "xavier delmas", "finary", "matthieu louvet", "grand angle",
        "les investisseurs 4.0", "objectif libre", "revenus et dividendes",
        # Anglais
        "invest with queenie", "andrei jikh", "graham stephan",
        "meet kevin", "mark tilbury", "ali abdaal money",
    ],
    "documentary": [
        "arte", "france 5", "national geographic", "bbc documentary",
        "netflix documentary", "envoyÃ© spÃ©cial", "cash investigation",
        "complÃ©ment d'enquÃªte", "infrarouge", "documentaire sociÃ©tÃ©",
        "vice", "vox", "frontline pbs", "history channel",
    ],
    "geopolitics": [
        "le dessous des cartes", "gÃ©opoliticus", "mappingtheworld",
        "tldr news", "caspian report", "visual politik", "polymatter",
        "real life lore", "wendover productions", "half as interesting",
    ],
    "tutorial": [
        # FranÃ§ais
        "grafikart", "pierre giraud", "openclassrooms", "formation informatique",
        # Anglais
        "traversy media", "freecodecamp", "the coding train", "web dev simplified",
        "fireship", "net ninja", "programming with mosh", "sentdex",
    ],
    "health": [
        "primum non nocere", "nutrition facts", "what i've learned",
        "docteur jimmy mohamed", "michel cymes", "dans ton corps",
        "andrew huberman", "dr berg", "medlife crisis",
    ],
    "news": [
        "bfmtv", "cnews", "france info", "lci", "france 24",
        "bbc news", "cnn", "reuters", "al jazeera", "dw news",
        "euronews", "sky news", "abc news",
    ],
    "culture": [
        # FranÃ§ais
        "arte cinÃ©ma", "blow up arte", "le fossoyeur de films", "inthepanda",
        "captain popcorn", "durendal", "les chroniques du mea",
        # Anglais
        "every frame a painting", "nerdwriter", "lindsay ellis",
        "lessons from the screenplay", "channel criswell",
    ],
    "debate": [
        "c dans l'air", "28 minutes arte", "l'heure des pros",
        "bfm story", "punchline", "face Ã  l'info",
    ],
}

# CatÃ©gories YouTube natives â†’ nos catÃ©gories
YOUTUBE_CATEGORY_MAPPING = {
    "Science & Technology": "science",
    "Education": "science",  # Souvent de la vulgarisation
    "News & Politics": "geopolitics",
    "People & Blogs": "interview",  # Souvent des podcasts
    "Entertainment": "general",
    "Music": "culture",
    "Film & Animation": "culture",
    "Gaming": "tech",
    "Howto & Style": "tutorial",
    "Sports": "general",
    "Nonprofits & Activism": "geopolitics",
    "Autos & Vehicles": "tech",
    "Pets & Animals": "documentary",
    "Travel & Events": "documentary",
    "Comedy": "general",
}


def detect_category(
    title: str, 
    description: str = "", 
    transcript: str = "",
    channel: str = "",
    tags: List[str] = None,
    youtube_categories: List[str] = None
) -> Tuple[str, float]:
    """
    ğŸ†• v3.0: DÃ©tection INTELLIGENTE de catÃ©gorie avec mÃ©tadonnÃ©es complÃ¨tes.
    
    Utilise dans l'ordre de prioritÃ©:
    1. Nom de la chaÃ®ne (chaÃ®nes connues = trÃ¨s haute confiance)
    2. Tags YouTube (bonne indication du contenu)
    3. CatÃ©gorie YouTube native (mapping)
    4. Titre (pondÃ©ration x5)
    5. Description (pondÃ©ration x2)
    6. Transcript (premiers 5000 mots)
    
    Retourne: (category_id, confidence)
    """
    tags = tags or []
    youtube_categories = youtube_categories or []
    
    # Normaliser les textes
    title_lower = title.lower() if title else ""
    desc_lower = description.lower() if description else ""
    channel_lower = channel.lower() if channel else ""
    tags_lower = [t.lower() for t in tags]
    transcript_lower = transcript[:8000].lower() if transcript else ""
    
    print(f"ğŸ·ï¸ [CATEGORY DETECTION v3.0]", flush=True)
    print(f"   ğŸ“º Channel: {channel}", flush=True)
    print(f"   ğŸ¬ Title: {title[:60]}...", flush=True)
    print(f"   ğŸ·ï¸ Tags: {tags[:5]}...", flush=True)
    print(f"   ğŸ“‚ YT Categories: {youtube_categories}", flush=True)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. CHAÃNE CONNUE (PRIORITÃ‰ MAXIMALE)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    for cat_id, channels in KNOWN_CHANNELS.items():
        for known_channel in channels:
            if known_channel in channel_lower:
                print(f"   âœ… MATCH: Known channel '{known_channel}' â†’ {cat_id} (confidence: 0.95)", flush=True)
                return cat_id, 0.95
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. CATÃ‰GORIE YOUTUBE NATIVE (HAUTE CONFIANCE)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    for yt_cat in youtube_categories:
        if yt_cat in YOUTUBE_CATEGORY_MAPPING:
            mapped_cat = YOUTUBE_CATEGORY_MAPPING[yt_cat]
            if mapped_cat != "general":
                print(f"   âœ… MATCH: YouTube category '{yt_cat}' â†’ {mapped_cat} (confidence: 0.85)", flush=True)
                return mapped_cat, 0.85
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. ANALYSE PAR MOTS-CLÃ‰S PONDÃ‰RÃ‰S
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    scores = {}
    
    for cat_id, cat_info in CATEGORIES.items():
        if cat_id == "general":
            continue
        
        score = 0
        matches = []
        
        for kw in cat_info["keywords"]:
            kw_lower = kw.lower()
            
            # Bonus chaÃ®ne (x10)
            if kw_lower in channel_lower:
                score += 10
                matches.append(f"channel:{kw}")
            
            # Bonus tags (x8) - trÃ¨s fiable
            if any(kw_lower in tag for tag in tags_lower):
                score += 8
                matches.append(f"tag:{kw}")
            
            # Bonus titre (x5)
            if kw_lower in title_lower:
                score += 5
                matches.append(f"title:{kw}")
            
            # Bonus description (x2)
            if kw_lower in desc_lower:
                count = desc_lower.count(kw_lower)
                score += min(count * 2, 6)  # Max 6 points
                if count > 0:
                    matches.append(f"desc:{kw}x{count}")
            
            # Transcript (x1)
            if kw_lower in transcript_lower:
                count = transcript_lower.count(kw_lower)
                score += min(count, 5)  # Max 5 points
        
        if score > 0:
            scores[cat_id] = {"score": score, "matches": matches[:10]}
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. SÃ‰LECTION DU MEILLEUR
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if not scores:
        print(f"   âš ï¸ No matches found â†’ general (confidence: 0.50)", flush=True)
        return "general", 0.50
    
    # Trier par score
    sorted_cats = sorted(scores.items(), key=lambda x: x[1]["score"], reverse=True)
    best_cat = sorted_cats[0][0]
    best_score = sorted_cats[0][1]["score"]
    best_matches = sorted_cats[0][1]["matches"]
    
    # Log des top 3
    print(f"   ğŸ“Š Top categories:", flush=True)
    for cat, info in sorted_cats[:3]:
        print(f"      - {cat}: score={info['score']} matches={info['matches'][:5]}", flush=True)
    
    # Calculer la confiance
    if len(sorted_cats) > 1:
        second_score = sorted_cats[1][1]["score"]
        gap = (best_score - second_score) / max(best_score, 1)
        confidence = min(0.92, 0.55 + (gap * 0.25) + (min(best_score, 30) * 0.01))
    else:
        confidence = min(0.90, 0.60 + (min(best_score, 25) * 0.012))
    
    print(f"   âœ… SELECTED: {best_cat} (confidence: {confidence:.2f})", flush=True)
    
    return best_cat, confidence


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¯ GÃ‰NÃ‰RATION DES PROMPTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_mode_instructions(mode: str, lang: str) -> str:
    """Retourne les instructions spÃ©cifiques au mode d'analyse"""
    
    if lang == "fr":
        instructions = {
            "accessible": """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“– MODE ACCESSIBLE â€” Le Vulgarisateur Brillant                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ­ PERSONA : Tu es un professeur charismatique qui rend TOUT fascinant.
   Tu simplifies sans jamais trahir. Tu enthousiasmes sans jamais mentir.

ğŸ¯ OBJECTIF : Une synthÃ¨se qu'on a ENVIE de lire et qu'on RETIENT
   â†’ L'essentiel en 60 secondes de lecture
   â†’ Des "Aha moments" qui marquent l'esprit
   â†’ ZÃ©ro jargon inutile, 100% impact

âœ¨ STYLE "SEXY BUT SMART" :
   â€¢ Accroche percutante dÃ¨s la premiÃ¨re phrase
   â€¢ Analogies mÃ©morables ("C'est comme si...")
   â€¢ Phrases courtes et punchy (max 20 mots)
   â€¢ Emojis stratÃ©giques pour scanner rapidement

ğŸ“ STRUCTURE Ã‰PURÃ‰E :
   ğŸ¯ L'ESSENTIEL (2-3 phrases choc)
   ğŸ“ LES POINTS CLÃ‰S (3-5 max, avec timecodes)
   ğŸ’¡ LE TAKEAWAY (1 phrase mÃ©morable)
""",
            "standard": """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“Š MODE STANDARD â€” L'Analyste Ã‰quilibrÃ©                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ­ PERSONA : Journaliste d'investigation + Fact-checker + PÃ©dagogue
   Tu cherches la vÃ©ritÃ©. Tu donnes au lecteur les outils pour juger lui-mÃªme.

ğŸ¯ OBJECTIF : SynthÃ¨se complÃ¨te avec Ã‰VALUATION CRITIQUE
   â†’ Couvrir TOUS les points importants
   â†’ Distinguer fait / opinion / hypothÃ¨se
   â†’ RÃ©vÃ©ler ce qui est dit ET ce qui est omis

âœ¨ STYLE "Ã‰LÃ‰GANT & RIGOUREUX" :
   â€¢ Structure claire avec hiÃ©rarchie visuelle
   â€¢ Transitions fluides entre les sections
   â€¢ Citations stratÃ©giques avec timecodes
   â€¢ Tableaux pour les comparaisons

ğŸ§  CADRE BAYÃ‰SIEN EXPLICITE :
   âœ… SOLIDE â€” Evidence forte, consensus large
   âš–ï¸ PLAUSIBLE â€” Arguments cohÃ©rents mais preuves limitÃ©es
   â“ INCERTAIN â€” IntÃ©ressant mais non Ã©tayÃ©
   âš ï¸ DOUTEUX â€” Contredit le consensus, biais Ã©vidents

ğŸ“ STRUCTURE RECOMMANDÃ‰E :
   ## ğŸ¯ SynthÃ¨se Express (30 secondes)
   ## ğŸ“ Analyse DÃ©taillÃ©e (par thÃ¨me, avec crÃ©dibilitÃ©)
   ## ğŸ” Regard Critique (forces, faiblesses, questions)
   ## ğŸ’¡ Ã€ Retenir (takeaways actionnables)
   ## â±ï¸ Index Temporel (moments clÃ©s)
""",
            "expert": """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ”¬ MODE EXPERT â€” L'Analyste BayÃ©sien Exhaustif                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ­ PERSONA : Chercheur senior en Ã©pistÃ©mologie + Critical thinker
   Tu produis des analyses de niveau acadÃ©mique. Rigueur maximale.

ğŸ¯ OBJECTIF : DÃ©corticage EXHAUSTIF avec RIGUEUR Ã‰PISTÃ‰MIQUE
   â†’ AUCUNE idÃ©e, argument ou nuance omis
   â†’ CHAQUE affirmation Ã©valuÃ©e selon cadre bayÃ©sien formel
   â†’ Structure argumentative entiÃ¨rement mise Ã  nu
   â†’ Les NON-DITS sont aussi importants que les dits

ğŸ§  CADRE BAYÃ‰SIEN FORMEL :
   Pour chaque claim significatif :
   â”‚ PRIOR P(H) : ProbabilitÃ© avant cette vidÃ©o
   â”‚ LIKELIHOOD : Ces preuves si hypothÃ¨se vraie ?
   â”‚ POSTERIOR : RÃ©vision de croyance justifiÃ©e
   â”‚ â†‘â†‘ Fort | â†‘ ModÃ©rÃ© | â†’ Neutre | â†“ Contre-indicatif

ğŸ”¬ ANALYSE RHÃ‰TORIQUE & LOGIQUE :
   â€¢ Structure argumentative : prÃ©misses â†’ infÃ©rences â†’ conclusions
   â€¢ Sophismes : ad hominem, homme de paille, pente glissante, faux dilemme
   â€¢ Biais cognitifs : confirmation, ancrage, survivant, Dunning-Kruger

ğŸ“ STRUCTURE OBLIGATOIRE :
   ## ğŸ¯ Executive Summary
   ## ğŸ“Š Cartographie Argumentative
   ## ğŸ”¬ Analyse DÃ©taillÃ©e (avec Ã©valuation bayÃ©sienne)
   ## âš–ï¸ Ã‰valuation Ã‰pistÃ©mique
   ## ğŸ†š Mise en Perspective
   ## â“ Questions Non RÃ©solues
   ## ğŸ“ Index Temporel Complet
"""
        }
    else:
        instructions = {
            "accessible": """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“– ACCESSIBLE MODE â€” The Brilliant Popularizer                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ­ PERSONA: You are a charismatic professor who makes EVERYTHING fascinating.
   You simplify without ever betraying. You inspire without ever lying.

ğŸ¯ OBJECTIVE: A synthesis that people WANT to read and REMEMBER
   â†’ The essentials in 60 seconds of reading
   â†’ "Aha moments" that stick in the mind
   â†’ Zero useless jargon, 100% impact

âœ¨ "SEXY BUT SMART" STYLE:
   â€¢ Punchy hook from the first sentence
   â€¢ Memorable analogies ("It's like...")
   â€¢ Short, punchy sentences (max 20 words)
   â€¢ Strategic emojis for quick scanning

ğŸ“ CLEAN STRUCTURE:
   ğŸ¯ THE ESSENTIALS (2-3 impactful sentences)
   ğŸ“ KEY POINTS (3-5 max, with timecodes)
   ğŸ’¡ THE TAKEAWAY (1 memorable sentence)
""",
            "standard": """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“Š STANDARD MODE â€” The Balanced Analyst                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ­ PERSONA: Investigative journalist + Fact-checker + Educator
   You seek the truth. You give the reader tools to judge for themselves.

ğŸ¯ OBJECTIVE: Complete synthesis with CRITICAL EVALUATION
   â†’ Cover ALL important points
   â†’ Distinguish fact / opinion / hypothesis
   â†’ Reveal what is said AND what is omitted

âœ¨ "ELEGANT & RIGOROUS" STYLE:
   â€¢ Clear structure with visual hierarchy
   â€¢ Smooth transitions between sections
   â€¢ Strategic quotes with timecodes
   â€¢ Tables for comparisons

ğŸ§  EXPLICIT BAYESIAN FRAMEWORK:
   âœ… SOLID â€” Strong evidence, broad consensus
   âš–ï¸ PLAUSIBLE â€” Coherent arguments but limited evidence
   â“ UNCERTAIN â€” Interesting but unsubstantiated
   âš ï¸ DOUBTFUL â€” Contradicts consensus, obvious biases

ğŸ“ RECOMMENDED STRUCTURE:
   ## ğŸ¯ Express Summary (30 seconds)
   ## ğŸ“ Detailed Analysis (by theme, with credibility)
   ## ğŸ” Critical Review (strengths, weaknesses, questions)
   ## ğŸ’¡ Takeaways (actionable)
   ## â±ï¸ Temporal Index (key moments)
""",
            "expert": """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ”¬ EXPERT MODE â€” The Exhaustive Bayesian Analyst                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ­ PERSONA: Senior researcher in epistemology + Critical thinker
   You produce academic-level analyses. Maximum rigor.

ğŸ¯ OBJECTIVE: EXHAUSTIVE deconstruction with EPISTEMIC RIGOR
   â†’ NO idea, argument or nuance omitted
   â†’ EACH claim evaluated according to formal Bayesian framework
   â†’ Argumentative structure entirely laid bare
   â†’ What is NOT SAID is as important as what is said

ğŸ§  FORMAL BAYESIAN FRAMEWORK:
   For each significant claim:
   â”‚ PRIOR P(H): Probability before this video
   â”‚ LIKELIHOOD: This evidence if hypothesis true?
   â”‚ POSTERIOR: Justified belief revision
   â”‚ â†‘â†‘ Strong | â†‘ Moderate | â†’ Neutral | â†“ Counter-indicative

ğŸ”¬ RHETORICAL & LOGICAL ANALYSIS:
   â€¢ Argumentative structure: premises â†’ inferences â†’ conclusions
   â€¢ Fallacies: ad hominem, straw man, slippery slope, false dilemma
   â€¢ Cognitive biases: confirmation, anchoring, survivorship, Dunning-Kruger

ğŸ“ MANDATORY STRUCTURE:
   ## ğŸ¯ Executive Summary
   ## ğŸ“Š Argumentative Mapping
   ## ğŸ”¬ Detailed Analysis (with Bayesian evaluation)
   ## âš–ï¸ Epistemic Evaluation
   ## ğŸ†š Contextualization
   ## â“ Unresolved Questions
   ## ğŸ“ Complete Temporal Index
"""
        }
    
    return instructions.get(mode, instructions["standard"])


def get_category_specific_instructions(category: str, lang: str) -> str:
    """
    ğŸ†• v2.0: Instructions spÃ©cifiques selon le type de contenu.
    Adapte la structure et le focus du rÃ©sumÃ© au type de vidÃ©o.
    """
    if lang == "fr":
        instructions = {
            "interview": """
ğŸ“Œ FOCUS INTERVIEW/PODCAST :
â€¢ Structure Q&R : Identifie les questions clÃ©s et les rÃ©ponses marquantes
â€¢ Profil de l'invitÃ© : Qui est-il ? Quelle expertise apporte-t-il ?
â€¢ Citations impactantes : Extrais 2-3 citations mÃ©morables avec timecodes
â€¢ RÃ©vÃ©lations : Qu'apprend-on de nouveau ou de surprenant ?
â€¢ Points de vue : Distingue les faits des opinions personnelles de l'invitÃ©
â€¢ Dynamique : Note les moments de tension, d'humour ou d'Ã©motion
""",
            "documentary": """
ğŸ“Œ FOCUS DOCUMENTAIRE :
â€¢ Arc narratif : Situation initiale â†’ DÃ©veloppement â†’ Conclusion
â€¢ Protagonistes : Qui sont les acteurs clÃ©s de l'histoire ?
â€¢ Contexte historique/social : Situe les Ã©vÃ©nements
â€¢ Preuves visuelles : Quelles images/documents marquants ?
â€¢ Parti pris : Le documentaire est-il neutre ou orientÃ© ?
â€¢ Impact : Quelles consÃ©quences ou leÃ§ons Ã  retenir ?
""",
            "tutorial": """
ğŸ“Œ FOCUS TUTORIEL :
â€¢ Objectif : Que va-t-on apprendre exactement ?
â€¢ PrÃ©requis : Niveau requis, matÃ©riel nÃ©cessaire
â€¢ Ã‰tapes clÃ©s : Liste numÃ©rotÃ©e des actions principales avec timecodes
â€¢ Astuces : Tips et raccourcis mentionnÃ©s
â€¢ PiÃ¨ges Ã  Ã©viter : Erreurs courantes signalÃ©es
â€¢ RÃ©sultat attendu : Ã€ quoi s'attendre Ã  la fin
""",
            "science": """
ğŸ“Œ FOCUS SCIENCE :
â€¢ HypothÃ¨se/Question : Quel problÃ¨me scientifique est abordÃ© ?
â€¢ MÃ©thodologie : Comment les conclusions sont-elles obtenues ?
â€¢ RÃ©sultats clÃ©s : Chiffres et donnÃ©es importantes
â€¢ Niveau de preuve : Ã‰tude unique, mÃ©ta-analyse, consensus ?
â€¢ Limites : Quelles sont les rÃ©serves ou incertitudes ?
â€¢ Implications : Applications pratiques ou thÃ©oriques
""",
            "news": """
ğŸ“Œ FOCUS ACTUALITÃ‰S (5W1H) :
â€¢ QUI ? Les acteurs principaux
â€¢ QUOI ? L'Ã©vÃ©nement prÃ©cis
â€¢ OÃ™ ? La localisation
â€¢ QUAND ? La chronologie
â€¢ POURQUOI ? Les causes et contexte
â€¢ COMMENT ? Le dÃ©roulement
â€¢ Sources : D'oÃ¹ viennent les informations ?
â€¢ Suivi : Quelles suites possibles ?
""",
            "conference": """
ğŸ“Œ FOCUS CONFÃ‰RENCE :
â€¢ ThÃ¨se centrale : Quel est le message principal ?
â€¢ Arguments : Les 3-5 arguments clÃ©s qui soutiennent la thÃ¨se
â€¢ Preuves : DonnÃ©es, exemples, Ã©tudes citÃ©es
â€¢ Appel Ã  l'action : Que demande le confÃ©rencier ?
â€¢ Public cible : Ã€ qui s'adresse ce message ?
â€¢ CredibilitÃ© : Quelle est l'expertise du confÃ©rencier ?
""",
            "debate": """
ğŸ“Œ FOCUS DÃ‰BAT :
â€¢ Sujet du dÃ©bat : Question centrale posÃ©e
â€¢ Position A : Arguments du premier camp
â€¢ Position B : Arguments du second camp
â€¢ Points d'accord : Y a-t-il des consensus ?
â€¢ Points de friction : OÃ¹ les positions divergent-elles ?
â€¢ Ã‰valuation : Quels arguments sont les plus solides ?
â€¢ Nuance : Existe-t-il une troisiÃ¨me voie ?
""",
            "finance": """
ğŸ“Œ FOCUS FINANCE :
â€¢ OpportunitÃ©/Risque : Quel est le sujet financier abordÃ© ?
â€¢ Analyse : Arguments pour et contre
â€¢ Chiffres clÃ©s : Performances, ratios, projections
â€¢ Horizon temporel : Court terme, moyen terme, long terme ?
â€¢ Profil de risque : Pour quel type d'investisseur ?
â€¢ Avertissement : Distingue conseil gÃ©nÃ©ral vs recommandation personnalisÃ©e
â€¢ Conflits d'intÃ©rÃªts : L'auteur a-t-il des intÃ©rÃªts ?
""",
            "tech": """
ğŸ“Œ FOCUS TECH :
â€¢ Innovation : Quelle est la technologie/produit prÃ©sentÃ© ?
â€¢ Fonctionnement : Comment Ã§a marche (simplifiÃ©) ?
â€¢ Avantages : Quels problÃ¨mes rÃ©sout-elle ?
â€¢ Limites : Quels sont les inconvÃ©nients ou risques ?
â€¢ Comparaison : Par rapport aux alternatives existantes ?
â€¢ DisponibilitÃ© : Quand et pour qui ?
â€¢ Implications sociÃ©tales : Impact potentiel sur la sociÃ©tÃ©
""",
            "health": """
ğŸ“Œ FOCUS SANTÃ‰ :
â€¢ Sujet mÃ©dical : Quelle condition/traitement est abordÃ© ?
â€¢ Niveau de preuve : Ã‰tude, consensus mÃ©dical, tÃ©moignage ?
â€¢ BÃ©nÃ©fices : Quels effets positifs documentÃ©s ?
â€¢ Risques : Effets secondaires ou contre-indications ?
â€¢ Population concernÃ©e : Pour qui est-ce pertinent ?
â€¢ Avertissement : Rappeler de consulter un professionnel de santÃ©
â€¢ Sources : Ã‰tudes ou experts citÃ©s
""",
            "geopolitics": """
ğŸ“Œ FOCUS GÃ‰OPOLITIQUE :
â€¢ Contexte : Situation historique et actuelle
â€¢ Acteurs : Pays, organisations, personnalitÃ©s impliquÃ©es
â€¢ Enjeux : IntÃ©rÃªts en jeu pour chaque partie
â€¢ Dynamiques : Alliances, tensions, rapports de force
â€¢ ScÃ©narios : Ã‰volutions possibles
â€¢ Sources : Origine des informations et fiabilitÃ©
""",
            "culture": """
ğŸ“Œ FOCUS CULTURE :
â€¢ Å’uvre/Artiste : PrÃ©sentation du sujet
â€¢ Contexte de crÃ©ation : Ã‰poque, influences, circonstances
â€¢ Analyse : ThÃ¨mes, techniques, symbolisme
â€¢ RÃ©ception : Critique, public, impact
â€¢ HÃ©ritage : Influence sur la culture
"""
        }
        return instructions.get(category, "")
    else:
        # English versions (simplified)
        return ""


def get_transcript_limit(duration: int, mode: str) -> int:
    """
    ğŸ†• v3.1: Calcule la limite de transcription dynamique selon la durÃ©e et le mode.

    Pour les vidÃ©os longues, on augmente la limite pour capturer l'intÃ©gralitÃ© du contenu.
    """
    # Limites de base par mode
    base_limits = {
        "accessible": 60000,
        "standard": 100000,
        "expert": 150000
    }
    base = base_limits.get(mode, 100000)

    # Augmenter pour les vidÃ©os longues (> 30 min)
    if duration > 1800:  # > 30 min
        multiplier = min(2.0, 1.0 + (duration - 1800) / 7200)  # Max x2 pour 2h+
        base = int(base * multiplier)

    # Augmenter encore pour les vidÃ©os trÃ¨s longues (> 2h)
    if duration > 7200:  # > 2h
        multiplier = min(1.5, 1.0 + (duration - 7200) / 14400)  # Max x1.5 supplÃ©mentaire
        base = int(base * multiplier)

    # Limite maximale absolue: 300k chars (environ 60-75k mots)
    return min(base, 300000)


def build_analysis_prompt(
    title: str,
    transcript: str,
    category: str,
    lang: str,
    mode: str,
    duration: int = 0,
    channel: str = "",
    description: str = ""
) -> Tuple[str, str]:
    """
    Construit le prompt systÃ¨me et utilisateur pour l'analyse.
    ğŸ†• v3.1: Limite de transcription dynamique pour vidÃ©os longues.
    Retourne: (system_prompt, user_prompt)
    """
    epistemic_rules = EPISTEMIC_RULES_FR if lang == "fr" else EPISTEMIC_RULES_EN
    mode_instructions = get_mode_instructions(mode, lang)
    category_instructions = get_category_specific_instructions(category, lang)

    # ğŸ†• v3.1: Limite dynamique de transcription
    transcript_limit = get_transcript_limit(duration, mode)

    # DÃ©terminer la longueur cible
    cat_info = CATEGORIES.get(category, CATEGORIES["general"])
    min_words, max_words = cat_info["min_words"], cat_info["max_words"]

    # Ajustements selon le mode
    if mode == "accessible":
        min_words, max_words = int(min_words * 0.7), int(max_words * 0.75)
    elif mode == "expert":
        min_words, max_words = int(min_words * 1.8), int(max_words * 2.0)
    
    # Ajustements selon la durÃ©e
    if duration > 3600:
        min_words, max_words = int(min_words * 1.3), int(max_words * 1.3)
    if duration > 7200:
        min_words, max_words = int(min_words * 1.5), int(max_words * 1.5)
    
    if lang == "fr":
        system_prompt = f"""Tu es Deep Sight, expert en analyse critique et synthÃ¨se de contenu vidÃ©o.

ğŸŒ IMPÃ‰RATIF LINGUISTIQUE: Tu DOIS rÃ©pondre UNIQUEMENT en franÃ§ais impeccable.
â€¢ Utilise un franÃ§ais acadÃ©mique, Ã©lÃ©gant et bien structurÃ©
â€¢ Ã‰vite les anglicismes (prÃ©fÃ¨re "apprentissage automatique" Ã  "machine learning")
â€¢ Formule des phrases professionnelles et fluides
â€¢ Les citations de la vidÃ©o peuvent rester en langue originale si pertinent

{epistemic_rules}

{mode_instructions}

{category_instructions}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â±ï¸ TIMECODES CLIQUABLES â€” MINIMUM 3-5 DANS CHAQUE RÃ‰SUMÃ‰ !
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ Tu DOIS inclure 3 Ã  5 timecodes [MM:SS] avec CROCHETS dans ta synthÃ¨se !
âœ… FORMAT STRICT : Utilise [MM:SS] avec des CROCHETS (pas de parenthÃ¨ses)
âœ… EXEMPLES : "L'idÃ©e clÃ© arrive Ã  [4:32]" ou "Il explique [7:15] que..."
âœ… Pour les longues vidÃ©os : "La partie sur X [12:45] puis Y [25:30]"
âŒ INTERDIT : "[XX:XX]" inventÃ©, format (MM:SS) avec parenthÃ¨ses

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“š CONCEPTS WIKIPEDIA CLIQUABLES â€” OBLIGATOIRE !
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ RÃˆGLE ABSOLUE : Tu DOIS entourer 5-10 termes importants avec [[double crochets]].
C'est une fonctionnalitÃ© ESSENTIELLE de Deep Sight. Sans [[concepts]], la rÃ©ponse est incomplÃ¨te.

âœ… TERMES Ã€ MARQUER OBLIGATOIREMENT :
â€¢ Noms de personnes : [[Peter Thiel]], [[Elon Musk]], [[Albert Einstein]]
â€¢ Entreprises/Organisations : [[Palantir]], [[Silicon Valley]], [[CIA]], [[ARTE]]
â€¢ Concepts techniques : [[intelligence artificielle]], [[Big Data]], [[algorithme]]
â€¢ Termes spÃ©cifiques : [[surveillance de masse]], [[capitalisme]], [[gÃ©opolitique]]

âœ… EXEMPLES DE PHRASES CORRECTES :
â€¢ "[[Palantir]], fondÃ©e par [[Peter Thiel]], collabore avec la [[CIA]]..."
â€¢ "Le documentaire explore les enjeux de la [[surveillance de masse]]..."
â€¢ "Cette approche utilise l'[[apprentissage automatique]] et le [[Big Data]]..."

âŒ NE PAS MARQUER : les mots courants (vidÃ©o, personne, chose, fait, temps)

ğŸ“Š QUANTITÃ‰ MINIMALE : 5 concepts [[marquÃ©s]] par synthÃ¨se. Maximum 10.

ğŸ“Š LONGUEUR CIBLE : {min_words}-{max_words} mots

ğŸŒ RÃ‰PONDS ENTIÃˆREMENT EN FRANÃ‡AIS IMPECCABLE.
"""
        
        user_prompt = f"""Analyse cette vidÃ©o YouTube :

ğŸ“º TITRE : {title}
ğŸ“º CHAÃNE : {channel}
â±ï¸ DURÃ‰E : {duration // 60} minutes
ğŸ“ CATÃ‰GORIE : {category}

ğŸ“ TRANSCRIPTION :
{transcript[:transcript_limit]}

GÃ©nÃ¨re une synthÃ¨se {mode} complÃ¨te avec timecodes."""

    else:
        system_prompt = f"""You are Deep Sight, expert in critical analysis and video content synthesis.

{epistemic_rules}

{mode_instructions}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MANDATORY CLICKABLE TIMECODES â€” MINIMUM 3-5 IN EACH SUMMARY!
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Include exact timecodes from transcript in format [MM:SS] with SQUARE BRACKETS.
Example: "The key idea appears at [4:32]" or "He explains at [7:15] that..."

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“š WIKIPEDIA CONCEPTS â€” MANDATORY!
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ ABSOLUTE RULE: You MUST wrap 5-10 important terms with [[double brackets]].
This is an ESSENTIAL feature of Deep Sight. Without [[concepts]], the response is incomplete.

âœ… TERMS TO MARK (REQUIRED):
â€¢ People names: [[Peter Thiel]], [[Elon Musk]], [[Albert Einstein]]
â€¢ Companies/Organizations: [[Palantir]], [[Silicon Valley]], [[CIA]], [[NASA]]
â€¢ Technical concepts: [[artificial intelligence]], [[Big Data]], [[algorithm]]
â€¢ Specific terms: [[mass surveillance]], [[capitalism]], [[geopolitics]]

âœ… CORRECT SENTENCE EXAMPLES:
â€¢ "[[Palantir]], founded by [[Peter Thiel]], collaborates with the [[CIA]]..."
â€¢ "The documentary explores [[mass surveillance]] issues..."
â€¢ "This approach uses [[machine learning]] and [[Big Data]]..."

âŒ DO NOT MARK: common words (video, person, thing, fact, time)

ğŸ“Š MINIMUM QUANTITY: 5 [[marked]] concepts per summary. Maximum 10.

TARGET LENGTH: {min_words}-{max_words} words

RESPOND ENTIRELY IN ENGLISH.
"""
        
        user_prompt = f"""Analyze this YouTube video:

ğŸ“º TITLE: {title}
ğŸ“º CHANNEL: {channel}
â±ï¸ DURATION: {duration // 60} minutes
ğŸ“ CATEGORY: {category}

ğŸ“ TRANSCRIPT:
{transcript[:transcript_limit]}

Generate a complete {mode} synthesis with timecodes."""

    return system_prompt, user_prompt


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¤– APPELS API MISTRAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def generate_summary(
    title: str,
    transcript: str,
    category: str,
    lang: str,
    mode: str,
    model: str = "mistral-small-latest",
    duration: int = 0,
    channel: str = "",
    description: str = "",
    api_key: str = None,
    web_context: str = None  # ğŸ†• v3.0: Contexte web prÃ©-analyse
) -> Optional[str]:
    """
    GÃ©nÃ¨re un rÃ©sumÃ© avec Mistral AI.
    
    ğŸ†• v3.0: Peut recevoir un web_context (de Perplexity) Ã  intÃ©grer dans l'analyse.
    """
    api_key = api_key or get_mistral_key()
    if not api_key:
        print("âŒ Mistral API key not configured", flush=True)
        return None
    
    print(f"ğŸ§  Generating summary with {model}...", flush=True)
    print(f"   Title: {title[:60]}...", flush=True)
    print(f"   Category: {category}, Mode: {mode}, Lang: {lang}", flush=True)
    if web_context:
        print(f"   ğŸ“¡ Web context provided: {len(web_context)} chars", flush=True)
    
    system_prompt, user_prompt = build_analysis_prompt(
        title=title,
        transcript=transcript,
        category=category,
        lang=lang,
        mode=mode,
        duration=duration,
        channel=channel,
        description=description
    )
    
    # ğŸ†• v3.0: Injecter le contexte web dans le prompt utilisateur
    if web_context:
        web_context_formatted = f"""

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“¡ CONTEXTE WEB ACTUEL (Recherche Perplexity - {datetime.now().strftime('%Y-%m-%d')})
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{web_context}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ INSTRUCTION IMPORTANTE: 
   - Utilise ce contexte web pour ENRICHIR ton analyse
   - Compare les informations de la vidÃ©o avec les donnÃ©es actuelles
   - Signale explicitement les informations qui ont pu Ã‰VOLUER depuis la vidÃ©o
   - Ajoute une section "ğŸ“¡ Mise Ã  jour" si des infos ont changÃ©
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        user_prompt = user_prompt + web_context_formatted
    
    # ğŸ†• v3.1: Tokens dynamiques selon mode ET durÃ©e de la vidÃ©o
    base_tokens = {
        "accessible": 2500,
        "standard": 5000,
        "expert": 10000
    }.get(mode, 5000)

    # Augmenter les tokens pour les vidÃ©os longues
    if duration > 1800:  # > 30 min
        duration_multiplier = min(2.0, 1.0 + (duration - 1800) / 7200)
        base_tokens = int(base_tokens * duration_multiplier)

    # VidÃ©os trÃ¨s longues (> 2h) â†’ encore plus de tokens
    if duration > 7200:
        base_tokens = int(base_tokens * 1.3)

    # Limites maximales par mode
    max_token_limits = {
        "accessible": 4000,
        "standard": 12000,
        "expert": 20000
    }
    max_tokens = min(base_tokens, max_token_limits.get(mode, 12000))

    # Augmenter si contexte web (plus de contenu Ã  analyser)
    if web_context:
        max_tokens = int(max_tokens * 1.2)  # +20%
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.mistral.ai/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": model,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    "max_tokens": max_tokens,
                    "temperature": 0.3
                },
                timeout=180  # 3 minutes pour les longues analyses
            )
            
            if response.status_code == 200:
                data = response.json()
                summary = data["choices"][0]["message"]["content"].strip()
                word_count = len(summary.split())
                print(f"âœ… Summary generated: {word_count} words", flush=True)
                return summary
            else:
                print(f"âŒ Mistral API error: {response.status_code}", flush=True)
                print(f"   Response: {response.text}", flush=True)
                return None
                
    except Exception as e:
        print(f"âŒ Summary generation error: {e}", flush=True)
        return None


async def extract_entities(
    summary: str,
    api_key: str = None,
    lang: str = "fr"
) -> Optional[Dict[str, List[str]]]:
    """
    Extrait les entitÃ©s (personnes, concepts, organisations) d'un rÃ©sumÃ©.
    """
    api_key = api_key or get_mistral_key()
    if not api_key or not summary:
        return None
    
    prompt = """Analyse ce rÃ©sumÃ© et extrait les entitÃ©s principales en JSON.
Format STRICT (JSON uniquement, sans markdown):
{
    "concepts": ["concept1", "concept2"],
    "persons": ["personne1", "personne2"],
    "organizations": ["org1", "org2"],
    "products": ["produit1", "produit2"]
}

RÃ©sumÃ©:
""" if lang == "fr" else """Analyze this summary and extract main entities as JSON.
STRICT format (JSON only, no markdown):
{
    "concepts": ["concept1", "concept2"],
    "persons": ["person1", "person2"],
    "organizations": ["org1", "org2"],
    "products": ["product1", "product2"]
}

Summary:
"""
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.mistral.ai/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "mistral-small-latest",
                    "messages": [{"role": "user", "content": f"{prompt}\n\n{summary[:3000]}"}],
                    "temperature": 0.1,
                    "max_tokens": 500
                },
                timeout=30
            )
            
            if response.status_code == 200:
                content = response.json()["choices"][0]["message"]["content"]
                # Nettoyer le JSON
                content = content.strip()
                if content.startswith("```"):
                    content = content.split("```")[1]
                    if content.startswith("json"):
                        content = content[4:]
                content = content.strip()
                
                return json.loads(content)
    except Exception as e:
        print(f"âš ï¸ Entity extraction error: {e}", flush=True)
    
    return None


async def calculate_reliability_score(
    summary: str,
    entities: Optional[Dict] = None,
    api_key: str = None,
    lang: str = "fr"
) -> float:
    """
    Calcule un score de fiabilitÃ© basÃ© sur les marqueurs Ã©pistÃ©miques.
    Score de 0 Ã  100.
    """
    if not summary:
        return 50.0
    
    # Analyse simple basÃ©e sur les marqueurs
    text = summary.lower()
    
    # Marqueurs positifs (augmentent la fiabilitÃ©)
    positive_markers = [
        "Ã©tude", "recherche", "donnÃ©es", "preuve", "dÃ©montrÃ©",
        "study", "research", "data", "evidence", "demonstrated",
        "selon", "d'aprÃ¨s", "according to", "âœ…"
    ]
    
    # Marqueurs nÃ©gatifs (diminuent la fiabilitÃ©)
    negative_markers = [
        "opinion", "je pense", "hypothÃ¨se", "spÃ©culation",
        "pourrait", "peut-Ãªtre", "possibly", "might",
        "âš ï¸", "â“", "non vÃ©rifiÃ©", "unverified"
    ]
    
    # Calculer le score
    positive_count = sum(1 for m in positive_markers if m in text)
    negative_count = sum(1 for m in negative_markers if m in text)
    
    # Score de base Ã  60
    score = 60.0
    score += positive_count * 3  # +3 par marqueur positif
    score -= negative_count * 5  # -5 par marqueur nÃ©gatif
    
    # Bonus si des sources sont citÃ©es
    if entities and entities.get("persons"):
        score += min(10, len(entities["persons"]) * 2)
    
    # Limiter entre 20 et 95
    return max(20.0, min(95.0, score))
