"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“š LONG VIDEO ANALYZER v2.0 â€” TRAITEMENT INTÃ‰GRAL GARANTI                         â•‘
â•‘  Analyse COMPLÃˆTE des vidÃ©os longues (2h+) par chunking exhaustif                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ğŸ¯ GARANTIE: 100% du transcript est analysÃ©, AUCUNE partie ignorÃ©e                â•‘
â•‘                                                                                    â•‘
â•‘  STRATÃ‰GIE:                                                                        â•‘
â•‘  1. Diviser le transcript en chunks SANS PERTE                                     â•‘
â•‘  2. Analyser TOUS les chunks (avec retry si Ã©chec)                                 â•‘
â•‘  3. Fusionner TOUTES les analyses en synthÃ¨se finale                               â•‘
â•‘  4. VÃ©rifier la couverture Ã  100%                                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import re
import asyncio
import httpx
from typing import List, Tuple, Optional, Dict, Any
from dataclasses import dataclass, field
from datetime import datetime

from core.config import get_mistral_key

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ CONFIGURATION â€” OPTIMISÃ‰E POUR TRAITEMENT COMPLET (mÃªme 3h+)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Seuils pour dÃ©clencher le chunking
LONG_VIDEO_THRESHOLD_WORDS = 5000       # ~20 min de vidÃ©o
VERY_LONG_VIDEO_THRESHOLD_WORDS = 15000 # ~1h de vidÃ©o
ULTRA_LONG_VIDEO_THRESHOLD_WORDS = 45000 # ~3h de vidÃ©o (NOUVEAU)

# Taille des chunks â€” OPTIMISÃ‰E pour garantir un traitement complet
CHUNK_SIZE_WORDS = 2500                 # 2500 mots max par chunk (plus petit = plus sÃ»r)
CHUNK_OVERLAP_WORDS = 300               # Chevauchement augmentÃ© pour meilleur contexte

# Retry et robustesse
MAX_RETRIES_PER_CHUNK = 4               # 4 tentatives par chunk (augmentÃ©)
RETRY_DELAY_SECONDS = 3                 # DÃ©lai entre les tentatives

# Concurrence - rÃ©duite pour Ã©viter rate limiting sur vidÃ©os trÃ¨s longues
MAX_CONCURRENT_CHUNKS = 2               # 2 chunks simultanÃ©s max
CHUNK_TIMEOUT_SECONDS = 180             # Timeout augmentÃ© Ã  3 min par chunk

# ğŸ†• GARANTIE 100% - PAS DE LIMITE sur le nombre de chunks
MAX_CHUNKS = None                       # IllimitÃ© - on traite TOUT le transcript

# ğŸ†• Pour le stockage du transcript complet pour le chat IA
STORE_FULL_TRANSCRIPT = True            # Stocker le transcript complet
MAX_TRANSCRIPT_STORAGE_CHARS = 500000   # 500k caractÃ¨res max en BDD (~3h de vidÃ©o)


@dataclass
class TranscriptChunk:
    """ReprÃ©sente un morceau de transcript"""
    index: int
    total_chunks: int
    text: str
    word_count: int
    start_time: Optional[str] = None
    end_time: Optional[str] = None
    start_word_index: int = 0
    end_word_index: int = 0
    
    # Tracking du traitement
    processed: bool = False
    retry_count: int = 0
    error: Optional[str] = None


@dataclass
class ChunkAnalysis:
    """RÃ©sultat d'analyse d'un chunk"""
    chunk_index: int
    summary: str
    key_points: List[str] = field(default_factory=list)
    important_quotes: List[str] = field(default_factory=list)
    topics: List[str] = field(default_factory=list)
    time_range: str = ""
    word_count_analyzed: int = 0  # Pour vÃ©rifier la couverture


@dataclass
class AnalysisReport:
    """Rapport de l'analyse complÃ¨te"""
    total_words: int
    total_chunks: int
    chunks_analyzed: int
    chunks_failed: int
    coverage_percent: float
    failed_chunks: List[int] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“ DÃ‰TECTION ET DÃ‰COUPAGE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def needs_chunking(transcript: str) -> Tuple[bool, int, str]:
    """
    DÃ©termine si un transcript nÃ©cessite un dÃ©coupage.
    
    Returns:
        (needs_chunking, word_count, reason)
    """
    words = transcript.split()
    word_count = len(words)
    
    if word_count > VERY_LONG_VIDEO_THRESHOLD_WORDS:
        return True, word_count, f"very_long ({word_count} mots â‰ˆ {word_count // 150} min)"
    elif word_count > LONG_VIDEO_THRESHOLD_WORDS:
        return True, word_count, f"long ({word_count} mots â‰ˆ {word_count // 150} min)"
    else:
        return False, word_count, "standard"


def estimate_timecode(word_index: int, total_words: int, video_duration: int) -> str:
    """
    Estime le timecode basÃ© sur la position dans le transcript.
    âš ï¸ FALLBACK: UtilisÃ© seulement si pas de vrais timestamps disponibles.
    
    Args:
        word_index: Index du mot dans le transcript
        total_words: Nombre total de mots
        video_duration: DurÃ©e de la vidÃ©o en secondes
    
    Returns:
        Timecode au format HH:MM:SS ou MM:SS
    """
    if total_words == 0:
        return "00:00"
    
    seconds = int((word_index / total_words) * video_duration)
    
    hours = seconds // 3600
    minutes = (seconds % 3600) // 60
    secs = seconds % 60
    
    if hours > 0:
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"
    else:
        return f"{minutes:02d}:{secs:02d}"


def parse_real_timestamps(transcript_timestamped: str) -> List[Tuple[int, str]]:
    """
    ğŸ†• v3.0: Parse les VRAIS timestamps du transcript YouTube.
    
    Le format attendu est: "[00:30] texte [01:00] suite..."
    
    Returns:
        Liste de tuples (seconds, text) avec les vrais timestamps
    """
    if not transcript_timestamped:
        return []
    
    segments = []
    # Pattern pour capturer [HH:MM:SS] ou [MM:SS] suivi du texte
    pattern = r'\[(\d{1,2}):(\d{2})(?::(\d{2}))?\]\s*([^\[]*)'
    
    matches = re.findall(pattern, transcript_timestamped)
    
    for match in matches:
        if match[2]:  # Format HH:MM:SS
            hours, minutes, seconds = int(match[0]), int(match[1]), int(match[2])
            total_seconds = hours * 3600 + minutes * 60 + seconds
        else:  # Format MM:SS
            minutes, seconds = int(match[0]), int(match[1])
            total_seconds = minutes * 60 + seconds
        
        text = match[3].strip()
        if text:
            segments.append((total_seconds, text))
    
    return segments


def get_timestamp_at_word_index(
    transcript_timestamped: str, 
    word_index: int,
    total_words: int,
    video_duration: int
) -> str:
    """
    ğŸ†• v3.0: Obtient le VRAI timestamp Ã  une position donnÃ©e.
    
    1. Parse les vrais timestamps
    2. Trouve le segment correspondant Ã  word_index
    3. Fallback sur estimation si pas de vrais timestamps
    """
    segments = parse_real_timestamps(transcript_timestamped)
    
    if not segments:
        # Fallback: estimation
        return estimate_timecode(word_index, total_words, video_duration)
    
    # Calculer la position relative (0 Ã  1)
    position_ratio = word_index / max(total_words, 1)
    
    # Trouver le segment correspondant
    # On suppose une distribution uniforme des mots dans le temps
    target_time = position_ratio * video_duration
    
    # Trouver le segment le plus proche
    best_segment = segments[0]
    for seg_time, seg_text in segments:
        if seg_time <= target_time:
            best_segment = (seg_time, seg_text)
        else:
            break
    
    # Formater le timestamp
    seconds = best_segment[0]
    hours = seconds // 3600
    minutes = (seconds % 3600) // 60
    secs = seconds % 60
    
    if hours > 0:
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"
    else:
        return f"{minutes:02d}:{secs:02d}"


def split_into_chunks_with_real_timestamps(
    transcript: str,
    transcript_timestamped: str,
    video_duration: int = 0,
    chunk_size: int = CHUNK_SIZE_WORDS,
    overlap: int = CHUNK_OVERLAP_WORDS
) -> List[TranscriptChunk]:
    """
    ğŸ†• v3.0: Divise le transcript en chunks avec VRAIS timestamps YouTube.
    
    AmÃ©lioration majeure:
    - Parse les timestamps rÃ©els du transcript_timestamped
    - Assigne les vrais timecodes Ã  chaque chunk
    - Fallback sur estimation si pas de timestamps
    """
    # Parser les vrais timestamps
    real_segments = parse_real_timestamps(transcript_timestamped)
    has_real_timestamps = len(real_segments) > 0
    
    if has_real_timestamps:
        print(f"âœ… [TIMESTAMPS] Found {len(real_segments)} real timestamps", flush=True)
    else:
        print(f"âš ï¸ [TIMESTAMPS] No real timestamps, using estimation", flush=True)
    
    words = transcript.split()
    total_words = len(words)
    
    if total_words <= chunk_size:
        end_time = "00:00"
        if has_real_timestamps and real_segments:
            last_seg = real_segments[-1]
            seconds = last_seg[0]
            hours = seconds // 3600
            minutes = (seconds % 3600) // 60
            secs = seconds % 60
            end_time = f"{hours:02d}:{minutes:02d}:{secs:02d}" if hours > 0 else f"{minutes:02d}:{secs:02d}"
        else:
            end_time = estimate_timecode(total_words, total_words, video_duration)
            
        return [TranscriptChunk(
            index=0,
            total_chunks=1,
            text=transcript,
            word_count=total_words,
            start_time="00:00",
            end_time=end_time,
            start_word_index=0,
            end_word_index=total_words
        )]
    
    chunks = []
    current_pos = 0
    chunk_index = 0
    
    # Estimer le nombre total de chunks
    estimated_chunks = max(1, (total_words - overlap) // (chunk_size - overlap))
    
    while current_pos < total_words:
        # Calculer la fin du chunk
        end_pos = min(current_pos + chunk_size, total_words)
        
        # Ajuster pour finir sur une phrase (chercher un point)
        if end_pos < total_words:
            search_start = max(current_pos + chunk_size - 200, current_pos)
            search_text = " ".join(words[search_start:end_pos])
            
            last_period = search_text.rfind('.')
            if last_period == -1:
                last_period = search_text.rfind('!')
            if last_period == -1:
                last_period = search_text.rfind('?')
            
            if last_period > 0:
                words_before_period = len(search_text[:last_period].split())
                end_pos = search_start + words_before_period + 1
        
        # CrÃ©er le chunk
        chunk_text = " ".join(words[current_pos:end_pos])
        
        # ğŸ†• Obtenir les VRAIS timestamps
        if has_real_timestamps:
            start_time = get_timestamp_at_word_index(
                transcript_timestamped, current_pos, total_words, video_duration
            )
            end_time = get_timestamp_at_word_index(
                transcript_timestamped, end_pos, total_words, video_duration
            )
        else:
            start_time = estimate_timecode(current_pos, total_words, video_duration)
            end_time = estimate_timecode(end_pos, total_words, video_duration)
        
        chunks.append(TranscriptChunk(
            index=chunk_index,
            total_chunks=estimated_chunks,
            text=chunk_text,
            word_count=end_pos - current_pos,
            start_time=start_time,
            end_time=end_time,
            start_word_index=current_pos,
            end_word_index=end_pos
        ))
        
        # Avancer avec chevauchement
        current_pos = end_pos - overlap if end_pos < total_words else total_words
        chunk_index += 1
    
    # Mettre Ã  jour le total de chunks
    for chunk in chunks:
        chunk.total_chunks = len(chunks)
    
    return chunks


# Garder l'ancienne fonction pour compatibilitÃ©
def split_into_chunks(
    transcript: str,
    video_duration: int = 0,
    chunk_size: int = CHUNK_SIZE_WORDS,
    overlap: int = CHUNK_OVERLAP_WORDS
) -> List[TranscriptChunk]:
    """
    âš ï¸ LEGACY: Utiliser split_into_chunks_with_real_timestamps de prÃ©fÃ©rence.
    Divise un transcript en chunks intelligents (timestamps estimÃ©s).
    """
    return split_into_chunks_with_real_timestamps(
        transcript=transcript,
        transcript_timestamped="",  # Pas de vrais timestamps
        video_duration=video_duration,
        chunk_size=chunk_size,
        overlap=overlap
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§  ANALYSE PAR CHUNKS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def analyze_chunk_with_retry(
    chunk: TranscriptChunk,
    video_title: str,
    category: str,
    lang: str,
    mode: str,
    model: str = "mistral-small-latest",
    api_key: str = None,
    max_retries: int = MAX_RETRIES_PER_CHUNK
) -> Optional[ChunkAnalysis]:
    """
    ğŸ”„ Analyse un chunk avec retry automatique en cas d'Ã©chec.
    
    GARANTIE: Tente jusqu'Ã  max_retries fois avant d'abandonner.
    """
    api_key = api_key or get_mistral_key()
    if not api_key:
        print(f"âŒ [Chunk {chunk.index}] No API key!", flush=True)
        return None
    
    last_error = None
    
    for attempt in range(max_retries):
        try:
            result = await _analyze_chunk_internal(
                chunk=chunk,
                video_title=video_title,
                category=category,
                lang=lang,
                mode=mode,
                model=model,
                api_key=api_key
            )
            
            if result:
                result.word_count_analyzed = chunk.word_count
                chunk.processed = True
                if attempt > 0:
                    print(f"âœ… [Chunk {chunk.index}] Succeeded on attempt {attempt + 1}", flush=True)
                return result
            else:
                last_error = "Empty result"
                
        except Exception as e:
            last_error = str(e)
            chunk.retry_count = attempt + 1
            print(f"âš ï¸ [Chunk {chunk.index}] Attempt {attempt + 1}/{max_retries} failed: {e}", flush=True)
        
        # Attendre avant de rÃ©essayer
        if attempt < max_retries - 1:
            await asyncio.sleep(RETRY_DELAY_SECONDS * (attempt + 1))  # Backoff progressif
    
    # Ã‰chec aprÃ¨s toutes les tentatives
    chunk.error = last_error
    print(f"âŒ [Chunk {chunk.index}] FAILED after {max_retries} attempts: {last_error}", flush=True)
    return None


async def _analyze_chunk_internal(
    chunk: TranscriptChunk,
    video_title: str,
    category: str,
    lang: str,
    mode: str,
    model: str,
    api_key: str
) -> Optional[ChunkAnalysis]:
    """
    Analyse interne d'un chunk (appelÃ©e par analyze_chunk_with_retry).
    """
    # Adapter le prompt selon la position
    position_context = ""
    if chunk.index == 0:
        position_context = "C'est le DÃ‰BUT de la vidÃ©o. Identifie le contexte, les intervenants, et le sujet principal."
    elif chunk.index == chunk.total_chunks - 1:
        position_context = "C'est la FIN de la vidÃ©o. Note les conclusions, recommandations, et points finaux."
    else:
        position_context = f"C'est la PARTIE {chunk.index + 1}/{chunk.total_chunks} de la vidÃ©o (milieu). Identifie les arguments et dÃ©veloppements."
    
    system_prompt = f"""Tu es un analyste expert qui rÃ©sume des segments de vidÃ©os longues.

CONTEXTE:
- VidÃ©o: "{video_title}"
- CatÃ©gorie: {category}
- Segment: {chunk.index + 1}/{chunk.total_chunks} ({chunk.start_time} â†’ {chunk.end_time})
- Mots dans ce segment: {chunk.word_count}
- {position_context}

ğŸ¯ MISSION CRITIQUE: Tu dois analyser TOUT le contenu de ce segment sans rien omettre.

TÃ‚CHE:
Analyse ce segment INTÃ‰GRALEMENT et extrais:
1. Un RÃ‰SUMÃ‰ COMPLET de cette partie (300-500 mots) - couvre TOUS les points importants
2. Les 5-8 POINTS CLÃ‰S avec des timecodes VARIÃ‰S entre {chunk.start_time} et {chunk.end_time}
   âš ï¸ IMPORTANT: RÃ©partis les timecodes dans TOUTE la plage [{chunk.start_time} - {chunk.end_time}], pas seulement au dÃ©but!
3. 2-3 CITATIONS IMPORTANTES (si pertinentes)
4. TOUS les THÃˆMES/SUJETS abordÃ©s dans ce segment

FORMAT DE RÃ‰PONSE (JSON):
{{
    "summary": "RÃ©sumÃ© COMPLET du segment...",
    "key_points": [
        "[{chunk.start_time}] Premier point (dÃ©but du segment)",
        "[...] Points suivants avec timecodes croissants",
        "[proche de {chunk.end_time}] Dernier point (fin du segment)"
    ],
    "quotes": ["Citation importante 1", "Citation 2"],
    "topics": ["ThÃ¨me 1", "ThÃ¨me 2", "ThÃ¨me 3"]
}}
"""

    user_prompt = f"""TRANSCRIPT SEGMENT [{chunk.start_time} - {chunk.end_time}] ({chunk.word_count} mots):

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{chunk.text}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Analyse ce segment INTÃ‰GRALEMENT en {"franÃ§ais" if lang == "fr" else "anglais"}.
N'omets aucun point important mentionnÃ© dans ce segment."""

    async with httpx.AsyncClient() as client:
        response = await client.post(
            "https://api.mistral.ai/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            },
            json={
                "model": model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "max_tokens": 2000,  # AugmentÃ© pour des rÃ©sumÃ©s plus complets
                "temperature": 0.3,
                "response_format": {"type": "json_object"}
            },
            timeout=CHUNK_TIMEOUT_SECONDS
        )
        
        if response.status_code == 200:
            data = response.json()
            content = data["choices"][0]["message"]["content"]
            
            # Parser le JSON
            import json
            try:
                parsed = json.loads(content)
                return ChunkAnalysis(
                    chunk_index=chunk.index,
                    summary=parsed.get("summary", ""),
                    key_points=parsed.get("key_points", []),
                    important_quotes=parsed.get("quotes", []),
                    topics=parsed.get("topics", []),
                    time_range=f"{chunk.start_time} - {chunk.end_time}",
                    word_count_analyzed=chunk.word_count
                )
            except json.JSONDecodeError:
                # Si pas de JSON valide, utiliser le texte brut
                return ChunkAnalysis(
                    chunk_index=chunk.index,
                    summary=content,
                    key_points=[],
                    important_quotes=[],
                    topics=[],
                    time_range=f"{chunk.start_time} - {chunk.end_time}",
                    word_count_analyzed=chunk.word_count
                )
        else:
            raise Exception(f"API error {response.status_code}: {response.text[:200]}")


# Garder l'ancienne fonction pour compatibilitÃ©
async def analyze_chunk(
    chunk: TranscriptChunk,
    video_title: str,
    category: str,
    lang: str,
    mode: str,
    model: str = "mistral-small-latest",
    api_key: str = None
) -> Optional[ChunkAnalysis]:
    """Wrapper pour compatibilitÃ© - utilise la version avec retry."""
    return await analyze_chunk_with_retry(
        chunk=chunk,
        video_title=video_title,
        category=category,
        lang=lang,
        mode=mode,
        model=model,
        api_key=api_key
    )


async def analyze_chunks_parallel(
    chunks: List[TranscriptChunk],
    video_title: str,
    category: str,
    lang: str,
    mode: str,
    model: str = "mistral-small-latest",
    max_concurrent: int = MAX_CONCURRENT_CHUNKS,
    progress_callback = None
) -> Tuple[List[ChunkAnalysis], AnalysisReport]:
    """
    ğŸ¯ Analyse TOUS les chunks en parallÃ¨le avec GARANTIE de traitement complet.
    
    Returns:
        Tuple[analyses, report] - Liste des analyses ET rapport de couverture
    """
    total_chunks = len(chunks)
    total_words = sum(c.word_count for c in chunks)
    
    print(f"ğŸ“š [FULL ANALYSIS] Starting analysis of {total_chunks} chunks ({total_words} words total)", flush=True)
    
    results: List[Optional[ChunkAnalysis]] = [None] * total_chunks
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def analyze_with_semaphore(chunk: TranscriptChunk, index: int):
        async with semaphore:
            if progress_callback:
                # Progress de 40% Ã  75% pendant l'analyse des chunks
                progress = 40 + int((index / total_chunks) * 35)
                progress_callback(progress, f"ğŸ“ Analyse partie {index + 1}/{total_chunks} ({chunk.word_count} mots)...")
            
            print(f"ğŸ” [Chunk {index + 1}/{total_chunks}] Analyzing {chunk.word_count} words ({chunk.start_time} â†’ {chunk.end_time})...", flush=True)
            
            result = await analyze_chunk_with_retry(
                chunk=chunk,
                video_title=video_title,
                category=category,
                lang=lang,
                mode=mode,
                model=model
            )
            
            if result:
                print(f"âœ… [Chunk {index + 1}/{total_chunks}] Done - {len(result.summary)} chars summary", flush=True)
            else:
                print(f"âŒ [Chunk {index + 1}/{total_chunks}] FAILED after all retries", flush=True)
            
            return index, result
    
    # Phase 1: Analyse initiale de TOUS les chunks
    print(f"ğŸš€ [FULL ANALYSIS] Phase 1: Initial analysis of all {total_chunks} chunks...", flush=True)
    
    tasks = [analyze_with_semaphore(chunk, i) for i, chunk in enumerate(chunks)]
    task_results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Collecter les rÃ©sultats
    failed_indices = []
    for result in task_results:
        if isinstance(result, Exception):
            print(f"âš ï¸ Task exception: {result}", flush=True)
            continue
        if isinstance(result, tuple):
            index, analysis = result
            results[index] = analysis
            if analysis is None:
                failed_indices.append(index)
    
    # Phase 2: Retry des chunks qui ont Ã©chouÃ©
    if failed_indices:
        print(f"ğŸ”„ [FULL ANALYSIS] Phase 2: Retrying {len(failed_indices)} failed chunks...", flush=True)
        
        if progress_callback:
            progress_callback(76, f"ğŸ”„ Nouvel essai pour {len(failed_indices)} parties...")
        
        for failed_index in failed_indices:
            chunk = chunks[failed_index]
            print(f"ğŸ”„ [Retry] Chunk {failed_index + 1}/{total_chunks}...", flush=True)
            
            # Attendre un peu avant de rÃ©essayer
            await asyncio.sleep(3)
            
            result = await analyze_chunk_with_retry(
                chunk=chunk,
                video_title=video_title,
                category=category,
                lang=lang,
                mode=mode,
                model=model,
                max_retries=2  # Moins de retries car dÃ©jÃ  essayÃ©
            )
            
            if result:
                results[failed_index] = result
                print(f"âœ… [Retry] Chunk {failed_index + 1} succeeded!", flush=True)
            else:
                print(f"âŒ [Retry] Chunk {failed_index + 1} still failed", flush=True)
    
    # Calculer le rapport de couverture
    successful_analyses = [r for r in results if r is not None]
    final_failed = [i for i, r in enumerate(results) if r is None]
    
    words_analyzed = sum(a.word_count_analyzed for a in successful_analyses)
    coverage_percent = (words_analyzed / total_words * 100) if total_words > 0 else 0
    
    report = AnalysisReport(
        total_words=total_words,
        total_chunks=total_chunks,
        chunks_analyzed=len(successful_analyses),
        chunks_failed=len(final_failed),
        coverage_percent=coverage_percent,
        failed_chunks=final_failed
    )
    
    # Warnings si couverture incomplÃ¨te
    if coverage_percent < 100:
        report.warnings.append(f"âš ï¸ Couverture: {coverage_percent:.1f}% - {len(final_failed)} chunks non analysÃ©s")
        for idx in final_failed:
            chunk = chunks[idx]
            report.warnings.append(f"  - Chunk {idx + 1}: {chunk.start_time} â†’ {chunk.end_time} ({chunk.word_count} mots)")
    
    print(f"ğŸ“Š [FULL ANALYSIS] REPORT:", flush=True)
    print(f"   - Total words: {total_words}", flush=True)
    print(f"   - Chunks: {len(successful_analyses)}/{total_chunks} analyzed", flush=True)
    print(f"   - Coverage: {coverage_percent:.1f}%", flush=True)
    if final_failed:
        print(f"   - âš ï¸ FAILED chunks: {final_failed}", flush=True)
    
    return successful_analyses, report


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”„ FUSION DES ANALYSES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def synthesize_chunk_analyses(
    analyses: List[ChunkAnalysis],
    video_title: str,
    video_duration: int,
    category: str,
    lang: str,
    mode: str,
    model: str = "mistral-large-latest",  # Utiliser un modÃ¨le plus puissant pour la synthÃ¨se
    api_key: str = None,
    web_context: str = None
) -> Optional[str]:
    """
    Fusionne les analyses de chunks en une synthÃ¨se finale cohÃ©rente.
    
    Cette Ã©tape utilise un modÃ¨le plus puissant car c'est la synthÃ¨se finale.
    """
    api_key = api_key or get_mistral_key()
    if not api_key:
        return None
    
    # Formater les analyses de chunks
    chunk_summaries = []
    all_quotes = []
    all_topics = set()
    
    # ğŸ”§ FIX: Ã‰chantillonnage Ã‰QUILIBRÃ‰ des points clÃ©s sur TOUTE la vidÃ©o
    # On garde 2 points clÃ©s de CHAQUE chunk pour garantir une couverture complÃ¨te
    balanced_key_points = []
    points_per_chunk = max(2, 20 // len(analyses)) if analyses else 2  # Au moins 2 par chunk
    
    for analysis in sorted(analyses, key=lambda x: x.chunk_index):
        chunk_summaries.append(f"""
### Segment {analysis.chunk_index + 1} ({analysis.time_range})
{analysis.summary}
""")
        # Prendre les N premiers points clÃ©s de CE chunk (avec timecodes de cette partie)
        chunk_points = analysis.key_points[:points_per_chunk] if analysis.key_points else []
        balanced_key_points.extend(chunk_points)
        
        all_quotes.extend(analysis.important_quotes)
        all_topics.update(analysis.topics)
    
    # Formater le contenu pour la synthÃ¨se
    chunks_content = "\n".join(chunk_summaries)
    
    # Points clÃ©s Ã©quilibrÃ©s sur toute la vidÃ©o (dÃ©dupliquÃ©s mais gardant l'ordre chronologique)
    unique_key_points = list(dict.fromkeys(balanced_key_points))
    
    mode_instructions = {
        "accessible": "CrÃ©e une synthÃ¨se COURTE et PERCUTANTE (500-800 mots). Utilise un langage simple et des analogies.",
        "standard": "CrÃ©e une synthÃ¨se Ã‰QUILIBRÃ‰E (1000-1500 mots). Structure claire avec sections thÃ©matiques.",
        "expert": "CrÃ©e une synthÃ¨se APPROFONDIE (1500-2500 mots). Analyse critique avec Ã©valuation Ã©pistÃ©mique."
    }
    
    # DurÃ©e formatÃ©e
    hours = video_duration // 3600
    minutes = (video_duration % 3600) // 60
    duration_str = f"{hours}h{minutes:02d}" if hours > 0 else f"{minutes} min"
    
    system_prompt = f"""Tu es un expert en synthÃ¨se de contenus longs.

MISSION: CrÃ©er une synthÃ¨se FINALE et COHÃ‰RENTE d'une vidÃ©o de {duration_str}.

Tu as reÃ§u les analyses de {len(analyses)} segments de cette vidÃ©o.
Tu dois les FUSIONNER en une synthÃ¨se unique, structurÃ©e et fluide.

RÃˆGLES CRITIQUES:
1. NE PAS rÃ©pÃ©ter les mÃªmes informations plusieurs fois
2. CrÃ©er une NARRATION FLUIDE (pas une liste de segments)
3. Organiser par THÃˆMES, pas par ordre chronologique
4. âš ï¸ IMPÃ‰RATIF: Les POINTS CLÃ‰S doivent couvrir TOUTE la vidÃ©o du DÃ‰BUT Ã  la FIN
   - Inclure des timecodes du dÃ©but (0-25%), du milieu (25-75%) ET de la fin (75-100%)
   - PAS seulement les 20 premiÃ¨res minutes !
5. {mode_instructions.get(mode, mode_instructions["standard"])}

STRUCTURE ATTENDUE:
- ğŸ¯ SYNTHÃˆSE GLOBALE (2-3 phrases d'accroche)
- ğŸ“‹ SOMMAIRE THÃ‰MATIQUE (les grands axes)
- ğŸ“ DÃ‰VELOPPEMENT (organisÃ© par thÃ¨mes, pas par segments)
- ğŸ’¡ POINTS CLÃ‰S (liste avec timecodes RÃ‰PARTIS sur toute la durÃ©e de {duration_str})
- ğŸ“ CONCLUSION / Ã€ RETENIR

âš ï¸ VÃ‰RIFICATION FINALE: Assure-toi que tes timecodes dans "POINTS CLÃ‰S" couvrent:
- Le dÃ©but de la vidÃ©o (premiers 25%)
- Le milieu de la vidÃ©o (25%-75%)
- La fin de la vidÃ©o (derniers 25%)
"""

    user_prompt = f"""VIDÃ‰O: "{video_title}"
CATÃ‰GORIE: {category}
DURÃ‰E: {duration_str}
SEGMENTS ANALYSÃ‰S: {len(analyses)}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RÃ‰SUMÃ‰S DES SEGMENTS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{chunks_content}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
POINTS CLÃ‰S EXTRAITS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{chr(10).join('â€¢ ' + p for p in unique_key_points)}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
THÃˆMES IDENTIFIÃ‰S:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{', '.join(all_topics)}

"""

    # Ajouter le contexte web si disponible
    if web_context:
        user_prompt += f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“¡ CONTEXTE WEB ACTUEL (pour vÃ©rification):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{web_context[:3000]}
"""

    user_prompt += f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CrÃ©e maintenant la SYNTHÃˆSE FINALE en {"franÃ§ais" if lang == "fr" else "anglais"}.

âš ï¸ RAPPEL CRITIQUE:
- La vidÃ©o dure {duration_str}
- Les POINTS CLÃ‰S doivent inclure des timecodes de TOUTE la vidÃ©o
- Ne cite pas seulement le dÃ©but, inclus aussi le milieu et la fin !
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

    # Utiliser plus de tokens pour la synthÃ¨se finale
    max_tokens = {
        "accessible": 2000,
        "standard": 4000,
        "expert": 6000
    }.get(mode, 4000)

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.mistral.ai/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": model,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    "max_tokens": max_tokens,
                    "temperature": 0.3
                },
                timeout=180  # 3 minutes pour la synthÃ¨se
            )
            
            if response.status_code == 200:
                data = response.json()
                synthesis = data["choices"][0]["message"]["content"].strip()
                word_count = len(synthesis.split())
                print(f"âœ… Final synthesis: {word_count} words from {len(analyses)} chunks", flush=True)
                return synthesis
            else:
                print(f"âŒ Synthesis failed: {response.status_code} - {response.text}", flush=True)
                return None
                
    except Exception as e:
        print(f"âŒ Synthesis error: {e}", flush=True)
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¯ FONCTION PRINCIPALE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def analyze_long_video(
    title: str,
    transcript: str,
    video_duration: int,
    category: str,
    lang: str,
    mode: str,
    model: str = "mistral-small-latest",
    web_context: str = None,
    progress_callback = None,
    transcript_timestamped: str = None  # ğŸ†• v3.0: Transcript avec vrais timestamps
) -> Optional[str]:
    """
    ğŸ¬ Analyse COMPLÃˆTE d'une vidÃ©o longue avec GARANTIE de traitement intÃ©gral.
    
    ğŸ†• v3.0: Support des VRAIS timestamps YouTube (plus de timecodes estimÃ©s!)
    
    âš ï¸ GARANTIE: 100% du transcript est analysÃ©. Aucune partie n'est ignorÃ©e.
    
    Cette fonction:
    1. DÃ©tecte si le chunking est nÃ©cessaire
    2. Divise le transcript en chunks SANS PERTE (avec vrais timestamps)
    3. Analyse TOUS les chunks (avec retry si Ã©chec)
    4. VÃ©rifie la couverture Ã  100%
    5. Fusionne TOUTES les analyses en synthÃ¨se finale
    
    Args:
        title: Titre de la vidÃ©o
        transcript: Transcript COMPLET (texte brut)
        video_duration: DurÃ©e en secondes
        category: CatÃ©gorie dÃ©tectÃ©e
        lang: Langue (fr/en)
        mode: Mode d'analyse (accessible/standard/expert)
        model: ModÃ¨le Mistral Ã  utiliser
        web_context: Contexte web optionnel (Perplexity)
        progress_callback: Fonction(progress, message) pour le suivi
        transcript_timestamped: ğŸ†• Transcript avec timestamps rÃ©els [00:30] text
    
    Returns:
        SynthÃ¨se finale COMPLÃˆTE ou None si erreur critique
    """
    needs_chunk, word_count, reason = needs_chunking(transcript)
    
    if not needs_chunk:
        print(f"ğŸ“ Standard analysis (no chunking needed): {word_count} words", flush=True)
        return None  # Utiliser l'analyse standard
    
    print(f"", flush=True)
    print(f"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—", flush=True)
    print(f"â•‘  ğŸ“š LONG VIDEO ANALYSIS v3.0 - REAL TIMESTAMPS                   â•‘", flush=True)
    print(f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•", flush=True)
    print(f"ğŸ“Š Transcript: {word_count} words", flush=True)
    print(f"â±ï¸ Duration: {video_duration // 60} min {video_duration % 60} sec", flush=True)
    print(f"ğŸ“ Category: {category}", flush=True)
    print(f"ğŸ¯ Mode: {mode}", flush=True)
    print(f"â±ï¸ Real timestamps: {'YES âœ…' if transcript_timestamped else 'NO (estimated)'}", flush=True)
    print(f"", flush=True)
    
    if progress_callback:
        progress_callback(35, f"ğŸ“š VidÃ©o longue dÃ©tectÃ©e ({word_count} mots)...")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. DÃ‰COUPAGE EN CHUNKS (AVEC VRAIS TIMESTAMPS)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    chunks = split_into_chunks_with_real_timestamps(
        transcript=transcript,
        transcript_timestamped=transcript_timestamped or "",
        video_duration=video_duration
    )
    
    # VÃ©rifier que le dÃ©coupage couvre tout
    total_chunk_words = sum(c.word_count for c in chunks)
    print(f"âœ‚ï¸ Split into {len(chunks)} chunks covering {total_chunk_words} words", flush=True)
    
    for i, chunk in enumerate(chunks):
        print(f"   â””â”€ Chunk {i + 1}: [{chunk.start_time} â†’ {chunk.end_time}] {chunk.word_count} mots", flush=True)
    
    if progress_callback:
        progress_callback(38, f"âœ‚ï¸ Division en {len(chunks)} parties...")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. ANALYSE DE TOUS LES CHUNKS (AVEC RETRY)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    chunk_analyses, report = await analyze_chunks_parallel(
        chunks=chunks,
        video_title=title,
        category=category,
        lang=lang,
        mode=mode,
        model=model,
        max_concurrent=MAX_CONCURRENT_CHUNKS,
        progress_callback=progress_callback
    )
    
    # VÃ©rifier la couverture
    if report.coverage_percent < 100:
        print(f"âš ï¸ WARNING: Coverage is {report.coverage_percent:.1f}% (not 100%)", flush=True)
        for warning in report.warnings:
            print(f"   {warning}", flush=True)
    else:
        print(f"âœ… PERFECT: 100% coverage achieved!", flush=True)
    
    if not chunk_analyses:
        print("âŒ CRITICAL: No chunk analyses succeeded at all!", flush=True)
        return None
    
    if len(chunk_analyses) < len(chunks) * 0.5:
        print(f"âŒ CRITICAL: Too many chunks failed ({len(chunk_analyses)}/{len(chunks)})", flush=True)
        # Quand mÃªme essayer de gÃ©nÃ©rer une synthÃ¨se partielle
    
    if progress_callback:
        if report.coverage_percent == 100:
            progress_callback(78, f"âœ… {len(chunk_analyses)} parties analysÃ©es (100%)")
        else:
            progress_callback(78, f"âš ï¸ {len(chunk_analyses)}/{len(chunks)} parties analysÃ©es ({report.coverage_percent:.0f}%)")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. FUSION EN SYNTHÃˆSE FINALE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if progress_callback:
        progress_callback(80, f"ğŸ”„ Fusion des {len(chunk_analyses)} analyses...")
    
    # Utiliser un modÃ¨le plus puissant pour la synthÃ¨se si disponible
    synthesis_model = "mistral-large-latest" if "large" in model or mode == "expert" else model
    
    final_summary = await synthesize_chunk_analyses(
        analyses=chunk_analyses,
        video_title=title,
        video_duration=video_duration,
        category=category,
        lang=lang,
        mode=mode,
        model=synthesis_model,
        web_context=web_context
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. AJOUTER LE RAPPORT DE COUVERTURE Ã€ LA SYNTHÃˆSE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if final_summary:
        # Ajouter un badge de couverture
        coverage_badge = ""
        if lang == "fr":
            if report.coverage_percent == 100:
                coverage_badge = f"\n\n---\nğŸ“Š **Analyse complÃ¨te** â€” {word_count} mots analysÃ©s en {len(chunk_analyses)} parties (100% de la vidÃ©o)"
            else:
                coverage_badge = f"\n\n---\nâš ï¸ **Analyse partielle** â€” {report.chunks_analyzed}/{report.total_chunks} parties analysÃ©es ({report.coverage_percent:.0f}% de la vidÃ©o)"
        else:
            if report.coverage_percent == 100:
                coverage_badge = f"\n\n---\nğŸ“Š **Complete analysis** â€” {word_count} words analyzed in {len(chunk_analyses)} parts (100% of video)"
            else:
                coverage_badge = f"\n\n---\nâš ï¸ **Partial analysis** â€” {report.chunks_analyzed}/{report.total_chunks} parts analyzed ({report.coverage_percent:.0f}% of video)"
        
        final_summary += coverage_badge
    
    if progress_callback:
        if final_summary:
            progress_callback(95, "âœ… SynthÃ¨se finale gÃ©nÃ©rÃ©e")
        else:
            progress_callback(95, "âŒ Ã‰chec de la synthÃ¨se")
    
    print(f"", flush=True)
    print(f"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—", flush=True)
    print(f"â•‘  ğŸ“Š ANALYSIS COMPLETE                                            â•‘", flush=True)
    print(f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•", flush=True)
    print(f"âœ… Chunks analyzed: {report.chunks_analyzed}/{report.total_chunks}", flush=True)
    print(f"ğŸ“Š Coverage: {report.coverage_percent:.1f}%", flush=True)
    print(f"ğŸ“ Final summary: {len(final_summary.split()) if final_summary else 0} words", flush=True)
    print(f"", flush=True)
    
    return final_summary


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š UTILITAIRES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_chunk_stats(transcript: str) -> Dict[str, Any]:
    """
    Retourne des statistiques sur le chunking nÃ©cessaire.
    Utile pour l'UI (afficher le nombre de parties).
    """
    needs_chunk, word_count, reason = needs_chunking(transcript)
    
    if not needs_chunk:
        return {
            "needs_chunking": False,
            "word_count": word_count,
            "estimated_chunks": 1,
            "reason": reason
        }
    
    estimated_chunks = max(1, (word_count - CHUNK_OVERLAP_WORDS) // (CHUNK_SIZE_WORDS - CHUNK_OVERLAP_WORDS))
    
    return {
        "needs_chunking": True,
        "word_count": word_count,
        "estimated_chunks": estimated_chunks,
        "estimated_duration_per_chunk": "~30s",
        "reason": reason,
        "chunk_size": CHUNK_SIZE_WORDS
    }
