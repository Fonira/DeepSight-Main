"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  üì¶ BATCH ROUTER ‚Äî API v2 pour analyses en lot                                     ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë  üÜï Features 2026:                                                                 ‚ïë
‚ïë  ‚Ä¢ Analyse de plusieurs vid√©os en une seule requ√™te                               ‚ïë
‚ïë  ‚Ä¢ Suivi du statut par batch_id                                                    ‚ïë
‚ïë  ‚Ä¢ Limites par plan (Free: 3, Pro: 10, Team: 50)                                   ‚ïë
‚ïë  ‚Ä¢ Priorisation des analyses par ordre de soumission                               ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""

import asyncio
from uuid import uuid4
from datetime import datetime
from typing import Optional, List
from pydantic import BaseModel, Field
from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from db.database import get_session, User
from auth.dependencies import get_current_user, get_verified_user
from core.config import PLAN_LIMITS

router = APIRouter()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üìã SCHEMAS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class BatchVideoItem(BaseModel):
    """Une vid√©o √† analyser dans un batch"""
    url: str = Field(..., description="URL de la vid√©o YouTube")
    mode: str = Field(default="standard", description="Mode: accessible, standard, expert")
    category: Optional[str] = Field(default=None, description="Cat√©gorie (auto si None)")
    lang: str = Field(default="fr", description="Langue: fr, en")


class BatchAnalyzeRequest(BaseModel):
    """Requ√™te pour analyser plusieurs vid√©os"""
    videos: List[BatchVideoItem] = Field(..., description="Liste des vid√©os √† analyser")
    priority: str = Field(default="normal", description="Priorit√©: low, normal, high (Team only)")


class BatchItemStatus(BaseModel):
    """Statut d'un item dans un batch"""
    url: str
    status: str  # pending, processing, completed, failed
    task_id: Optional[str] = None
    summary_id: Optional[int] = None
    error: Optional[str] = None


class BatchStatusResponse(BaseModel):
    """Statut d'un batch complet"""
    batch_id: str
    status: str  # pending, processing, completed, partial, failed
    total: int
    completed: int
    failed: int
    items: List[BatchItemStatus]
    created_at: datetime
    completed_at: Optional[datetime] = None


class BatchCreateResponse(BaseModel):
    """R√©ponse de cr√©ation d'un batch"""
    batch_id: str
    status: str
    total: int
    credits_reserved: int
    message: str


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üíæ STOCKAGE EN M√âMOIRE (pour MVP - remplacer par Redis en production)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

_batch_store: dict = {}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üîß LIMITES PAR PLAN
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

BATCH_LIMITS = {
    "free": 3,
    "student": 5,
    "starter": 5,
    "pro": 10,
    "expert": 20,
    "team": 50,
    "unlimited": 100,
}


def get_batch_limit(plan: str) -> int:
    """Retourne la limite de vid√©os par batch selon le plan"""
    return BATCH_LIMITS.get(plan, BATCH_LIMITS["free"])


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üì¶ ENDPOINTS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

@router.post("/analyze", response_model=BatchCreateResponse)
async def create_batch_analysis(
    request: BatchAnalyzeRequest,
    background_tasks: BackgroundTasks,
    current_user: User = Depends(get_verified_user),
    session: AsyncSession = Depends(get_session)
):
    """
    Cr√©e une analyse en lot pour plusieurs vid√©os YouTube.

    - **videos**: Liste des vid√©os √† analyser (max selon plan)
    - **priority**: Priorit√© de traitement (Team only pour high)

    Retourne un batch_id pour suivre le statut des analyses.
    """
    user_plan = current_user.plan or "free"
    batch_limit = get_batch_limit(user_plan)

    # V√©rifier la limite de vid√©os
    if len(request.videos) > batch_limit:
        raise HTTPException(
            status_code=400,
            detail=f"Batch limit exceeded. Your plan ({user_plan}) allows max {batch_limit} videos per batch."
        )

    if len(request.videos) == 0:
        raise HTTPException(
            status_code=400,
            detail="At least one video is required."
        )

    # V√©rifier priorit√© (high = Team only)
    if request.priority == "high" and user_plan not in ["team", "expert", "unlimited"]:
        request.priority = "normal"

    # Calculer le co√ªt total en cr√©dits
    plan_limits = PLAN_LIMITS.get(user_plan, PLAN_LIMITS["free"])
    credit_cost_per_video = plan_limits.get("credit_cost", 5)
    total_credits = len(request.videos) * credit_cost_per_video

    # V√©rifier les cr√©dits disponibles
    if (current_user.credits or 0) < total_credits:
        raise HTTPException(
            status_code=402,
            detail=f"Insufficient credits. Need {total_credits}, have {current_user.credits or 0}."
        )

    # G√©n√©rer un batch_id
    batch_id = f"batch_{uuid4().hex[:12]}"

    # Cr√©er les items de statut
    items = [
        BatchItemStatus(
            url=video.url,
            status="pending",
            task_id=None,
            summary_id=None,
            error=None
        )
        for video in request.videos
    ]

    # Stocker le batch
    _batch_store[batch_id] = {
        "batch_id": batch_id,
        "user_id": current_user.id,
        "status": "pending",
        "total": len(request.videos),
        "completed": 0,
        "failed": 0,
        "items": [item.model_dump() for item in items],
        "videos": [video.model_dump() for video in request.videos],
        "created_at": datetime.utcnow(),
        "completed_at": None,
        "priority": request.priority,
    }

    # Lancer le traitement en arri√®re-plan
    background_tasks.add_task(
        process_batch,
        batch_id=batch_id,
        user_id=current_user.id,
    )

    return BatchCreateResponse(
        batch_id=batch_id,
        status="pending",
        total=len(request.videos),
        credits_reserved=total_credits,
        message=f"Batch created. {len(request.videos)} videos queued for analysis."
    )


@router.get("/status/{batch_id}", response_model=BatchStatusResponse)
async def get_batch_status(
    batch_id: str,
    current_user: User = Depends(get_current_user),
):
    """
    R√©cup√®re le statut d'un batch d'analyses.

    Retourne le statut global et le d√©tail de chaque vid√©o.
    """
    batch = _batch_store.get(batch_id)

    if not batch:
        raise HTTPException(status_code=404, detail="Batch not found")

    # V√©rifier que l'utilisateur est propri√©taire du batch
    if batch["user_id"] != current_user.id:
        raise HTTPException(status_code=403, detail="Access denied")

    return BatchStatusResponse(
        batch_id=batch["batch_id"],
        status=batch["status"],
        total=batch["total"],
        completed=batch["completed"],
        failed=batch["failed"],
        items=[BatchItemStatus(**item) for item in batch["items"]],
        created_at=batch["created_at"],
        completed_at=batch.get("completed_at"),
    )


@router.get("/list")
async def list_user_batches(
    current_user: User = Depends(get_current_user),
    limit: int = 10,
):
    """
    Liste les batches r√©cents de l'utilisateur.
    """
    user_batches = [
        {
            "batch_id": b["batch_id"],
            "status": b["status"],
            "total": b["total"],
            "completed": b["completed"],
            "failed": b["failed"],
            "created_at": b["created_at"],
        }
        for b in _batch_store.values()
        if b["user_id"] == current_user.id
    ]

    # Trier par date de cr√©ation d√©croissante
    user_batches.sort(key=lambda x: x["created_at"], reverse=True)

    return {"batches": user_batches[:limit]}


@router.delete("/{batch_id}")
async def cancel_batch(
    batch_id: str,
    current_user: User = Depends(get_current_user),
):
    """
    Annule un batch en attente (ne peut pas annuler les analyses en cours).
    """
    batch = _batch_store.get(batch_id)

    if not batch:
        raise HTTPException(status_code=404, detail="Batch not found")

    if batch["user_id"] != current_user.id:
        raise HTTPException(status_code=403, detail="Access denied")

    if batch["status"] not in ["pending", "processing"]:
        raise HTTPException(
            status_code=400,
            detail=f"Cannot cancel batch with status: {batch['status']}"
        )

    # Marquer comme annul√©
    batch["status"] = "cancelled"
    batch["completed_at"] = datetime.utcnow()

    # Marquer les items pending comme cancelled
    for item in batch["items"]:
        if item["status"] == "pending":
            item["status"] = "cancelled"

    return {"success": True, "message": "Batch cancelled"}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üîÑ TRAITEMENT EN ARRI√àRE-PLAN
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def process_batch(batch_id: str, user_id: int):
    """
    Traite un batch d'analyses en arri√®re-plan.
    """
    from db.database import async_session_maker
    from videos.service import create_task, update_task_status
    from videos.router import run_analysis_task

    batch = _batch_store.get(batch_id)
    if not batch:
        return

    batch["status"] = "processing"

    async with async_session_maker() as session:
        # R√©cup√©rer l'utilisateur
        result = await session.execute(select(User).where(User.id == user_id))
        user = result.scalar_one_or_none()

        if not user:
            batch["status"] = "failed"
            return

        # Traiter chaque vid√©o s√©quentiellement
        for i, video_config in enumerate(batch["videos"]):
            item = batch["items"][i]

            # V√©rifier si le batch a √©t√© annul√©
            if batch["status"] == "cancelled":
                break

            try:
                item["status"] = "processing"

                # Cr√©er une t√¢che pour cette vid√©o
                task_id = f"task_{uuid4().hex[:12]}"
                item["task_id"] = task_id

                # Simuler l'analyse (dans une vraie impl√©mentation,
                # appeler run_analysis_task ou la logique d'analyse)
                await asyncio.sleep(0.5)  # Placeholder

                # Pour l'instant, marquer comme compl√©t√©
                # TODO: Int√©grer avec le syst√®me d'analyse r√©el
                item["status"] = "completed"
                batch["completed"] += 1

            except Exception as e:
                item["status"] = "failed"
                item["error"] = str(e)[:200]
                batch["failed"] += 1

    # Mettre √† jour le statut final
    if batch["status"] != "cancelled":
        if batch["failed"] == batch["total"]:
            batch["status"] = "failed"
        elif batch["completed"] == batch["total"]:
            batch["status"] = "completed"
        else:
            batch["status"] = "partial"

    batch["completed_at"] = datetime.utcnow()
