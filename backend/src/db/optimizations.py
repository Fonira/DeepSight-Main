"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ—„ï¸ DATABASE OPTIMIZATIONS v2.0 â€” Index, Migrations & Query Optimization           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  OPTIMISATIONS:                                                                    â•‘
â•‘  â€¢ ğŸ” Index optimisÃ©s pour les requÃªtes frÃ©quentes                                â•‘
â•‘  â€¢ ğŸ“Š Vues matÃ©rialisÃ©es pour les agrÃ©gations                                     â•‘
â•‘  â€¢ ğŸ”„ Migrations Alembic                                                           â•‘
â•‘  â€¢ ğŸ“ˆ Query optimization patterns                                                  â•‘
â•‘  â€¢ ğŸ’¾ Connection pooling avancÃ©                                                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Usage:
    # Appliquer les optimisations
    python -m db.optimizations apply
    
    # VÃ©rifier les index manquants
    python -m db.optimizations check
    
    # Analyser les requÃªtes lentes
    python -m db.optimizations analyze
"""

import os
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from contextlib import asynccontextmanager

from sqlalchemy import text, Index, event
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from sqlalchemy.pool import NullPool, QueuePool

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ DATABASE ENGINE CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DATABASE_URL = os.environ.get("DATABASE_URL", "")

def create_optimized_engine(
    url: str = DATABASE_URL,
    pool_size: int = 20,
    max_overflow: int = 10,
    pool_pre_ping: bool = True,
    pool_recycle: int = 3600,
    echo: bool = False,
):
    """
    CrÃ©e un engine SQLAlchemy optimisÃ© avec connection pooling avancÃ©.
    
    Args:
        url: URL de la base de donnÃ©es
        pool_size: Nombre de connexions dans le pool
        max_overflow: Connexions supplÃ©mentaires autorisÃ©es
        pool_pre_ping: VÃ©rifie les connexions avant utilisation
        pool_recycle: Recycle les connexions aprÃ¨s N secondes
        echo: Log les requÃªtes SQL
    """
    engine = create_async_engine(
        url,
        # Pool configuration
        poolclass=QueuePool,
        pool_size=pool_size,
        max_overflow=max_overflow,
        pool_pre_ping=pool_pre_ping,
        pool_recycle=pool_recycle,
        
        # Performance
        echo=echo,
        future=True,
        
        # Connection args pour PostgreSQL
        connect_args={
            "server_settings": {
                "jit": "off",  # DÃ©sactiver JIT pour les requÃªtes courtes
                "statement_timeout": "30000",  # 30s timeout
            }
        }
    )
    
    # Event listeners pour le monitoring
    @event.listens_for(engine.sync_engine, "connect")
    def set_search_path(dbapi_connection, connection_record):
        """Configure le search_path Ã  la connexion"""
        cursor = dbapi_connection.cursor()
        cursor.execute("SET search_path TO public")
        cursor.close()
    
    return engine


# Session factory
engine = create_optimized_engine()
async_session_maker = async_sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False,
    autoflush=False,
)


@asynccontextmanager
async def get_session():
    """Context manager pour les sessions DB"""
    session = async_session_maker()
    try:
        yield session
        await session.commit()
    except Exception:
        await session.rollback()
        raise
    finally:
        await session.close()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ” INDEX DEFINITIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

RECOMMENDED_INDEXES = """
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ“Š SUMMARIES TABLE INDEXES
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- Index pour la recherche par utilisateur (trÃ¨s frÃ©quent)
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_summaries_user_id 
ON summaries(user_id);

-- Index pour le tri par date (historique)
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_summaries_user_created 
ON summaries(user_id, created_at DESC);

-- Index pour la recherche par video_id (Ã©viter les doublons)
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_summaries_video_id 
ON summaries(video_id);

-- Index composite pour les filtres frÃ©quents
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_summaries_user_category_created 
ON summaries(user_id, category, created_at DESC);

-- Index pour les favoris
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_summaries_user_favorite 
ON summaries(user_id, is_favorite) 
WHERE is_favorite = true;

-- Index full-text pour la recherche dans les rÃ©sumÃ©s
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_summaries_content_gin 
ON summaries USING gin(to_tsvector('french', video_title || ' ' || COALESCE(summary_content, '')));

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ’¬ CHAT MESSAGES TABLE INDEXES
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- Index pour rÃ©cupÃ©rer les messages d'un rÃ©sumÃ©
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_chat_messages_summary_created 
ON chat_messages(summary_id, created_at);

-- Index pour les messages par utilisateur
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_chat_messages_user_id 
ON chat_messages(user_id);

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ‘¤ USERS TABLE INDEXES
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- Index unique pour l'email (dÃ©jÃ  en contrainte, mais s'assurer qu'il existe)
CREATE UNIQUE INDEX CONCURRENTLY IF NOT EXISTS idx_users_email 
ON users(email);

-- Index pour Stripe
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_users_stripe_customer 
ON users(stripe_customer_id) 
WHERE stripe_customer_id IS NOT NULL;

-- Index pour le plan
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_users_plan 
ON users(plan);

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ“‹ PLAYLISTS TABLE INDEXES
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- Index pour les playlists par utilisateur
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_playlists_user_id 
ON playlists(user_id);

-- Index pour les items de playlist
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_playlist_items_playlist_position 
ON playlist_items(playlist_id, position);

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ“Š TASK STATUS TABLE INDEXES
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- Index pour les tÃ¢ches en cours par utilisateur
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_task_status_user_status 
ON task_status(user_id, status) 
WHERE status IN ('pending', 'processing');

-- Index pour le nettoyage des vieilles tÃ¢ches
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_task_status_created 
ON task_status(created_at);
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š MATERIALIZED VIEWS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

MATERIALIZED_VIEWS = """
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ“ˆ VUE: Statistiques utilisateur (refresh toutes les heures)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CREATE MATERIALIZED VIEW IF NOT EXISTS mv_user_stats AS
SELECT 
    u.id as user_id,
    u.email,
    u.plan,
    COUNT(DISTINCT s.id) as total_summaries,
    COUNT(DISTINCT s.id) FILTER (WHERE s.created_at > NOW() - INTERVAL '30 days') as summaries_30d,
    COUNT(DISTINCT cm.id) as total_chat_messages,
    COALESCE(SUM(s.word_count), 0) as total_words,
    MIN(s.created_at) as first_summary_at,
    MAX(s.created_at) as last_summary_at,
    NOW() as refreshed_at
FROM users u
LEFT JOIN summaries s ON s.user_id = u.id
LEFT JOIN chat_messages cm ON cm.user_id = u.id
GROUP BY u.id, u.email, u.plan;

CREATE UNIQUE INDEX IF NOT EXISTS idx_mv_user_stats_user_id 
ON mv_user_stats(user_id);

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ“Š VUE: CatÃ©gories populaires par utilisateur
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CREATE MATERIALIZED VIEW IF NOT EXISTS mv_user_categories AS
SELECT 
    user_id,
    category,
    COUNT(*) as count,
    MAX(created_at) as last_used
FROM summaries
WHERE category IS NOT NULL
GROUP BY user_id, category;

CREATE INDEX IF NOT EXISTS idx_mv_user_categories_user 
ON mv_user_categories(user_id, count DESC);

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ“ˆ VUE: MÃ©triques globales (pour admin)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CREATE MATERIALIZED VIEW IF NOT EXISTS mv_global_metrics AS
SELECT 
    COUNT(DISTINCT u.id) as total_users,
    COUNT(DISTINCT u.id) FILTER (WHERE u.plan != 'free') as paid_users,
    COUNT(DISTINCT u.id) FILTER (WHERE u.created_at > NOW() - INTERVAL '7 days') as new_users_7d,
    COUNT(DISTINCT s.id) as total_summaries,
    COUNT(DISTINCT s.id) FILTER (WHERE s.created_at > NOW() - INTERVAL '24 hours') as summaries_24h,
    COUNT(DISTINCT cm.id) as total_chat_messages,
    COALESCE(SUM(s.word_count), 0) as total_words_generated,
    NOW() as refreshed_at
FROM users u
LEFT JOIN summaries s ON s.user_id = u.id
LEFT JOIN chat_messages cm ON cm.user_id = u.id;
"""

REFRESH_MATERIALIZED_VIEWS = """
-- RafraÃ®chir les vues matÃ©rialisÃ©es (Ã  exÃ©cuter pÃ©riodiquement)
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_user_stats;
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_user_categories;
REFRESH MATERIALIZED VIEW CONCURRENTLY mv_global_metrics;
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ QUERY OPTIMIZATION HELPERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class QueryOptimizer:
    """Helpers pour optimiser les requÃªtes frÃ©quentes"""
    
    @staticmethod
    async def get_user_history_optimized(
        session: AsyncSession,
        user_id: int,
        limit: int = 20,
        offset: int = 0,
        category: Optional[str] = None,
        favorites_only: bool = False,
        search_query: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        """
        RÃ©cupÃ¨re l'historique utilisateur de maniÃ¨re optimisÃ©e.
        Utilise les index et Ã©vite les N+1 queries.
        """
        # Construire la requÃªte de base
        base_query = """
            SELECT 
                s.id,
                s.video_id,
                s.video_title,
                s.video_channel,
                s.category,
                s.word_count,
                s.is_favorite,
                s.created_at,
                s.mode,
                s.lang,
                (SELECT COUNT(*) FROM chat_messages cm WHERE cm.summary_id = s.id) as chat_count
            FROM summaries s
            WHERE s.user_id = :user_id
        """
        
        params = {"user_id": user_id, "limit": limit, "offset": offset}
        
        # Filtres conditionnels
        if category:
            base_query += " AND s.category = :category"
            params["category"] = category
        
        if favorites_only:
            base_query += " AND s.is_favorite = true"
        
        if search_query:
            base_query += """
                AND to_tsvector('french', s.video_title || ' ' || COALESCE(s.summary_content, '')) 
                @@ plainto_tsquery('french', :search_query)
            """
            params["search_query"] = search_query
        
        # Tri et pagination
        base_query += " ORDER BY s.created_at DESC LIMIT :limit OFFSET :offset"
        
        result = await session.execute(text(base_query), params)
        rows = result.fetchall()
        
        return [
            {
                "id": row.id,
                "video_id": row.video_id,
                "video_title": row.video_title,
                "video_channel": row.video_channel,
                "category": row.category,
                "word_count": row.word_count,
                "is_favorite": row.is_favorite,
                "created_at": row.created_at.isoformat(),
                "mode": row.mode,
                "lang": row.lang,
                "chat_count": row.chat_count,
            }
            for row in rows
        ]
    
    @staticmethod
    async def get_user_stats_fast(
        session: AsyncSession,
        user_id: int,
    ) -> Dict[str, Any]:
        """
        RÃ©cupÃ¨re les stats utilisateur depuis la vue matÃ©rialisÃ©e.
        Fallback sur une requÃªte normale si la vue n'existe pas.
        """
        try:
            result = await session.execute(
                text("SELECT * FROM mv_user_stats WHERE user_id = :user_id"),
                {"user_id": user_id}
            )
            row = result.fetchone()
            
            if row:
                return {
                    "total_summaries": row.total_summaries,
                    "summaries_30d": row.summaries_30d,
                    "total_chat_messages": row.total_chat_messages,
                    "total_words": row.total_words,
                    "first_summary_at": row.first_summary_at.isoformat() if row.first_summary_at else None,
                    "last_summary_at": row.last_summary_at.isoformat() if row.last_summary_at else None,
                }
        except Exception:
            pass
        
        # Fallback
        result = await session.execute(
            text("""
                SELECT 
                    COUNT(*) as total_summaries,
                    COUNT(*) FILTER (WHERE created_at > NOW() - INTERVAL '30 days') as summaries_30d,
                    COALESCE(SUM(word_count), 0) as total_words
                FROM summaries
                WHERE user_id = :user_id
            """),
            {"user_id": user_id}
        )
        row = result.fetchone()
        
        return {
            "total_summaries": row.total_summaries,
            "summaries_30d": row.summaries_30d,
            "total_words": row.total_words,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ› ï¸ MAINTENANCE FUNCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def apply_indexes():
    """Applique tous les index recommandÃ©s"""
    async with engine.begin() as conn:
        for statement in RECOMMENDED_INDEXES.strip().split(';'):
            statement = statement.strip()
            if statement and not statement.startswith('--'):
                try:
                    await conn.execute(text(statement))
                    print(f"âœ… Applied: {statement[:60]}...")
                except Exception as e:
                    print(f"âš ï¸ Skipped (may already exist): {e}")


async def create_materialized_views():
    """CrÃ©e les vues matÃ©rialisÃ©es"""
    async with engine.begin() as conn:
        for statement in MATERIALIZED_VIEWS.strip().split(';'):
            statement = statement.strip()
            if statement and not statement.startswith('--'):
                try:
                    await conn.execute(text(statement))
                    print(f"âœ… Created view: {statement[:60]}...")
                except Exception as e:
                    print(f"âš ï¸ Skipped: {e}")


async def refresh_materialized_views():
    """RafraÃ®chit les vues matÃ©rialisÃ©es"""
    async with engine.begin() as conn:
        for statement in REFRESH_MATERIALIZED_VIEWS.strip().split(';'):
            statement = statement.strip()
            if statement and not statement.startswith('--'):
                try:
                    await conn.execute(text(statement))
                    print(f"âœ… Refreshed: {statement[:60]}...")
                except Exception as e:
                    print(f"âš ï¸ Error refreshing: {e}")


async def analyze_tables():
    """Analyse les tables pour optimiser les plans de requÃªte"""
    tables = ['users', 'summaries', 'chat_messages', 'playlists', 'playlist_items', 'task_status']
    
    async with engine.begin() as conn:
        for table in tables:
            await conn.execute(text(f"ANALYZE {table}"))
            print(f"âœ… Analyzed: {table}")


async def check_missing_indexes():
    """VÃ©rifie les index manquants (requÃªtes lentes)"""
    query = """
        SELECT 
            schemaname || '.' || relname as table,
            seq_scan,
            seq_tup_read,
            idx_scan,
            idx_tup_fetch,
            CASE WHEN seq_scan > 0 
                THEN round(seq_tup_read::numeric / seq_scan, 2) 
                ELSE 0 
            END as avg_rows_per_seq_scan
        FROM pg_stat_user_tables
        WHERE seq_scan > 100
        ORDER BY seq_tup_read DESC
        LIMIT 20;
    """
    
    async with engine.begin() as conn:
        result = await conn.execute(text(query))
        rows = result.fetchall()
        
        print("\nğŸ“Š Tables avec beaucoup de sequential scans:")
        print("-" * 80)
        for row in rows:
            print(f"  {row.table}: {row.seq_scan} seq scans, {row.avg_rows_per_seq_scan} avg rows/scan")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“¦ CLI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import sys
    import asyncio
    
    async def main():
        command = sys.argv[1] if len(sys.argv) > 1 else "help"
        
        if command == "apply":
            print("ğŸ”§ Applying database optimizations...")
            await apply_indexes()
            await create_materialized_views()
            await analyze_tables()
            print("\nâœ… Done!")
            
        elif command == "refresh":
            print("ğŸ”„ Refreshing materialized views...")
            await refresh_materialized_views()
            print("\nâœ… Done!")
            
        elif command == "check":
            print("ğŸ” Checking for missing indexes...")
            await check_missing_indexes()
            
        elif command == "analyze":
            print("ğŸ“Š Analyzing tables...")
            await analyze_tables()
            print("\nâœ… Done!")
            
        else:
            print("""
Usage: python -m db.optimizations <command>

Commands:
    apply     - Apply all indexes and create materialized views
    refresh   - Refresh materialized views
    check     - Check for missing indexes
    analyze   - Analyze tables for query optimization
            """)
    
    asyncio.run(main())
